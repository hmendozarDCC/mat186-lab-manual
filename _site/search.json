[
  {
    "objectID": "labs/lab01.html",
    "href": "labs/lab01.html",
    "title": "Lab 1: R and RStudio Installation",
    "section": "",
    "text": "By the end of this lab, students will‚Ä¶\nSuccessfully install the R‚Ä¶ # Lab 1: R and RStudio Installation",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 1: R and RStudio Installation"
    ]
  },
  {
    "objectID": "labs/lab01.html#learning-objectives",
    "href": "labs/lab01.html#learning-objectives",
    "title": "Lab 1: R and RStudio Installation",
    "section": "",
    "text": "By the end of this lab, students will‚Ä¶\nSuccessfully install the R‚Ä¶ # Lab 1: R and RStudio Installation",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 1: R and RStudio Installation"
    ]
  },
  {
    "objectID": "labs/lab01.html#introduction",
    "href": "labs/lab01.html#introduction",
    "title": "Lab 1: R and RStudio Installation",
    "section": "Introduction",
    "text": "Introduction\nTo perform data science at DCC, we use two primary tools. Think of R as the ‚Äúengine‚Äù of a car and RStudio as the ‚Äúdashboard.‚Äù You need the engine to go, but you need the dashboard to steer and see where you are going.\n\nIf you are using a DCC Chromebook or a computer where you cannot install software, please contact the instructor about using Posit Cloud (the web-based version of RStudio).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 1: R and RStudio Installation"
    ]
  },
  {
    "objectID": "labs/lab01.html#step-1-install-r-the-engine",
    "href": "labs/lab01.html#step-1-install-r-the-engine",
    "title": "Lab 1: R and RStudio Installation",
    "section": "Step 1: Install R (The Engine)",
    "text": "Step 1: Install R (The Engine)\nYou must install R before you install RStudio.\n\nGo to the CRAN (Comprehensive R Archive Network) website.\nSelect the download link for your operating system:\n\nDownload R for Windows -&gt; Click ‚Äúbase‚Äù -&gt; Click ‚ÄúDownload R 4.x.x for Windows.‚Äù\nDownload R for (macOS) -&gt; Download the .pkg file that matches your chip (Apple silicon M1/M2 or Intel).\n\nRun the downloaded installer and keep all default settings by clicking ‚ÄúNext‚Äù or ‚ÄúContinue.‚Äù",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 1: R and RStudio Installation"
    ]
  },
  {
    "objectID": "labs/lab01.html#step-2-install-rstudio-the-dashboard",
    "href": "labs/lab01.html#step-2-install-rstudio-the-dashboard",
    "title": "Lab 1: R and RStudio Installation",
    "section": "Step 2: Install RStudio (The Dashboard)",
    "text": "Step 2: Install RStudio (The Dashboard)\nRStudio is the interface where you will write your code and view your data visualizations.\n\nVisit the Posit Download Page.\nScroll down to ‚Äú2: Install RStudio‚Äù and click the button for your operating system.\nRun the installer. Like R, it is best to keep all default settings.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 1: R and RStudio Installation"
    ]
  },
  {
    "objectID": "labs/lab01.html#step-3-verify-your-setup",
    "href": "labs/lab01.html#step-3-verify-your-setup",
    "title": "Lab 1: R and RStudio Installation",
    "section": "Step 3: Verify Your Setup",
    "text": "Step 3: Verify Your Setup\nLet‚Äôs make sure the ‚Äúengine‚Äù and ‚Äúdashboard‚Äù are talking to each other.\n\nOpen RStudio from your applications folder or start menu.\nFind the Console pane (usually on the bottom left).\nType the following code and press Enter:\n\n\nprint(\"Hello, MAT 186!\")\n\n[1] \"Hello, MAT 186!\"\n\n\n\n\n\n\n\n\nImportantüìù Lab Task 2: Capturing Your Work\n\n\n\nFollow these steps to take a screenshot of your R console:\n\nRun the Code: In your Console (the bottom-left panel of RStudio), type the following exactly and press Enter: print(\"Hello, MAT 186!\")\nTake a Screenshot: Capture an image of your screen showing that message.\n\nWindows: Use Windows Key + Shift + S.\nMac: Use Cmd + Shift + 4.\n\nSave Your Work: Save the screenshot into your Mat186 folder on your computer. Give it a clear name like Lab2_Screenshot.\nSubmit: Upload this image file to the Lab 2 assignment folder in your course portal.\n\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 1: R and RStudio Installation"
    ]
  },
  {
    "objectID": "labs/lab01.html#learning-objectives-1",
    "href": "labs/lab01.html#learning-objectives-1",
    "title": "Lab 1: R and RStudio Installation",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lab, students will be able to:\n\nSuccessfully install the R programming language.\nInstall the RStudio Desktop Integrated Development Environment (IDE).\nVerify the installation by running a simple command.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 1: R and RStudio Installation"
    ]
  },
  {
    "objectID": "labs/lab05.html",
    "href": "labs/lab05.html",
    "title": "Lab 5: Getting Data into R",
    "section": "",
    "text": "By the end of this lab, students will be able to:\n\nUnderstand the difference between Absolute and Relative file paths.\nImport data from a local CSV file.\nImport data directly from a URL (Web).\nUse the readr package (part of the tidyverse).\n\n\n\n\n\nBefore we can visualize or model data, we have to ‚Äúimport‚Äù it into R‚Äôs memory. Most data you will encounter is stored in CSV (Comma Separated Values) format, which looks like an Excel spreadsheet but is much lighter and easier for programs to read.\n\n\n\n\nR needs to know which folder on your computer it should ‚Äúlook‚Äù in.\n\nCrucial Step: This is why we use RStudio Projects (from Lab 2). When you open your .Rproj file, R automatically sets your folder as the ‚ÄúWorking Directory.‚Äù\n\nTo check where R is looking,\n\nLocate the Console pane (typically in the bottom-left of RStudio).\nType getwd() at the command prompt (&gt;). It is important to include the parentheses () because it is a function.\nPress the Enter (or Return) key on your keyboard.\n\n\n\n\n\nThe easiest way to get started is to pull data directly from the internet. We will use the read_csv() function from the tidyverse.\n\n\n\n\n\n\nNoteüí° Tip: Working with Code Chunks\n\n\n\nTo Insert a New Chunk: Click the green ‚Äú+C‚Äù icon (Insert) in the toolbar at the top of your editor script, then select R. This creates a new gray box for your code.\nTo Run the Code: Click the green ‚ÄúPlay‚Äù button (the small triangle) in the top-right corner of the gray box. The results will appear directly below the chunk in your document.\n\n\n\n\nIn this step, we will tell R to go to the internet, find our dataset, and bring it into RStudio so we can analyze it.\nFollow these steps: 1. Create a new R chunk in your RStudio document. 2. Copy the code below by clicking the copy icon in the top-right corner of the gray box. 3. Paste the code into your new chunk in RStudio. 4. Click the Green Play button (the triangle) to run the code.\n\n# Step 1: Load the tidyverse tools\nlibrary(tidyverse)\n\n# Step 2: Set the web address for the Low Birth Weight (LBW) data\nurl &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/lbw.csv\"\n\n# Step 3: Download the data and name it 'lbw_data'\nlbw_data &lt;- read_csv(url)\n\n# Step 4: Show the first few rows of the data\nhead(lbw_data)\n\n# A tibble: 6 √ó 11\n  rownames   low smoke  race   age   lwt   ptl    ht    ui   ftv   bwt\n     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1        1     0     0     2    19   182     0     0     1     0  2523\n2        2     0     0     3    33   155     0     0     0     3  2551\n3        3     0     1     1    20   105     0     0     0     1  2557\n4        4     0     1     1    21   108     0     0     1     2  2594\n5        5     0     1     1    18   107     0     0     1     0  2600\n6        6     0     0     3    21   124     0     0     0     0  2622\n\n\n\n\n\n\n\n\nTip‚úÖ Success Check\n\n\n\nIf the code worked, you should see a table appear directly below your code chunk starting with column names like rownames, low, age, and lwt.\n\n\n\n\n\n\n\nOften, you will download a dataset from a site like Kaggle or a government portal.This link to free data\n\nFind a CSV file (or download a sample one).\nMove that file into your MAT186_Labs folder.\nUse the following code (replace filename.csv with your actual file name):\n\nmy_data &lt;- read_csv(\"filename.csv\")\n\n\n\n\n\n‚ÄúFile not found‚Äù: This usually means the file is not in your Project folder, or you misspelled the name (remember: Data.csv is different from data.csv).\nColumn Parsing: Sometimes R guesses the data type wrong (e.g., thinking a zip code is a number instead of a label). We will learn to fix this in future labs!\n\n\n\nLab Task 5:\n\nFind any public CSV dataset. For example, this link to free data. Use the lbw data set.\n\n\n\n\n\n\n\nTipüì• How to Download the Data\n\n\n\nFollow these steps to save the dataset to your computer:\n\nSearch for the Data: In the search box at the top of the website, type ‚Äúlbw‚Äù.\nDownload the File: Find the link labeled CSV.\n\nRight-click (or Ctrl+click on a Mac) the CSV link.\nSelect ‚ÄúSave Link As‚Ä¶‚Äù or ‚ÄúDownload Linked File As‚Ä¶‚Äù.\n\nSave it in the Right Place: Save the file directly into your Mat186 folder on your computer.\n\n\n\n\nImport it into a new Quarto document using read_csv.\nUse the glimpse() command to show the structure of your data:\n\nglimpse(my_data)\n\nRender the document and confirm that your data table appears in the HTML.\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 5: Getting data into R"
    ]
  },
  {
    "objectID": "labs/lab05.html#learning-objectives",
    "href": "labs/lab05.html#learning-objectives",
    "title": "Lab 5: Getting Data into R",
    "section": "",
    "text": "By the end of this lab, students will be able to:\n\nUnderstand the difference between Absolute and Relative file paths.\nImport data from a local CSV file.\nImport data directly from a URL (Web).\nUse the readr package (part of the tidyverse).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 5: Getting data into R"
    ]
  },
  {
    "objectID": "labs/lab05.html#introduction",
    "href": "labs/lab05.html#introduction",
    "title": "Lab 5: Getting Data into R",
    "section": "",
    "text": "Before we can visualize or model data, we have to ‚Äúimport‚Äù it into R‚Äôs memory. Most data you will encounter is stored in CSV (Comma Separated Values) format, which looks like an Excel spreadsheet but is much lighter and easier for programs to read.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 5: Getting data into R"
    ]
  },
  {
    "objectID": "labs/lab05.html#part-1-the-working-directory",
    "href": "labs/lab05.html#part-1-the-working-directory",
    "title": "Lab 5: Getting Data into R",
    "section": "",
    "text": "R needs to know which folder on your computer it should ‚Äúlook‚Äù in.\n\nCrucial Step: This is why we use RStudio Projects (from Lab 2). When you open your .Rproj file, R automatically sets your folder as the ‚ÄúWorking Directory.‚Äù\n\nTo check where R is looking,\n\nLocate the Console pane (typically in the bottom-left of RStudio).\nType getwd() at the command prompt (&gt;). It is important to include the parentheses () because it is a function.\nPress the Enter (or Return) key on your keyboard.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 5: Getting data into R"
    ]
  },
  {
    "objectID": "labs/lab05.html#part-2-loading-data-from-a-url",
    "href": "labs/lab05.html#part-2-loading-data-from-a-url",
    "title": "Lab 5: Getting Data into R",
    "section": "",
    "text": "The easiest way to get started is to pull data directly from the internet. We will use the read_csv() function from the tidyverse.\n\n\n\n\n\n\nNoteüí° Tip: Working with Code Chunks\n\n\n\nTo Insert a New Chunk: Click the green ‚Äú+C‚Äù icon (Insert) in the toolbar at the top of your editor script, then select R. This creates a new gray box for your code.\nTo Run the Code: Click the green ‚ÄúPlay‚Äù button (the small triangle) in the top-right corner of the gray box. The results will appear directly below the chunk in your document.\n\n\n\n\nIn this step, we will tell R to go to the internet, find our dataset, and bring it into RStudio so we can analyze it.\nFollow these steps: 1. Create a new R chunk in your RStudio document. 2. Copy the code below by clicking the copy icon in the top-right corner of the gray box. 3. Paste the code into your new chunk in RStudio. 4. Click the Green Play button (the triangle) to run the code.\n\n# Step 1: Load the tidyverse tools\nlibrary(tidyverse)\n\n# Step 2: Set the web address for the Low Birth Weight (LBW) data\nurl &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/lbw.csv\"\n\n# Step 3: Download the data and name it 'lbw_data'\nlbw_data &lt;- read_csv(url)\n\n# Step 4: Show the first few rows of the data\nhead(lbw_data)\n\n# A tibble: 6 √ó 11\n  rownames   low smoke  race   age   lwt   ptl    ht    ui   ftv   bwt\n     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1        1     0     0     2    19   182     0     0     1     0  2523\n2        2     0     0     3    33   155     0     0     0     3  2551\n3        3     0     1     1    20   105     0     0     0     1  2557\n4        4     0     1     1    21   108     0     0     1     2  2594\n5        5     0     1     1    18   107     0     0     1     0  2600\n6        6     0     0     3    21   124     0     0     0     0  2622\n\n\n\n\n\n\n\n\nTip‚úÖ Success Check\n\n\n\nIf the code worked, you should see a table appear directly below your code chunk starting with column names like rownames, low, age, and lwt.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 5: Getting data into R"
    ]
  },
  {
    "objectID": "labs/lab05.html#part-3-loading-a-local-csv",
    "href": "labs/lab05.html#part-3-loading-a-local-csv",
    "title": "Lab 5: Getting Data into R",
    "section": "",
    "text": "Often, you will download a dataset from a site like Kaggle or a government portal.This link to free data\n\nFind a CSV file (or download a sample one).\nMove that file into your MAT186_Labs folder.\nUse the following code (replace filename.csv with your actual file name):\n\nmy_data &lt;- read_csv(\"filename.csv\")",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 5: Getting data into R"
    ]
  },
  {
    "objectID": "labs/lab05.html#part-4-dealing-with-common-errors",
    "href": "labs/lab05.html#part-4-dealing-with-common-errors",
    "title": "Lab 5: Getting Data into R",
    "section": "",
    "text": "‚ÄúFile not found‚Äù: This usually means the file is not in your Project folder, or you misspelled the name (remember: Data.csv is different from data.csv).\nColumn Parsing: Sometimes R guesses the data type wrong (e.g., thinking a zip code is a number instead of a label). We will learn to fix this in future labs!\n\n\n\nLab Task 5:\n\nFind any public CSV dataset. For example, this link to free data. Use the lbw data set.\n\n\n\n\n\n\n\nTipüì• How to Download the Data\n\n\n\nFollow these steps to save the dataset to your computer:\n\nSearch for the Data: In the search box at the top of the website, type ‚Äúlbw‚Äù.\nDownload the File: Find the link labeled CSV.\n\nRight-click (or Ctrl+click on a Mac) the CSV link.\nSelect ‚ÄúSave Link As‚Ä¶‚Äù or ‚ÄúDownload Linked File As‚Ä¶‚Äù.\n\nSave it in the Right Place: Save the file directly into your Mat186 folder on your computer.\n\n\n\n\nImport it into a new Quarto document using read_csv.\nUse the glimpse() command to show the structure of your data:\n\nglimpse(my_data)\n\nRender the document and confirm that your data table appears in the HTML.\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 5: Getting data into R"
    ]
  },
  {
    "objectID": "labs/lab06.html",
    "href": "labs/lab06.html",
    "title": "Lab 6: Data Collection and Sources",
    "section": "",
    "text": "Distinguish between Primary and Secondary data.\nExplore ‚ÄúOpen Data‚Äù portals (Local, State, and Federal).\nUnderstand the concept of Tidy Data.\nPractice ethical data attribution.\n\n\n\n\n\nData doesn‚Äôt just appear out of nowhere; it is collected via sensors, surveys, web scraping, or manual entry. As a data scientist at DCC, you should know how to find reliable sources of information to answer real-world questions.\n\n\n\n\nGovernment agencies often provide ‚ÄúOpen Data‚Äù portals where anyone can download datasets for free. These are excellent sources for your final projects.\n\n\n\nDutchess County Open Data: Local data on parcels, transit, and public safety.\nNY State Open Data: Information on education, health, and the environment across New York.\nU.S. Census Bureau: The gold standard for demographic data in the United States.\n\n\n\n\n\n\nOnce you collect data, it needs to be in a specific format for R to read it easily. This is called Tidy Data. There are three rules:\n\nEach variable must have its own column.\nEach observation (case) must have its own row.\nEach value must have its own cell.\n\n\n\n\n\nWhenever you collect data that you didn‚Äôt create yourself, you must provide a Data Citation. This gives credit to the original collectors and allows others to verify your work.\nA good citation includes:\n\nThe name of the organization.\nThe year the data was accessed.\nThe URL/Link to the dataset.\n\n\n\nLab Task 6: The Scavenger Hunt\n\nVisit the NY State Open Data Portal.\nSearch for a dataset that interests you (e.g., ‚ÄúStudent Enrollment‚Äù or ‚ÄúWater Quality‚Äù).\nDownload the CSV version of that data.\nMove the file into your RStudio Project folder.\nIn a new Quarto document, write a short paragraph describing:\n\nWhere the data came from.\nWho collected it.\nWhat one row in the dataset represents (the observation).\n\nUse read_csv() to load the data and show the first 10 rows using head().\n\n\n\n\n\n\nData you find ‚Äúin the wild‚Äù is rarely perfect. In the next lab, we will learn how to ‚Äúclean‚Äù the data you just found‚Äîremoving empty rows and fixing typos!\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 6: Data collection"
    ]
  },
  {
    "objectID": "labs/lab06.html#learning-objectives",
    "href": "labs/lab06.html#learning-objectives",
    "title": "Lab 6: Data Collection and Sources",
    "section": "",
    "text": "Distinguish between Primary and Secondary data.\nExplore ‚ÄúOpen Data‚Äù portals (Local, State, and Federal).\nUnderstand the concept of Tidy Data.\nPractice ethical data attribution.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 6: Data collection"
    ]
  },
  {
    "objectID": "labs/lab06.html#introduction",
    "href": "labs/lab06.html#introduction",
    "title": "Lab 6: Data Collection and Sources",
    "section": "",
    "text": "Data doesn‚Äôt just appear out of nowhere; it is collected via sensors, surveys, web scraping, or manual entry. As a data scientist at DCC, you should know how to find reliable sources of information to answer real-world questions.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 6: Data collection"
    ]
  },
  {
    "objectID": "labs/lab06.html#part-1-finding-open-data",
    "href": "labs/lab06.html#part-1-finding-open-data",
    "title": "Lab 6: Data Collection and Sources",
    "section": "",
    "text": "Government agencies often provide ‚ÄúOpen Data‚Äù portals where anyone can download datasets for free. These are excellent sources for your final projects.\n\n\n\nDutchess County Open Data: Local data on parcels, transit, and public safety.\nNY State Open Data: Information on education, health, and the environment across New York.\nU.S. Census Bureau: The gold standard for demographic data in the United States.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 6: Data collection"
    ]
  },
  {
    "objectID": "labs/lab06.html#part-2-what-is-tidy-data",
    "href": "labs/lab06.html#part-2-what-is-tidy-data",
    "title": "Lab 6: Data Collection and Sources",
    "section": "",
    "text": "Once you collect data, it needs to be in a specific format for R to read it easily. This is called Tidy Data. There are three rules:\n\nEach variable must have its own column.\nEach observation (case) must have its own row.\nEach value must have its own cell.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 6: Data collection"
    ]
  },
  {
    "objectID": "labs/lab06.html#part-3-data-ethics-attribution",
    "href": "labs/lab06.html#part-3-data-ethics-attribution",
    "title": "Lab 6: Data Collection and Sources",
    "section": "",
    "text": "Whenever you collect data that you didn‚Äôt create yourself, you must provide a Data Citation. This gives credit to the original collectors and allows others to verify your work.\nA good citation includes:\n\nThe name of the organization.\nThe year the data was accessed.\nThe URL/Link to the dataset.\n\n\n\nLab Task 6: The Scavenger Hunt\n\nVisit the NY State Open Data Portal.\nSearch for a dataset that interests you (e.g., ‚ÄúStudent Enrollment‚Äù or ‚ÄúWater Quality‚Äù).\nDownload the CSV version of that data.\nMove the file into your RStudio Project folder.\nIn a new Quarto document, write a short paragraph describing:\n\nWhere the data came from.\nWho collected it.\nWhat one row in the dataset represents (the observation).\n\nUse read_csv() to load the data and show the first 10 rows using head().",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 6: Data collection"
    ]
  },
  {
    "objectID": "labs/lab06.html#part-4-the-next-step-preview",
    "href": "labs/lab06.html#part-4-the-next-step-preview",
    "title": "Lab 6: Data Collection and Sources",
    "section": "",
    "text": "Data you find ‚Äúin the wild‚Äù is rarely perfect. In the next lab, we will learn how to ‚Äúclean‚Äù the data you just found‚Äîremoving empty rows and fixing typos!\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 6: Data collection"
    ]
  },
  {
    "objectID": "labs/lab07.html",
    "href": "labs/lab07.html",
    "title": "Lab 7: Cleaning Data with dplyr",
    "section": "",
    "text": "Understand the concept of ‚ÄúData Wrangling.‚Äù\nUse the Pipe Operator (|&gt;) to chain commands.\nLearn core cleaning functions: filter(), select(), and rename().\nHandle missing values (NA).\n\n\n\n\n\n‚ÄúRaw‚Äù data is rarely ready for analysis. It might have columns you don‚Äôt need, rows that aren‚Äôt relevant to your study, or names that are hard to type. In this lab, we use the dplyr package (part of the tidyverse) to ‚Äútidy up‚Äù our datasets.\n\n\n\n\nThink of the pipe operator as saying the words ‚Äúand then.‚Äù It takes the output of one function and passes it to the next.\nInstead of writing: clean_data &lt;- filter(raw_data, age &gt; 18)\nWe write: clean_data &lt;- raw_data |&gt; filter(age &gt; 18)\n\n\n\n\n\n\nIf your dataset has 100 columns but you only need 3, use select().\n\nlibrary(tidyverse)\n\n# Keep only the 'name' and 'height' columns\nsw_small &lt;- starwars |&gt; \n  select(name, height)\n\n# Use knitr::kable to generate an accessible HTML table\nknitr::kable(head(sw_small))\n\n\n\nTable¬†1: Table 1: Name and height of the first six characters in the Star Wars dataset.\n\n\n\n\n\n\nname\nheight\n\n\n\n\nLuke Skywalker\n172\n\n\nC-3PO\n167\n\n\nR2-D2\n96\n\n\nDarth Vader\n202\n\n\nLeia Organa\n150\n\n\nOwen Lars\n178\n\n\n\n\n\n\n\n\n\n\n\nIf you only want to look at specific observations (e.g., characters taller than 100cm).\n\nlibrary(tidyverse)\n\n# Keep only rows where height is greater than 100\ntall_characters &lt;- starwars |&gt; \n  filter(height &gt; 100) |&gt;\n  select(name, height, species, homeworld) # Selecting specific columns makes tables easier to read\n\n# Use kable to create an accessible HTML table structure\nknitr::kable(head(tall_characters))\n\n\n\nTable¬†2: Table: Subset of Star Wars characters with a height greater than 100cm.\n\n\n\n\n\n\nname\nheight\nspecies\nhomeworld\n\n\n\n\nLuke Skywalker\n172\nHuman\nTatooine\n\n\nC-3PO\n167\nDroid\nTatooine\n\n\nDarth Vader\n202\nHuman\nTatooine\n\n\nLeia Organa\n150\nHuman\nAlderaan\n\n\nOwen Lars\n178\nHuman\nTatooine\n\n\nBeru Whitesun Lars\n165\nHuman\nTatooine\n\n\n\n\n\n\n\n\n\n\n\nIf a column name is confusing or has spaces, rename it.\n\nlibrary(tidyverse)\n\n# Change 'homeworld' to 'home_planet'\nsw_clean &lt;- starwars |&gt; \n  rename(home_planet = homeworld)\n\n# We select a few columns so the table isn't too wide for a screen reader\nknitr::kable(head(sw_clean[, c(\"name\", \"height\", \"home_planet\")]))\n\n\n\nTable¬†3: Table: Star Wars character data showing the renamed ‚Äòhome_planet‚Äô column.\n\n\n\n\n\n\nname\nheight\nhome_planet\n\n\n\n\nLuke Skywalker\n172\nTatooine\n\n\nC-3PO\n167\nTatooine\n\n\nR2-D2\n96\nNaboo\n\n\nDarth Vader\n202\nTatooine\n\n\nLeia Organa\n150\nAlderaan\n\n\nOwen Lars\n178\nTatooine\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn R, missing values are represented as NA (Not Available). You can‚Äôt calculate the mean of a column if it has NA values without telling R what to do.\nTo remove rows with any missing data:\n\nlibrary(tidyverse)\n\n# Remove rows where height is NA\ntidy_sw &lt;- starwars |&gt; \n  drop_na(height)\n\n# Display the first six rows using an accessible HTML table format\nknitr::kable(head(tidy_sw[, c(\"name\", \"height\", \"mass\", \"species\")]))\n\n\n\nTable¬†4: Table: Star Wars characters after removing rows with missing height values.\n\n\n\n\n\n\nname\nheight\nmass\nspecies\n\n\n\n\nLuke Skywalker\n172\n77\nHuman\n\n\nC-3PO\n167\n75\nDroid\n\n\nR2-D2\n96\n32\nDroid\n\n\nDarth Vader\n202\n136\nHuman\n\n\nLeia Organa\n150\n49\nHuman\n\n\nOwen Lars\n178\n120\nHuman\n\n\n\n\n\n\n\n\n\n\nLab Task 7:\n\nOpen your Quarto document from Lab 6 (the one with your NY State Open Data).\nCreate a new section called ‚ÄúData Cleaning.‚Äù\nUse select() to keep only the 4 most important columns in your dataset.\nUse filter() to narrow your data down to one specific category or a certain range of numbers.\nUse rename() to make at least one column name easier to read.\nRender your document and check that your new ‚ÄúCleaned‚Äù table looks correct.\n\n\n\n\n\n\nAlways run glimpse(your_data) after cleaning to make sure you haven‚Äôt accidentally deleted something you meant to keep!\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 7: Cleaning Data"
    ]
  },
  {
    "objectID": "labs/lab07.html#learning-objectives",
    "href": "labs/lab07.html#learning-objectives",
    "title": "Lab 7: Cleaning Data with dplyr",
    "section": "",
    "text": "Understand the concept of ‚ÄúData Wrangling.‚Äù\nUse the Pipe Operator (|&gt;) to chain commands.\nLearn core cleaning functions: filter(), select(), and rename().\nHandle missing values (NA).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 7: Cleaning Data"
    ]
  },
  {
    "objectID": "labs/lab07.html#introduction",
    "href": "labs/lab07.html#introduction",
    "title": "Lab 7: Cleaning Data with dplyr",
    "section": "",
    "text": "‚ÄúRaw‚Äù data is rarely ready for analysis. It might have columns you don‚Äôt need, rows that aren‚Äôt relevant to your study, or names that are hard to type. In this lab, we use the dplyr package (part of the tidyverse) to ‚Äútidy up‚Äù our datasets.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 7: Cleaning Data"
    ]
  },
  {
    "objectID": "labs/lab07.html#part-1-the-pipe-operator",
    "href": "labs/lab07.html#part-1-the-pipe-operator",
    "title": "Lab 7: Cleaning Data with dplyr",
    "section": "",
    "text": "Think of the pipe operator as saying the words ‚Äúand then.‚Äù It takes the output of one function and passes it to the next.\nInstead of writing: clean_data &lt;- filter(raw_data, age &gt; 18)\nWe write: clean_data &lt;- raw_data |&gt; filter(age &gt; 18)",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 7: Cleaning Data"
    ]
  },
  {
    "objectID": "labs/lab07.html#part-2-core-cleaning-functions",
    "href": "labs/lab07.html#part-2-core-cleaning-functions",
    "title": "Lab 7: Cleaning Data with dplyr",
    "section": "",
    "text": "If your dataset has 100 columns but you only need 3, use select().\n\nlibrary(tidyverse)\n\n# Keep only the 'name' and 'height' columns\nsw_small &lt;- starwars |&gt; \n  select(name, height)\n\n# Use knitr::kable to generate an accessible HTML table\nknitr::kable(head(sw_small))\n\n\n\nTable¬†1: Table 1: Name and height of the first six characters in the Star Wars dataset.\n\n\n\n\n\n\nname\nheight\n\n\n\n\nLuke Skywalker\n172\n\n\nC-3PO\n167\n\n\nR2-D2\n96\n\n\nDarth Vader\n202\n\n\nLeia Organa\n150\n\n\nOwen Lars\n178\n\n\n\n\n\n\n\n\n\n\n\nIf you only want to look at specific observations (e.g., characters taller than 100cm).\n\nlibrary(tidyverse)\n\n# Keep only rows where height is greater than 100\ntall_characters &lt;- starwars |&gt; \n  filter(height &gt; 100) |&gt;\n  select(name, height, species, homeworld) # Selecting specific columns makes tables easier to read\n\n# Use kable to create an accessible HTML table structure\nknitr::kable(head(tall_characters))\n\n\n\nTable¬†2: Table: Subset of Star Wars characters with a height greater than 100cm.\n\n\n\n\n\n\nname\nheight\nspecies\nhomeworld\n\n\n\n\nLuke Skywalker\n172\nHuman\nTatooine\n\n\nC-3PO\n167\nDroid\nTatooine\n\n\nDarth Vader\n202\nHuman\nTatooine\n\n\nLeia Organa\n150\nHuman\nAlderaan\n\n\nOwen Lars\n178\nHuman\nTatooine\n\n\nBeru Whitesun Lars\n165\nHuman\nTatooine\n\n\n\n\n\n\n\n\n\n\n\nIf a column name is confusing or has spaces, rename it.\n\nlibrary(tidyverse)\n\n# Change 'homeworld' to 'home_planet'\nsw_clean &lt;- starwars |&gt; \n  rename(home_planet = homeworld)\n\n# We select a few columns so the table isn't too wide for a screen reader\nknitr::kable(head(sw_clean[, c(\"name\", \"height\", \"home_planet\")]))\n\n\n\nTable¬†3: Table: Star Wars character data showing the renamed ‚Äòhome_planet‚Äô column.\n\n\n\n\n\n\nname\nheight\nhome_planet\n\n\n\n\nLuke Skywalker\n172\nTatooine\n\n\nC-3PO\n167\nTatooine\n\n\nR2-D2\n96\nNaboo\n\n\nDarth Vader\n202\nTatooine\n\n\nLeia Organa\n150\nAlderaan\n\n\nOwen Lars\n178\nTatooine",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 7: Cleaning Data"
    ]
  },
  {
    "objectID": "labs/lab07.html#part-3-handling-missing-data-na",
    "href": "labs/lab07.html#part-3-handling-missing-data-na",
    "title": "Lab 7: Cleaning Data with dplyr",
    "section": "",
    "text": "In R, missing values are represented as NA (Not Available). You can‚Äôt calculate the mean of a column if it has NA values without telling R what to do.\nTo remove rows with any missing data:\n\nlibrary(tidyverse)\n\n# Remove rows where height is NA\ntidy_sw &lt;- starwars |&gt; \n  drop_na(height)\n\n# Display the first six rows using an accessible HTML table format\nknitr::kable(head(tidy_sw[, c(\"name\", \"height\", \"mass\", \"species\")]))\n\n\n\nTable¬†4: Table: Star Wars characters after removing rows with missing height values.\n\n\n\n\n\n\nname\nheight\nmass\nspecies\n\n\n\n\nLuke Skywalker\n172\n77\nHuman\n\n\nC-3PO\n167\n75\nDroid\n\n\nR2-D2\n96\n32\nDroid\n\n\nDarth Vader\n202\n136\nHuman\n\n\nLeia Organa\n150\n49\nHuman\n\n\nOwen Lars\n178\n120\nHuman\n\n\n\n\n\n\n\n\n\n\nLab Task 7:\n\nOpen your Quarto document from Lab 6 (the one with your NY State Open Data).\nCreate a new section called ‚ÄúData Cleaning.‚Äù\nUse select() to keep only the 4 most important columns in your dataset.\nUse filter() to narrow your data down to one specific category or a certain range of numbers.\nUse rename() to make at least one column name easier to read.\nRender your document and check that your new ‚ÄúCleaned‚Äù table looks correct.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 7: Cleaning Data"
    ]
  },
  {
    "objectID": "labs/lab07.html#pro-tip-the-glimpse",
    "href": "labs/lab07.html#pro-tip-the-glimpse",
    "title": "Lab 7: Cleaning Data with dplyr",
    "section": "",
    "text": "Always run glimpse(your_data) after cleaning to make sure you haven‚Äôt accidentally deleted something you meant to keep!\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 7: Cleaning Data"
    ]
  },
  {
    "objectID": "labs/lab08.html",
    "href": "labs/lab08.html",
    "title": "Lab 8: Data Exploration and Visualization with ggplot2",
    "section": "",
    "text": "Calculate ‚ÄúSummary Statistics‚Äù using dplyr.\nUnderstand the Grammar of Graphics (Data, Aesthetics, and Geoms).\nCreate distributions (Histograms) and relationships (Scatter Plots).\nIdentify outliers and patterns through visual-first discovery.\n\n\n\n\n\nBefore we draw, we must understand the ‚Äúcenter‚Äù and ‚Äúspread‚Äù of our data. We use summarize() to get the hard numbers.\n\nlibrary(tidyverse)\n\n# Analyzing the Star Wars dataset\nstarwars |&gt;\n  drop_na(height) |&gt;\n  summarize(\n    mean_height = mean(height),\n    median_height = median(height),\n    sd_height = sd(height)\n  ) |&gt;\n  knitr::kable()\n\n\n\nTable¬†1: Summary statistics for Star Wars character heights, including mean, median, and standard deviation (measured in cm).\n\n\n\n\n\n\nmean_height\nmedian_height\nsd_height\n\n\n\n\n174.6049\n180\n34.77416\n\n\n\n\n\n\n\n\n\n\n\n\nIn ggplot2, every plot has three essential ingredients:\n\nData: The dataframe we are using.\nAesthetics (aes): The mapping of data to the axes (x and y).\nGeoms: The geometric shapes used to represent the data (points, bars, lines).\n\n\n\n\n\nA histogram helps us see where the data is ‚Äúclumped.‚Äù If the mean and median are very different, the histogram will show a ‚Äúskew.‚Äù\n\nlibrary(tidyverse)\n\nggplot(data = starwars, mapping = aes(x = height)) +\n  geom_histogram(binwidth = 15, fill = \"steelblue\", color = \"white\") +\n  labs(\n    title = \"Distribution of Character Heights\",\n    x = \"Height (cm)\",\n    y = \"Frequency\"\n  )\n\n\n\n\n\n\n\nFigure¬†1: Histogram showing the distribution of Star Wars character heights.\n\n\n\n\n\n\n\n\n\nTo see if two numeric variables are related (like height and weight), we use geom_point().\n\n# Removing the extreme outlier (Jabba the Hutt) for a better view\nstarwars_filtered &lt;- starwars |&gt; filter(mass &lt; 500)\n\nggplot(data = starwars_filtered, mapping = aes(x = height, y = mass)) +\n  geom_point(color = \"darkgreen\", alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") + \n  labs(title = \"Relationship between Height and Mass\",\n       x = \"Height (cm)\",\n       y = \"Mass (kg)\")\n\n\n\n\n\n\n\nFigure¬†2: Scatterplot showing the positive relationship between height and mass in Star Wars characters.\n\n\n\n\n\n\n\n\n\nBoxplots are the best way to see how a numeric variable varies across different categories.\n\nlibrary(tidyverse)\n\nggplot(data = starwars, mapping = aes(x = gender, y = height)) +\n  geom_boxplot(fill = \"lightgray\") +\n  labs(\n    title = \"Height Distribution by Gender\",\n    x = \"Gender Identity\",\n    y = \"Height (cm)\"\n  )\n\n\n\n\n\n\n\nFigure¬†3: Boxplot comparing height distributions across different gender identities in Star Wars characters.\n\n\n\n\n\n\n\nLab Task 8:\n\nUsing your cleaned dataset from Lab 7, calculate the Mean and Standard Deviation for your main numeric variable.\nCreate a Histogram of that variable. Is the data bell-shaped or skewed?\nCreate a Scatter Plot comparing two numeric variables. Add a trend line using geom_smooth().\nCreate a Boxplot that compares one numeric variable across different categories.\nObservation: In your Quarto document, write 3 sentences describing the most interesting pattern or outlier you found in your plots.\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 8: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "labs/lab08.html#learning-objectives",
    "href": "labs/lab08.html#learning-objectives",
    "title": "Lab 8: Data Exploration and Visualization with ggplot2",
    "section": "",
    "text": "Calculate ‚ÄúSummary Statistics‚Äù using dplyr.\nUnderstand the Grammar of Graphics (Data, Aesthetics, and Geoms).\nCreate distributions (Histograms) and relationships (Scatter Plots).\nIdentify outliers and patterns through visual-first discovery.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 8: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "labs/lab08.html#part-1-numerical-exploration",
    "href": "labs/lab08.html#part-1-numerical-exploration",
    "title": "Lab 8: Data Exploration and Visualization with ggplot2",
    "section": "",
    "text": "Before we draw, we must understand the ‚Äúcenter‚Äù and ‚Äúspread‚Äù of our data. We use summarize() to get the hard numbers.\n\nlibrary(tidyverse)\n\n# Analyzing the Star Wars dataset\nstarwars |&gt;\n  drop_na(height) |&gt;\n  summarize(\n    mean_height = mean(height),\n    median_height = median(height),\n    sd_height = sd(height)\n  ) |&gt;\n  knitr::kable()\n\n\n\nTable¬†1: Summary statistics for Star Wars character heights, including mean, median, and standard deviation (measured in cm).\n\n\n\n\n\n\nmean_height\nmedian_height\nsd_height\n\n\n\n\n174.6049\n180\n34.77416",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 8: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "labs/lab08.html#part-2-the-grammar-of-ggplot2",
    "href": "labs/lab08.html#part-2-the-grammar-of-ggplot2",
    "title": "Lab 8: Data Exploration and Visualization with ggplot2",
    "section": "",
    "text": "In ggplot2, every plot has three essential ingredients:\n\nData: The dataframe we are using.\nAesthetics (aes): The mapping of data to the axes (x and y).\nGeoms: The geometric shapes used to represent the data (points, bars, lines).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 8: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "labs/lab08.html#part-3-visualizing-distributions-histograms",
    "href": "labs/lab08.html#part-3-visualizing-distributions-histograms",
    "title": "Lab 8: Data Exploration and Visualization with ggplot2",
    "section": "",
    "text": "A histogram helps us see where the data is ‚Äúclumped.‚Äù If the mean and median are very different, the histogram will show a ‚Äúskew.‚Äù\n\nlibrary(tidyverse)\n\nggplot(data = starwars, mapping = aes(x = height)) +\n  geom_histogram(binwidth = 15, fill = \"steelblue\", color = \"white\") +\n  labs(\n    title = \"Distribution of Character Heights\",\n    x = \"Height (cm)\",\n    y = \"Frequency\"\n  )\n\n\n\n\n\n\n\nFigure¬†1: Histogram showing the distribution of Star Wars character heights.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 8: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "labs/lab08.html#part-4-visualizing-relationships-scatter-plots",
    "href": "labs/lab08.html#part-4-visualizing-relationships-scatter-plots",
    "title": "Lab 8: Data Exploration and Visualization with ggplot2",
    "section": "",
    "text": "To see if two numeric variables are related (like height and weight), we use geom_point().\n\n# Removing the extreme outlier (Jabba the Hutt) for a better view\nstarwars_filtered &lt;- starwars |&gt; filter(mass &lt; 500)\n\nggplot(data = starwars_filtered, mapping = aes(x = height, y = mass)) +\n  geom_point(color = \"darkgreen\", alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") + \n  labs(title = \"Relationship between Height and Mass\",\n       x = \"Height (cm)\",\n       y = \"Mass (kg)\")\n\n\n\n\n\n\n\nFigure¬†2: Scatterplot showing the positive relationship between height and mass in Star Wars characters.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 8: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "labs/lab08.html#part-5-comparing-groups-boxplots",
    "href": "labs/lab08.html#part-5-comparing-groups-boxplots",
    "title": "Lab 8: Data Exploration and Visualization with ggplot2",
    "section": "",
    "text": "Boxplots are the best way to see how a numeric variable varies across different categories.\n\nlibrary(tidyverse)\n\nggplot(data = starwars, mapping = aes(x = gender, y = height)) +\n  geom_boxplot(fill = \"lightgray\") +\n  labs(\n    title = \"Height Distribution by Gender\",\n    x = \"Gender Identity\",\n    y = \"Height (cm)\"\n  )\n\n\n\n\n\n\n\nFigure¬†3: Boxplot comparing height distributions across different gender identities in Star Wars characters.\n\n\n\n\n\n\n\nLab Task 8:\n\nUsing your cleaned dataset from Lab 7, calculate the Mean and Standard Deviation for your main numeric variable.\nCreate a Histogram of that variable. Is the data bell-shaped or skewed?\nCreate a Scatter Plot comparing two numeric variables. Add a trend line using geom_smooth().\nCreate a Boxplot that compares one numeric variable across different categories.\nObservation: In your Quarto document, write 3 sentences describing the most interesting pattern or outlier you found in your plots.\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 8: Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "labs/lab09.html",
    "href": "labs/lab09.html",
    "title": "Lab 9: Probability and Sampling Distributions",
    "section": "",
    "text": "Distinguish between Discrete and Continuous probability distributions.\nVisualize the Normal Distribution (the ‚ÄúBell Curve‚Äù).\nDemonstrate the Central Limit Theorem through simulation.\nUnderstand how sample size affects the ‚ÄúStandard Error.‚Äù\n\n\n\n\n\nIn nature and data science, many variables (like heights or exam scores) follow a ‚ÄúNormal‚Äù distribution. We can use R to visualize the perfect mathematical curve and compare it to our real data.\n\nlibrary(tidyverse)\n\n# Generating a theoretical normal distribution\ndata.frame(x = c(-4, 4)) |&gt;\n  ggplot(aes(x)) +\n  stat_function(fun = dnorm, color = \"blue\", linewidth = 1) +\n  labs(title = \"The Standard Normal Distribution (z-distribution)\",\n       subtitle = \"Mean = 0, SD = 1\",\n       x = \"Standard Deviations\", y = \"Density\")\n\n\n\n\n\n\n\nFigure¬†1: The Standard Normal Distribution curve with a mean of 0 and standard deviation of 1.\n\n\n\n\n\n\n\n\n\nWhen we have ‚ÄúYes/No‚Äù outcomes (like a coin flip or a student passing a test), we use the Binomial Distribution.\n\nlibrary(tidyverse)\n\n# Simulating 100 people flipping a coin 10 times each\nset.seed(123) # Setting a seed makes the simulation (and your alt-text) consistent\nflips &lt;- rbinom(n = 100, size = 10, prob = 0.5)\n\nggplot(data.frame(flips), aes(x = flips)) +\n  geom_bar(fill = \"darkorange\", color = \"white\") +\n  labs(title = \"Binomial Distribution of Coin Flips\",\n       x = \"Number of Heads\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nFigure¬†2: Bar chart showing the results of 100 people flipping a coin 10 times each.\n\n\n\n\n\n\n\n\n\nThe CLT is the ‚ÄúMagic‚Äù of statistics. It states that if you take enough samples, the distribution of the sample means will always look normal, even if the original data is messy or skewed.\n\n\n\nlibrary(tidyverse)\n\n# 1. Take 1000 samples of size 30 from a random population\n# We set a seed so the 'bell shape' described in alt-text stays consistent\nset.seed(42)\nsamples &lt;- replicate(1000, mean(rexp(30, rate = 0.5)))\n\n# 2. Visualize the results\nggplot(data.frame(samples), aes(x = samples)) +\n  geom_histogram(fill = \"seagreen\", color = \"white\", bins = 30) +\n  labs(title = \"Sampling Distribution of the Mean\",\n       subtitle = \"Notice the bell shape! This is the Central Limit Theorem in action.\",\n       x = \"Sample Means\", y = \"Count\")\n\n\n\n\n\n\n\nFigure¬†3: Sampling distribution of the mean for 1,000 samples (n = 30) drawn from an exponential population.\n\n\n\n\n\n\n\n\n\n\nWe can use the pnorm() function to calculate the probability of a specific event occurring.\nExample: If the average height of a character is 170cm with an SD of 10, what is the probability of a character being taller than 190cm?\n\n# Probability of a height greater than 190cm\nprob &lt;- 1 - pnorm(190, mean = 170, sd = 10)\n\n\n\nLab Task 9:\n\nCreate a new Quarto document titled ‚ÄúLab 9: Probability.‚Äù\nCreate a histogram of a variable from your own dataset. Does it look ‚ÄúNormal‚Äù?\nUse mean() and sd() to find the center and spread of that variable.\nThe Simulation: Use the ‚ÄúCLT simulation‚Äù code above, but change the sample size from 30 to 5. Render it. Then change it to 100 and render it again.\nObservation: Write 2 sentences explaining how the ‚Äúspread‚Äù of the histogram changed when you increased the sample size.\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 9: Probability distribution"
    ]
  },
  {
    "objectID": "labs/lab09.html#learning-objectives",
    "href": "labs/lab09.html#learning-objectives",
    "title": "Lab 9: Probability and Sampling Distributions",
    "section": "",
    "text": "Distinguish between Discrete and Continuous probability distributions.\nVisualize the Normal Distribution (the ‚ÄúBell Curve‚Äù).\nDemonstrate the Central Limit Theorem through simulation.\nUnderstand how sample size affects the ‚ÄúStandard Error.‚Äù",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 9: Probability distribution"
    ]
  },
  {
    "objectID": "labs/lab09.html#part-1-the-normal-distribution",
    "href": "labs/lab09.html#part-1-the-normal-distribution",
    "title": "Lab 9: Probability and Sampling Distributions",
    "section": "",
    "text": "In nature and data science, many variables (like heights or exam scores) follow a ‚ÄúNormal‚Äù distribution. We can use R to visualize the perfect mathematical curve and compare it to our real data.\n\nlibrary(tidyverse)\n\n# Generating a theoretical normal distribution\ndata.frame(x = c(-4, 4)) |&gt;\n  ggplot(aes(x)) +\n  stat_function(fun = dnorm, color = \"blue\", linewidth = 1) +\n  labs(title = \"The Standard Normal Distribution (z-distribution)\",\n       subtitle = \"Mean = 0, SD = 1\",\n       x = \"Standard Deviations\", y = \"Density\")\n\n\n\n\n\n\n\nFigure¬†1: The Standard Normal Distribution curve with a mean of 0 and standard deviation of 1.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 9: Probability distribution"
    ]
  },
  {
    "objectID": "labs/lab09.html#part-2-working-with-the-binomial-distribution",
    "href": "labs/lab09.html#part-2-working-with-the-binomial-distribution",
    "title": "Lab 9: Probability and Sampling Distributions",
    "section": "",
    "text": "When we have ‚ÄúYes/No‚Äù outcomes (like a coin flip or a student passing a test), we use the Binomial Distribution.\n\nlibrary(tidyverse)\n\n# Simulating 100 people flipping a coin 10 times each\nset.seed(123) # Setting a seed makes the simulation (and your alt-text) consistent\nflips &lt;- rbinom(n = 100, size = 10, prob = 0.5)\n\nggplot(data.frame(flips), aes(x = flips)) +\n  geom_bar(fill = \"darkorange\", color = \"white\") +\n  labs(title = \"Binomial Distribution of Coin Flips\",\n       x = \"Number of Heads\", \n       y = \"Frequency\")\n\n\n\n\n\n\n\nFigure¬†2: Bar chart showing the results of 100 people flipping a coin 10 times each.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 9: Probability distribution"
    ]
  },
  {
    "objectID": "labs/lab09.html#part-3-the-central-limit-theorem-clt",
    "href": "labs/lab09.html#part-3-the-central-limit-theorem-clt",
    "title": "Lab 9: Probability and Sampling Distributions",
    "section": "",
    "text": "The CLT is the ‚ÄúMagic‚Äù of statistics. It states that if you take enough samples, the distribution of the sample means will always look normal, even if the original data is messy or skewed.\n\n\n\nlibrary(tidyverse)\n\n# 1. Take 1000 samples of size 30 from a random population\n# We set a seed so the 'bell shape' described in alt-text stays consistent\nset.seed(42)\nsamples &lt;- replicate(1000, mean(rexp(30, rate = 0.5)))\n\n# 2. Visualize the results\nggplot(data.frame(samples), aes(x = samples)) +\n  geom_histogram(fill = \"seagreen\", color = \"white\", bins = 30) +\n  labs(title = \"Sampling Distribution of the Mean\",\n       subtitle = \"Notice the bell shape! This is the Central Limit Theorem in action.\",\n       x = \"Sample Means\", y = \"Count\")\n\n\n\n\n\n\n\nFigure¬†3: Sampling distribution of the mean for 1,000 samples (n = 30) drawn from an exponential population.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 9: Probability distribution"
    ]
  },
  {
    "objectID": "labs/lab09.html#part-4-probability-in-your-data",
    "href": "labs/lab09.html#part-4-probability-in-your-data",
    "title": "Lab 9: Probability and Sampling Distributions",
    "section": "",
    "text": "We can use the pnorm() function to calculate the probability of a specific event occurring.\nExample: If the average height of a character is 170cm with an SD of 10, what is the probability of a character being taller than 190cm?\n\n# Probability of a height greater than 190cm\nprob &lt;- 1 - pnorm(190, mean = 170, sd = 10)\n\n\n\nLab Task 9:\n\nCreate a new Quarto document titled ‚ÄúLab 9: Probability.‚Äù\nCreate a histogram of a variable from your own dataset. Does it look ‚ÄúNormal‚Äù?\nUse mean() and sd() to find the center and spread of that variable.\nThe Simulation: Use the ‚ÄúCLT simulation‚Äù code above, but change the sample size from 30 to 5. Render it. Then change it to 100 and render it again.\nObservation: Write 2 sentences explaining how the ‚Äúspread‚Äù of the histogram changed when you increased the sample size.\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 9: Probability distribution"
    ]
  },
  {
    "objectID": "labs/lab10.html",
    "href": "labs/lab10.html",
    "title": "Lab 10: Statistical Inference for One Mean",
    "section": "",
    "text": "Understand the logic of Null (\\(H_0\\)) and Alternative (\\(H_a\\)) Hypotheses.\nCalculate and interpret Confidence Intervals.\nConduct a One-Sample t-test in R.\nInterpret the p-value to make a statistical decision.\n\n\n\n\n\nWe rarely have data for an entire population (like every person in New York). Instead, we use a Sample to make an educated guess about the Population.\n\nNull Hypothesis (\\(H_0\\)): The status quo. There is ‚Äúnothing going on‚Äù or no difference.\nAlternative Hypothesis (\\(H_a\\)): What we are trying to prove. There is a significant difference.\n\n\n\n\n\nA confidence interval gives us a range of plausible values for the true population mean. We usually use a 95% Confidence Level.\n\nlibrary(tidyverse)\n\n# Let's look at the average height of Star Wars characters\nstarwars_heights &lt;- starwars |&gt; drop_na(height)\n\n# Running the t-test\ntest_results &lt;- t.test(starwars_heights$height, conf.level = 0.95)\n\n# Converting the test result list into an accessible table\nlibrary(broom)\ntidy_results &lt;- tidy(test_results)\n\nknitr::kable(\n  tidy_results[, c(\"estimate\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"Mean Height (cm)\", \"Lower Bound (2.5%)\", \"Upper Bound (97.5%)\"),\n  digits = 2\n)\n\n\n\nTable¬†1: 95% Confidence Interval for the mean height of Star Wars characters.\n\n\n\n\n\n\nMean Height (cm)\nLower Bound (2.5%)\nUpper Bound (97.5%)\n\n\n\n\n174.6\n166.92\n182.29\n\n\n\n\n\n\n\n\n\n\n\n\nImagine a claim that the ‚ÄúAverage height of a galactic citizen is 175 cm.‚Äù Does our data support this?\n\n# 1. Perform the test\nt_test_results &lt;- t.test(starwars_heights$height, mu = 175)\n\n# 2. Use the 'broom' library to turn the text output into a data frame\nlibrary(broom)\ntidy_t &lt;- tidy(t_test_results)\n\n# 3. Create an accessible table with descriptive headers\nknitr::kable(\n  tidy_t[, c(\"statistic\", \"p.value\", \"estimate\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"t-statistic\", \"p-value\", \"Sample Mean\", \"95% CI Lower\", \"95% CI Upper\"),\n  digits = 4\n)\n\n\n\nTable¬†2: One-sample t-test results comparing Star Wars character heights to a null hypothesis mean of 175 cm.\n\n\n\n\n\n\nt-statistic\np-value\nSample Mean\n95% CI Lower\n95% CI Upper\n\n\n\n\n-0.1022\n0.9188\n174.6049\n166.9157\n182.2941\n\n\n\n\n\n\n\n\n\n\n\nt: The test statistic (how many standard errors we are from the claim).\ndf: Degrees of freedom (sample size minus 1).\np-value: The probability that we would see our result if the Null Hypothesis were true.\n\n\n\n\n\n\nIn MAT 186, we typically use an alpha (\\(\\alpha\\)) level of 0.05.\n\nIf p-value &lt; 0.05: We Reject the Null Hypothesis. The result is ‚ÄúStatistically Significant.‚Äù\nIf p-value &gt; 0.05: We Fail to Reject the Null Hypothesis. We do not have enough evidence to support the change.\n\n\n\nLab Task 10:\n\nUse your personal dataset from previous labs.\nPick a numeric variable (e.g., age, price, or score).\nState your Hypotheses: * \\(H_0: \\mu = \\text{choose a number close to your average}\\)\n\n\\(H_a: \\mu \\neq \\text{that same number}\\)\n\nRun a t.test() in R using your variable and your chosen mu.\nThe Conclusion: In your Quarto document, write a formal conclusion. ‚ÄúSince the p-value was [insert p-value], we [reject/fail to reject] the null hypothesis. There [is/is not] sufficient evidence to suggest the mean is different from [insert mu].‚Äù\n\n\n\n\n\n\nWhen writing your report, always include the Confidence Interval. This helps readers (and screen readers) understand the magnitude of your finding, not just whether it was ‚Äúsignificant‚Äù or not.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 10: Statistical inference for one mean"
    ]
  },
  {
    "objectID": "labs/lab10.html#learning-objectives",
    "href": "labs/lab10.html#learning-objectives",
    "title": "Lab 10: Statistical Inference for One Mean",
    "section": "",
    "text": "Understand the logic of Null (\\(H_0\\)) and Alternative (\\(H_a\\)) Hypotheses.\nCalculate and interpret Confidence Intervals.\nConduct a One-Sample t-test in R.\nInterpret the p-value to make a statistical decision.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 10: Statistical inference for one mean"
    ]
  },
  {
    "objectID": "labs/lab10.html#part-1-the-logic-of-inference",
    "href": "labs/lab10.html#part-1-the-logic-of-inference",
    "title": "Lab 10: Statistical Inference for One Mean",
    "section": "",
    "text": "We rarely have data for an entire population (like every person in New York). Instead, we use a Sample to make an educated guess about the Population.\n\nNull Hypothesis (\\(H_0\\)): The status quo. There is ‚Äúnothing going on‚Äù or no difference.\nAlternative Hypothesis (\\(H_a\\)): What we are trying to prove. There is a significant difference.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 10: Statistical inference for one mean"
    ]
  },
  {
    "objectID": "labs/lab10.html#part-2-confidence-intervals",
    "href": "labs/lab10.html#part-2-confidence-intervals",
    "title": "Lab 10: Statistical Inference for One Mean",
    "section": "",
    "text": "A confidence interval gives us a range of plausible values for the true population mean. We usually use a 95% Confidence Level.\n\nlibrary(tidyverse)\n\n# Let's look at the average height of Star Wars characters\nstarwars_heights &lt;- starwars |&gt; drop_na(height)\n\n# Running the t-test\ntest_results &lt;- t.test(starwars_heights$height, conf.level = 0.95)\n\n# Converting the test result list into an accessible table\nlibrary(broom)\ntidy_results &lt;- tidy(test_results)\n\nknitr::kable(\n  tidy_results[, c(\"estimate\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"Mean Height (cm)\", \"Lower Bound (2.5%)\", \"Upper Bound (97.5%)\"),\n  digits = 2\n)\n\n\n\nTable¬†1: 95% Confidence Interval for the mean height of Star Wars characters.\n\n\n\n\n\n\nMean Height (cm)\nLower Bound (2.5%)\nUpper Bound (97.5%)\n\n\n\n\n174.6\n166.92\n182.29",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 10: Statistical inference for one mean"
    ]
  },
  {
    "objectID": "labs/lab10.html#part-3-the-one-sample-t-test",
    "href": "labs/lab10.html#part-3-the-one-sample-t-test",
    "title": "Lab 10: Statistical Inference for One Mean",
    "section": "",
    "text": "Imagine a claim that the ‚ÄúAverage height of a galactic citizen is 175 cm.‚Äù Does our data support this?\n\n# 1. Perform the test\nt_test_results &lt;- t.test(starwars_heights$height, mu = 175)\n\n# 2. Use the 'broom' library to turn the text output into a data frame\nlibrary(broom)\ntidy_t &lt;- tidy(t_test_results)\n\n# 3. Create an accessible table with descriptive headers\nknitr::kable(\n  tidy_t[, c(\"statistic\", \"p.value\", \"estimate\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"t-statistic\", \"p-value\", \"Sample Mean\", \"95% CI Lower\", \"95% CI Upper\"),\n  digits = 4\n)\n\n\n\nTable¬†2: One-sample t-test results comparing Star Wars character heights to a null hypothesis mean of 175 cm.\n\n\n\n\n\n\nt-statistic\np-value\nSample Mean\n95% CI Lower\n95% CI Upper\n\n\n\n\n-0.1022\n0.9188\n174.6049\n166.9157\n182.2941\n\n\n\n\n\n\n\n\n\n\n\nt: The test statistic (how many standard errors we are from the claim).\ndf: Degrees of freedom (sample size minus 1).\np-value: The probability that we would see our result if the Null Hypothesis were true.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 10: Statistical inference for one mean"
    ]
  },
  {
    "objectID": "labs/lab10.html#part-4-making-a-decision",
    "href": "labs/lab10.html#part-4-making-a-decision",
    "title": "Lab 10: Statistical Inference for One Mean",
    "section": "",
    "text": "In MAT 186, we typically use an alpha (\\(\\alpha\\)) level of 0.05.\n\nIf p-value &lt; 0.05: We Reject the Null Hypothesis. The result is ‚ÄúStatistically Significant.‚Äù\nIf p-value &gt; 0.05: We Fail to Reject the Null Hypothesis. We do not have enough evidence to support the change.\n\n\n\nLab Task 10:\n\nUse your personal dataset from previous labs.\nPick a numeric variable (e.g., age, price, or score).\nState your Hypotheses: * \\(H_0: \\mu = \\text{choose a number close to your average}\\)\n\n\\(H_a: \\mu \\neq \\text{that same number}\\)\n\nRun a t.test() in R using your variable and your chosen mu.\nThe Conclusion: In your Quarto document, write a formal conclusion. ‚ÄúSince the p-value was [insert p-value], we [reject/fail to reject] the null hypothesis. There [is/is not] sufficient evidence to suggest the mean is different from [insert mu].‚Äù",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 10: Statistical inference for one mean"
    ]
  },
  {
    "objectID": "labs/lab10.html#accessibility-tip-reporting-results",
    "href": "labs/lab10.html#accessibility-tip-reporting-results",
    "title": "Lab 10: Statistical Inference for One Mean",
    "section": "",
    "text": "When writing your report, always include the Confidence Interval. This helps readers (and screen readers) understand the magnitude of your finding, not just whether it was ‚Äúsignificant‚Äù or not.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 10: Statistical inference for one mean"
    ]
  },
  {
    "objectID": "labs/lab11.html",
    "href": "labs/lab11.html",
    "title": "Lab 11: Statistical Inference for One Proportion",
    "section": "",
    "text": "Understand the conditions for the Large Sample Proportions Test.\nState Null (\\(H_0\\)) and Alternative (\\(H_a\\)) hypotheses for proportions.\nUse prop.test() in R to calculate p-values and confidence intervals.\nApply these skills to real-world categorical data.\n\n\n\n\n\nA proportion (\\(p\\)) is the ratio of ‚Äúsuccesses‚Äù to the total number of trials. * Example: If 45 out of 100 students at DCC use RStudio, the sample proportion (\\(\\hat{p}\\)) is \\(0.45\\) (or 45%).\n\n\n\n\nWhen we test a proportion, we are comparing our sample to a claimed population value (\\(p_0\\)).\n\nNull Hypothesis (\\(H_0\\)): \\(p = p_0\\) (The proportion is exactly what was claimed).\nAlternative Hypothesis (\\(H_a\\)): \\(p \\neq p_0\\) (The proportion is different than the claim).\n\n\n\n\n\nWe use the prop.test() function. You need two numbers: x (number of successes) and n (total sample size).\nScenario: A news report claims that 50% of Star Wars characters are Humans. In our dataset, we find that 35 out of 87 characters are Human. Is the report‚Äôs 50% claim accurate?\n\n# 1. Perform the test\nprop_results &lt;- prop.test(x = 35, n = 87, p = 0.50, correct = FALSE)\n\n# 2. Tidy the result into a data frame\nlibrary(broom)\ntidy_prop &lt;- tidy(prop_results)\n\n# 3. Create an accessible table with descriptive headers\nknitr::kable(\n  tidy_prop[, c(\"estimate\", \"statistic\", \"p.value\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"Sample Proportion\", \"Chi-squared\", \"p-value\", \"Lower 95% CI\", \"Upper 95% CI\"),\n  digits = 4\n)\n\n\n\nTable¬†1: One-sample proportion test results comparing the observed proportion of humans (35/87) to a null hypothesis of 0.50.\n\n\n\n\n\n\nSample Proportion\nChi-squared\np-value\nLower 95% CI\nUpper 95% CI\n\n\n\n\n0.4023\n3.3218\n0.0684\n0.3055\n0.5074\n\n\n\n\n\n\n\n\n\n\n\nX-squared: The test statistic (similar to the \\(t\\) value from Lab 10).\np-value: If this is below 0.05, we reject the claim that the true proportion is 50%.\nsample estimate: This is your \\(\\hat{p}\\) (the \\(35/87\\) from your data).\n\n\n\n\n\n\nThe prop.test() also gives you a 95% Confidence Interval. This tells you the range where the true population proportion likely falls.\nIf your confidence interval is (0.301, 0.508), it means we are 95% confident that the true percentage of Humans in the galaxy is between 30.1% and 50.8%.\n\n\nLab Task 11:\n\nPick a categorical variable from your dataset (e.g., Gender, Species, or Success/Failure).\nCount how many ‚Äúsuccesses‚Äù (a specific category) you have compared to the total.\nThe Test: Test a claim of your choice. (e.g., ‚ÄúIs the proportion of [category] equal to 0.25?‚Äù)\nRun prop.test() in your Quarto document.\nReport: * What was your sample proportion (\\(\\hat{p}\\))?\n\nWas your p-value significant?\nWhat is the 95% confidence interval for your proportion?\n\n\n\n\n\n\n\nWhen reporting proportions to a general audience, always convert decimals to percentages and round to one decimal place (e.g., \\(0.4022\\) becomes 40.2%). This makes your findings much easier to digest for readers using assistive technology.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 11: Statistical inference for one proportion"
    ]
  },
  {
    "objectID": "labs/lab11.html#learning-objectives",
    "href": "labs/lab11.html#learning-objectives",
    "title": "Lab 11: Statistical Inference for One Proportion",
    "section": "",
    "text": "Understand the conditions for the Large Sample Proportions Test.\nState Null (\\(H_0\\)) and Alternative (\\(H_a\\)) hypotheses for proportions.\nUse prop.test() in R to calculate p-values and confidence intervals.\nApply these skills to real-world categorical data.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 11: Statistical inference for one proportion"
    ]
  },
  {
    "objectID": "labs/lab11.html#part-1-categorical-data-and-proportions",
    "href": "labs/lab11.html#part-1-categorical-data-and-proportions",
    "title": "Lab 11: Statistical Inference for One Proportion",
    "section": "",
    "text": "A proportion (\\(p\\)) is the ratio of ‚Äúsuccesses‚Äù to the total number of trials. * Example: If 45 out of 100 students at DCC use RStudio, the sample proportion (\\(\\hat{p}\\)) is \\(0.45\\) (or 45%).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 11: Statistical inference for one proportion"
    ]
  },
  {
    "objectID": "labs/lab11.html#part-2-hypotheses-for-proportions",
    "href": "labs/lab11.html#part-2-hypotheses-for-proportions",
    "title": "Lab 11: Statistical Inference for One Proportion",
    "section": "",
    "text": "When we test a proportion, we are comparing our sample to a claimed population value (\\(p_0\\)).\n\nNull Hypothesis (\\(H_0\\)): \\(p = p_0\\) (The proportion is exactly what was claimed).\nAlternative Hypothesis (\\(H_a\\)): \\(p \\neq p_0\\) (The proportion is different than the claim).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 11: Statistical inference for one proportion"
    ]
  },
  {
    "objectID": "labs/lab11.html#part-3-running-the-test-in-r",
    "href": "labs/lab11.html#part-3-running-the-test-in-r",
    "title": "Lab 11: Statistical Inference for One Proportion",
    "section": "",
    "text": "We use the prop.test() function. You need two numbers: x (number of successes) and n (total sample size).\nScenario: A news report claims that 50% of Star Wars characters are Humans. In our dataset, we find that 35 out of 87 characters are Human. Is the report‚Äôs 50% claim accurate?\n\n# 1. Perform the test\nprop_results &lt;- prop.test(x = 35, n = 87, p = 0.50, correct = FALSE)\n\n# 2. Tidy the result into a data frame\nlibrary(broom)\ntidy_prop &lt;- tidy(prop_results)\n\n# 3. Create an accessible table with descriptive headers\nknitr::kable(\n  tidy_prop[, c(\"estimate\", \"statistic\", \"p.value\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"Sample Proportion\", \"Chi-squared\", \"p-value\", \"Lower 95% CI\", \"Upper 95% CI\"),\n  digits = 4\n)\n\n\n\nTable¬†1: One-sample proportion test results comparing the observed proportion of humans (35/87) to a null hypothesis of 0.50.\n\n\n\n\n\n\nSample Proportion\nChi-squared\np-value\nLower 95% CI\nUpper 95% CI\n\n\n\n\n0.4023\n3.3218\n0.0684\n0.3055\n0.5074\n\n\n\n\n\n\n\n\n\n\n\nX-squared: The test statistic (similar to the \\(t\\) value from Lab 10).\np-value: If this is below 0.05, we reject the claim that the true proportion is 50%.\nsample estimate: This is your \\(\\hat{p}\\) (the \\(35/87\\) from your data).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 11: Statistical inference for one proportion"
    ]
  },
  {
    "objectID": "labs/lab11.html#part-4-confidence-intervals-for-proportions",
    "href": "labs/lab11.html#part-4-confidence-intervals-for-proportions",
    "title": "Lab 11: Statistical Inference for One Proportion",
    "section": "",
    "text": "The prop.test() also gives you a 95% Confidence Interval. This tells you the range where the true population proportion likely falls.\nIf your confidence interval is (0.301, 0.508), it means we are 95% confident that the true percentage of Humans in the galaxy is between 30.1% and 50.8%.\n\n\nLab Task 11:\n\nPick a categorical variable from your dataset (e.g., Gender, Species, or Success/Failure).\nCount how many ‚Äúsuccesses‚Äù (a specific category) you have compared to the total.\nThe Test: Test a claim of your choice. (e.g., ‚ÄúIs the proportion of [category] equal to 0.25?‚Äù)\nRun prop.test() in your Quarto document.\nReport: * What was your sample proportion (\\(\\hat{p}\\))?\n\nWas your p-value significant?\nWhat is the 95% confidence interval for your proportion?",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 11: Statistical inference for one proportion"
    ]
  },
  {
    "objectID": "labs/lab11.html#accessibility-note-rounding-for-clarity",
    "href": "labs/lab11.html#accessibility-note-rounding-for-clarity",
    "title": "Lab 11: Statistical Inference for One Proportion",
    "section": "",
    "text": "When reporting proportions to a general audience, always convert decimals to percentages and round to one decimal place (e.g., \\(0.4022\\) becomes 40.2%). This makes your findings much easier to digest for readers using assistive technology.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 11: Statistical inference for one proportion"
    ]
  },
  {
    "objectID": "labs/lab12.html",
    "href": "labs/lab12.html",
    "title": "Lab 12: Statistical Inference for Two Means",
    "section": "",
    "text": "Understand the difference between Independent and Paired samples.\nState the Null (\\(H_0\\)) and Alternative (\\(H_a\\)) hypotheses for comparing two groups.\nConduct an Independent Samples t-test in R.\nVisualize the difference between groups using Boxplots.\n\n\n\n\n\nWe use an Independent Samples t-test when we want to compare the means of two distinct, unrelated groups. * Example: Do ‚ÄúHumans‚Äù have a different average height than ‚ÄúDroids‚Äù? * Example: Is the average house price in Poughkeepsie different from the average price in Fishkill?\n\n\n\n\nIn this test, we are looking at the difference between the two population means (\\(\\mu_1 - \\mu_2\\)).\n\nNull Hypothesis (\\(H_0\\)): \\(\\mu_1 = \\mu_2\\) (The means are the same; the difference is zero).\nAlternative Hypothesis (\\(H_a\\)): \\(\\mu_1 \\neq \\mu_2\\) (The means are significantly different).\n\n\n\n\n\nBefore running the math, we should always visualize the two groups side-by-side using a Boxplot.\n\nlibrary(tidyverse)\n\n# Comparing heights of Humans and Droids\ncomparison_data &lt;- starwars |&gt; \n  filter(species %in% c(\"Human\", \"Droid\")) |&gt;\n  drop_na(height)\n\nggplot(comparison_data, aes(x = species, y = height, fill = species)) +\n  geom_boxplot() +\n  scale_fill_brewer(palette = \"Set2\") + # Better color contrast for accessibility\n  labs(title = \"Height Comparison: Humans vs. Droids\",\n       x = \"Species\",\n       y = \"Height (cm)\")\n\n\n\n\n\n\n\nFigure¬†1: Comparison of height distributions between Humans and Droids.\n\n\n\n\n\n\n\n\n\nIn R, we use the ‚Äúformula‚Äù syntax: y ~ x (where y is the numeric value and x is the grouping category).\n\n# 1. Conduct the Independent Samples t-test\nt_test_results &lt;- t.test(height ~ species, data = comparison_data)\n\n# 2. Tidy the results into a data frame\nlibrary(broom)\ntidy_t_test &lt;- tidy(t_test_results)\n\n# 3. Create an accessible table with descriptive headers\nknitr::kable(\n  tidy_t_test[, c(\"estimate\", \"statistic\", \"p.value\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"Difference in Means\", \"t-statistic\", \"p-value\", \"Lower 95% CI\", \"Upper 95% CI\"),\n  digits = 3\n)\n\n\n\nTable¬†1: Independent samples t-test comparing the mean heights of Humans and Droids.\n\n\n\n\n\n\nDifference in Means\nt-statistic\np-value\nLower 95% CI\nUpper 95% CI\n\n\n\n\n-46.8\n-2.119\n0.1\n-107.658\n14.058\n\n\n\n\n\n\n\n\n\n\n\np-value: If p &lt; 0.05, we conclude that the average heights of Humans and Droids are significantly different.\n95% Confidence Interval: This gives the range of the difference between the two means. If the interval contains 0, the results are usually not significant.\n\n\n\nLab Task 12:\n\nPick a dataset that has at least one categorical variable with two groups (e.g., Male/Female, Treatment/Control, Yes/No).\nCreate a Boxplot to visually compare a numeric variable across those two groups.\nState your Null and Alternative hypotheses.\nRun the t.test() using the formula syntax.\nThe Conclusion: Report your p-value and state whether you reject or fail to reject the null hypothesis. Does the data suggest the groups are truly different?\n\n\n\n\n\n\n\nWhen using the fill = species aesthetic in your plots, remember that some students may have color vision deficiencies. Use scale_fill_viridis_d() to ensure your group comparisons are accessible to everyone.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 12: Statistical inference for two means"
    ]
  },
  {
    "objectID": "labs/lab12.html#learning-objectives",
    "href": "labs/lab12.html#learning-objectives",
    "title": "Lab 12: Statistical Inference for Two Means",
    "section": "",
    "text": "Understand the difference between Independent and Paired samples.\nState the Null (\\(H_0\\)) and Alternative (\\(H_a\\)) hypotheses for comparing two groups.\nConduct an Independent Samples t-test in R.\nVisualize the difference between groups using Boxplots.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 12: Statistical inference for two means"
    ]
  },
  {
    "objectID": "labs/lab12.html#part-1-comparing-two-independent-groups",
    "href": "labs/lab12.html#part-1-comparing-two-independent-groups",
    "title": "Lab 12: Statistical Inference for Two Means",
    "section": "",
    "text": "We use an Independent Samples t-test when we want to compare the means of two distinct, unrelated groups. * Example: Do ‚ÄúHumans‚Äù have a different average height than ‚ÄúDroids‚Äù? * Example: Is the average house price in Poughkeepsie different from the average price in Fishkill?",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 12: Statistical inference for two means"
    ]
  },
  {
    "objectID": "labs/lab12.html#part-2-hypotheses-for-two-means",
    "href": "labs/lab12.html#part-2-hypotheses-for-two-means",
    "title": "Lab 12: Statistical Inference for Two Means",
    "section": "",
    "text": "In this test, we are looking at the difference between the two population means (\\(\\mu_1 - \\mu_2\\)).\n\nNull Hypothesis (\\(H_0\\)): \\(\\mu_1 = \\mu_2\\) (The means are the same; the difference is zero).\nAlternative Hypothesis (\\(H_a\\)): \\(\\mu_1 \\neq \\mu_2\\) (The means are significantly different).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 12: Statistical inference for two means"
    ]
  },
  {
    "objectID": "labs/lab12.html#part-3-visualizing-the-comparison",
    "href": "labs/lab12.html#part-3-visualizing-the-comparison",
    "title": "Lab 12: Statistical Inference for Two Means",
    "section": "",
    "text": "Before running the math, we should always visualize the two groups side-by-side using a Boxplot.\n\nlibrary(tidyverse)\n\n# Comparing heights of Humans and Droids\ncomparison_data &lt;- starwars |&gt; \n  filter(species %in% c(\"Human\", \"Droid\")) |&gt;\n  drop_na(height)\n\nggplot(comparison_data, aes(x = species, y = height, fill = species)) +\n  geom_boxplot() +\n  scale_fill_brewer(palette = \"Set2\") + # Better color contrast for accessibility\n  labs(title = \"Height Comparison: Humans vs. Droids\",\n       x = \"Species\",\n       y = \"Height (cm)\")\n\n\n\n\n\n\n\nFigure¬†1: Comparison of height distributions between Humans and Droids.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 12: Statistical inference for two means"
    ]
  },
  {
    "objectID": "labs/lab12.html#part-4-running-the-t-test-in-r",
    "href": "labs/lab12.html#part-4-running-the-t-test-in-r",
    "title": "Lab 12: Statistical Inference for Two Means",
    "section": "",
    "text": "In R, we use the ‚Äúformula‚Äù syntax: y ~ x (where y is the numeric value and x is the grouping category).\n\n# 1. Conduct the Independent Samples t-test\nt_test_results &lt;- t.test(height ~ species, data = comparison_data)\n\n# 2. Tidy the results into a data frame\nlibrary(broom)\ntidy_t_test &lt;- tidy(t_test_results)\n\n# 3. Create an accessible table with descriptive headers\nknitr::kable(\n  tidy_t_test[, c(\"estimate\", \"statistic\", \"p.value\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"Difference in Means\", \"t-statistic\", \"p-value\", \"Lower 95% CI\", \"Upper 95% CI\"),\n  digits = 3\n)\n\n\n\nTable¬†1: Independent samples t-test comparing the mean heights of Humans and Droids.\n\n\n\n\n\n\nDifference in Means\nt-statistic\np-value\nLower 95% CI\nUpper 95% CI\n\n\n\n\n-46.8\n-2.119\n0.1\n-107.658\n14.058\n\n\n\n\n\n\n\n\n\n\n\np-value: If p &lt; 0.05, we conclude that the average heights of Humans and Droids are significantly different.\n95% Confidence Interval: This gives the range of the difference between the two means. If the interval contains 0, the results are usually not significant.\n\n\n\nLab Task 12:\n\nPick a dataset that has at least one categorical variable with two groups (e.g., Male/Female, Treatment/Control, Yes/No).\nCreate a Boxplot to visually compare a numeric variable across those two groups.\nState your Null and Alternative hypotheses.\nRun the t.test() using the formula syntax.\nThe Conclusion: Report your p-value and state whether you reject or fail to reject the null hypothesis. Does the data suggest the groups are truly different?",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 12: Statistical inference for two means"
    ]
  },
  {
    "objectID": "labs/lab12.html#accessibility-tip-high-contrast-visuals",
    "href": "labs/lab12.html#accessibility-tip-high-contrast-visuals",
    "title": "Lab 12: Statistical Inference for Two Means",
    "section": "",
    "text": "When using the fill = species aesthetic in your plots, remember that some students may have color vision deficiencies. Use scale_fill_viridis_d() to ensure your group comparisons are accessible to everyone.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 12: Statistical inference for two means"
    ]
  },
  {
    "objectID": "labs/lab13.html",
    "href": "labs/lab13.html",
    "title": "Lab 13: Statistical Inference for Two Proportions",
    "section": "",
    "text": "Compare the ‚Äúsuccess rates‚Äù or percentages of two independent groups.\nState the Null (\\(H_0\\)) and Alternative (\\(H_a\\)) hypotheses for differences in proportions.\nUse the prop.test() function in R for two-sample comparisons.\nCreate a Stacked Bar Chart to visualize the relative differences between groups.\n\n\n\n\n\nIn Lab 11, we looked at one proportion. In the real world, we usually want to compare two. For example: * Does Group A have a higher graduation rate than Group B? * Is a medicine more effective in the treatment group than the control group?\n\n\n\n\nWe are testing the difference between two population proportions (\\(p_1 - p_2\\)).\n\nNull Hypothesis (\\(H_0\\)): \\(p_1 = p_2\\) (There is no difference between the groups).\nAlternative Hypothesis (\\(H_a\\)): \\(p_1 \\neq p_2\\) (The groups have significantly different proportions).\n\n\n\n\n\nWhen comparing proportions, a standard bar chart can be misleading if the group sizes are different. We use position = \"fill\" to show the percentage (0 to 100%) rather than the raw count.\nlibrary(tidyverse)\n\n# Comparing 'Success' across two different categories\nggplot(my_data, aes(x = group_variable, fill = success_variable)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Proportional Comparison of Success by Group\",\n       y = \"Proportion (0 to 1)\",\n       x = \"Group Name\")\n\nlibrary(tidyverse)\n\n# Creating a simplified category: Tatooine vs Other\nstarwars_props &lt;- starwars |&gt;\n  filter(!is.na(gender)) |&gt;\n  mutate(location = if_else(homeworld == \"Tatooine\", \"Tatooine\", \"Other\"))\n\nggplot(starwars_props, aes(x = location, fill = gender)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_viridis_d(option = \"mako\") + # High contrast, color-blind friendly palette\n  labs(title = \"Gender Proportions: Tatooine vs. Other Worlds\",\n       subtitle = \"Standardized to 100% using position = 'fill'\",\n       x = \"Homeworld Category\",\n       y = \"Proportion\",\n       fill = \"Gender\")\n\n\n\n\n\n\n\nFigure¬†1: Stacked bar chart showing the proportion of gender identities for characters from Tatooine versus other homeworlds.\n\n\n\n\n\n\n\n\n\nIn R, we provide the ‚Äúsuccesses‚Äù and the ‚Äútotals‚Äù as vectors within the prop.test() function.\nScenario: * Group 1: 45 people out of 100 succeeded. * Group 2: 30 people out of 100 succeeded.\n\n# 1. Perform the test\n# x = number of successes (45 and 30)\n# n = total sample sizes (100 and 100)\nresults &lt;- prop.test(x = c(45, 30), n = c(100, 100), correct = FALSE)\n\n# 2. Tidy the results into a data frame\nlibrary(broom)\ntidy_prop_two &lt;- tidy(results)\n\n# 3. Create an accessible table with descriptive headers\n# Note: 'estimate' in a two-sample test contains the proportions for both groups\nknitr::kable(\n  tidy_prop_two[, c(\"statistic\", \"p.value\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"Chi-squared\", \"p-value\", \"Lower 95% CI\", \"Upper 95% CI\"),\n  digits = 4\n)\n\n\n\nTable¬†1: Two-sample proportion test comparing Group 1 (45/100) and Group 2 (30/100).\n\n\n\n\n\n\nChi-squared\np-value\nLower 95% CI\nUpper 95% CI\n\n\n\n\n4.8\n0.0285\n0.0174\n0.2826\n\n\n\n\n\n\n\n\n\n\n\n\n\np-value: If the p-value is less than 0.05, we conclude the difference is ‚ÄúStatistically Significant.‚Äù\nSample Estimates: R will show you the individual proportions (\\(\\hat{p}_1\\) and \\(\\hat{p}_2\\)).\nConfidence Interval: This interval estimates the true difference between the two population percentages.\n\n\n\nLab Task 13:\n\nOpen your Quarto document for Lab 13.\nChoose two groups from your data and a binary ‚Äúsuccess‚Äù outcome (e.g., ‚ÄúPass/Fail‚Äù or ‚ÄúYes/No‚Äù).\nCreate a Stacked Bar Chart using position = \"fill\".\nRun prop.test() to compare the two groups.\nConclusion: State your p-value and write a one-sentence conclusion. ‚ÄúWe [reject/fail to reject] the null hypothesis and conclude there is [a/no] significant difference in the proportions.‚Äù\n\n\n\n\n\n\nWhen creating stacked bar charts, rely on more than just color. Using high-contrast palettes like scale_fill_brewer(palette = \"Set1\") helps students with color blindness distinguish between the ‚ÄúSuccess‚Äù and ‚ÄúFailure‚Äù sections of your bars.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 13: Statistical inference for two proportions"
    ]
  },
  {
    "objectID": "labs/lab13.html#learning-objectives",
    "href": "labs/lab13.html#learning-objectives",
    "title": "Lab 13: Statistical Inference for Two Proportions",
    "section": "",
    "text": "Compare the ‚Äúsuccess rates‚Äù or percentages of two independent groups.\nState the Null (\\(H_0\\)) and Alternative (\\(H_a\\)) hypotheses for differences in proportions.\nUse the prop.test() function in R for two-sample comparisons.\nCreate a Stacked Bar Chart to visualize the relative differences between groups.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 13: Statistical inference for two proportions"
    ]
  },
  {
    "objectID": "labs/lab13.html#introduction",
    "href": "labs/lab13.html#introduction",
    "title": "Lab 13: Statistical Inference for Two Proportions",
    "section": "",
    "text": "In Lab 11, we looked at one proportion. In the real world, we usually want to compare two. For example: * Does Group A have a higher graduation rate than Group B? * Is a medicine more effective in the treatment group than the control group?",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 13: Statistical inference for two proportions"
    ]
  },
  {
    "objectID": "labs/lab13.html#part-1-hypotheses-for-two-proportions",
    "href": "labs/lab13.html#part-1-hypotheses-for-two-proportions",
    "title": "Lab 13: Statistical Inference for Two Proportions",
    "section": "",
    "text": "We are testing the difference between two population proportions (\\(p_1 - p_2\\)).\n\nNull Hypothesis (\\(H_0\\)): \\(p_1 = p_2\\) (There is no difference between the groups).\nAlternative Hypothesis (\\(H_a\\)): \\(p_1 \\neq p_2\\) (The groups have significantly different proportions).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 13: Statistical inference for two proportions"
    ]
  },
  {
    "objectID": "labs/lab13.html#part-2-visualizing-with-stacked-bar-charts",
    "href": "labs/lab13.html#part-2-visualizing-with-stacked-bar-charts",
    "title": "Lab 13: Statistical Inference for Two Proportions",
    "section": "",
    "text": "When comparing proportions, a standard bar chart can be misleading if the group sizes are different. We use position = \"fill\" to show the percentage (0 to 100%) rather than the raw count.\nlibrary(tidyverse)\n\n# Comparing 'Success' across two different categories\nggplot(my_data, aes(x = group_variable, fill = success_variable)) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Proportional Comparison of Success by Group\",\n       y = \"Proportion (0 to 1)\",\n       x = \"Group Name\")\n\nlibrary(tidyverse)\n\n# Creating a simplified category: Tatooine vs Other\nstarwars_props &lt;- starwars |&gt;\n  filter(!is.na(gender)) |&gt;\n  mutate(location = if_else(homeworld == \"Tatooine\", \"Tatooine\", \"Other\"))\n\nggplot(starwars_props, aes(x = location, fill = gender)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_viridis_d(option = \"mako\") + # High contrast, color-blind friendly palette\n  labs(title = \"Gender Proportions: Tatooine vs. Other Worlds\",\n       subtitle = \"Standardized to 100% using position = 'fill'\",\n       x = \"Homeworld Category\",\n       y = \"Proportion\",\n       fill = \"Gender\")\n\n\n\n\n\n\n\nFigure¬†1: Stacked bar chart showing the proportion of gender identities for characters from Tatooine versus other homeworlds.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 13: Statistical inference for two proportions"
    ]
  },
  {
    "objectID": "labs/lab13.html#part-3-running-the-two-sample-prop-test",
    "href": "labs/lab13.html#part-3-running-the-two-sample-prop-test",
    "title": "Lab 13: Statistical Inference for Two Proportions",
    "section": "",
    "text": "In R, we provide the ‚Äúsuccesses‚Äù and the ‚Äútotals‚Äù as vectors within the prop.test() function.\nScenario: * Group 1: 45 people out of 100 succeeded. * Group 2: 30 people out of 100 succeeded.\n\n# 1. Perform the test\n# x = number of successes (45 and 30)\n# n = total sample sizes (100 and 100)\nresults &lt;- prop.test(x = c(45, 30), n = c(100, 100), correct = FALSE)\n\n# 2. Tidy the results into a data frame\nlibrary(broom)\ntidy_prop_two &lt;- tidy(results)\n\n# 3. Create an accessible table with descriptive headers\n# Note: 'estimate' in a two-sample test contains the proportions for both groups\nknitr::kable(\n  tidy_prop_two[, c(\"statistic\", \"p.value\", \"conf.low\", \"conf.high\")],\n  col.names = c(\"Chi-squared\", \"p-value\", \"Lower 95% CI\", \"Upper 95% CI\"),\n  digits = 4\n)\n\n\n\nTable¬†1: Two-sample proportion test comparing Group 1 (45/100) and Group 2 (30/100).\n\n\n\n\n\n\nChi-squared\np-value\nLower 95% CI\nUpper 95% CI\n\n\n\n\n4.8\n0.0285\n0.0174\n0.2826",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 13: Statistical inference for two proportions"
    ]
  },
  {
    "objectID": "labs/lab13.html#part-4-interpreting-the-results",
    "href": "labs/lab13.html#part-4-interpreting-the-results",
    "title": "Lab 13: Statistical Inference for Two Proportions",
    "section": "",
    "text": "p-value: If the p-value is less than 0.05, we conclude the difference is ‚ÄúStatistically Significant.‚Äù\nSample Estimates: R will show you the individual proportions (\\(\\hat{p}_1\\) and \\(\\hat{p}_2\\)).\nConfidence Interval: This interval estimates the true difference between the two population percentages.\n\n\n\nLab Task 13:\n\nOpen your Quarto document for Lab 13.\nChoose two groups from your data and a binary ‚Äúsuccess‚Äù outcome (e.g., ‚ÄúPass/Fail‚Äù or ‚ÄúYes/No‚Äù).\nCreate a Stacked Bar Chart using position = \"fill\".\nRun prop.test() to compare the two groups.\nConclusion: State your p-value and write a one-sentence conclusion. ‚ÄúWe [reject/fail to reject] the null hypothesis and conclude there is [a/no] significant difference in the proportions.‚Äù",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 13: Statistical inference for two proportions"
    ]
  },
  {
    "objectID": "labs/lab13.html#accessibility-tip-color-and-texture",
    "href": "labs/lab13.html#accessibility-tip-color-and-texture",
    "title": "Lab 13: Statistical Inference for Two Proportions",
    "section": "",
    "text": "When creating stacked bar charts, rely on more than just color. Using high-contrast palettes like scale_fill_brewer(palette = \"Set1\") helps students with color blindness distinguish between the ‚ÄúSuccess‚Äù and ‚ÄúFailure‚Äù sections of your bars.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 13: Statistical inference for two proportions"
    ]
  },
  {
    "objectID": "labs/lab14.html",
    "href": "labs/lab14.html",
    "title": "Lab 14: Bootstrapping and Resampling",
    "section": "",
    "text": "Understand the concept of Sampling with Replacement.\nUse the infer package to create a bootstrap distribution.\nEstimate a Confidence Interval without assuming the data is ‚ÄúNormal.‚Äù\nCompare Bootstrap results to traditional T-test results.\n\n\n\n\n\nWhat if your data is skewed, or you have a very small sample size? Traditional math might fail you. Bootstrapping solves this by treating your sample like a ‚Äúmini-population.‚Äù We take thousands of samples from our own data to see how much the mean varies.\n\n\n\n\nIn R, the infer package makes the logic of bootstrapping very clear. We follow four steps: specify, generate, calculate, and visualize.\n\n# Install and load the infer package\nif(!require(infer)) install.packages(\"infer\")\nlibrary(tidyverse)\nlibrary(infer)\n\n# Let's bootstrap the mean height of Star Wars characters\nboot_dist &lt;- starwars |&gt;\n  drop_na(height) |&gt;\n  specify(response = height) |&gt;              # 1. What variable?\n  generate(reps = 1000, type = \"bootstrap\") |&gt; # 2. Resample 1000 times\n  calculate(stat = \"mean\")                   # 3. Find the mean each time\n\n#| label: tbl-boot-head\n#| tbl-cap: \"The first six rows of the bootstrap distribution, showing the calculated mean for each simulation replicate.\"\n\nhead(boot_dist) |&gt;\n  knitr::kable()\n\n\n\n\nreplicate\nstat\n\n\n\n\n1\n173.9012\n\n\n2\n174.7778\n\n\n3\n174.3210\n\n\n4\n177.0000\n\n\n5\n179.7778\n\n\n6\n172.1111\n\n\n\n\n\n\n\n\n\nInstead of a theoretical curve, we look at the actual distribution of our 1,000 ‚Äúfake‚Äù means.\n\nvisualize(boot_dist) +\n  labs(title = \"Bootstrap Distribution of the Mean\",\n       x = \"Sample Mean Height (cm)\", \n       y = \"Count\")\n\n\n\n\n\n\n\nFigure¬†1: Bootstrap distribution of mean heights for Star Wars characters based on 1,000 resamples.\n\n\n\n\n\n\n\n\n\nTo find a 95% Confidence Interval, we simply look at where the middle 95% of our 1,000 bootstrap means fall.\n\n# 1. Calculate the interval\npercentile_ci &lt;- boot_dist |&gt;\n  get_confidence_interval(level = 0.95, type = \"percentile\")\n\n# 2. Present as an accessible table\nknitr::kable(\n  percentile_ci,\n  col.names = c(\"Lower Bound (2.5%)\", \"Upper Bound (97.5%)\"),\n  digits = 2\n)\n\n\n\nTable¬†1: 95% Confidence Interval for mean height using the Percentile Method (1,000 bootstrap replicates).\n\n\n\n\n\n\nLower Bound (2.5%)\nUpper Bound (97.5%)\n\n\n\n\n166.97\n181.97\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo ‚ÄúNormality‚Äù Required: It works even if your data is weirdly shaped.\nAny Statistic: You can bootstrap the mean, the median, the standard deviation, or even the correlation coefficient.\nVisual Logic: It helps you see the uncertainty in your estimate.\n\n\n\nLab Task 14:\n\nPick a numeric variable from your dataset.\nCreate a histogram of the original data. (Is it skewed?)\nRun the infer code above to generate 1,000 bootstrap reps for the Median instead of the mean (stat = \"median\").\nVisualize the bootstrap distribution.\nCalculate the 95% Confidence Interval.\nReflection: In your Quarto document, explain in your own words why we ‚Äúsample with replacement‚Äù during bootstrapping.\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 14: Bootstrapping"
    ]
  },
  {
    "objectID": "labs/lab14.html#learning-objectives",
    "href": "labs/lab14.html#learning-objectives",
    "title": "Lab 14: Bootstrapping and Resampling",
    "section": "",
    "text": "Understand the concept of Sampling with Replacement.\nUse the infer package to create a bootstrap distribution.\nEstimate a Confidence Interval without assuming the data is ‚ÄúNormal.‚Äù\nCompare Bootstrap results to traditional T-test results.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 14: Bootstrapping"
    ]
  },
  {
    "objectID": "labs/lab14.html#introduction-pulling-yourself-up-by-your-boots",
    "href": "labs/lab14.html#introduction-pulling-yourself-up-by-your-boots",
    "title": "Lab 14: Bootstrapping and Resampling",
    "section": "",
    "text": "What if your data is skewed, or you have a very small sample size? Traditional math might fail you. Bootstrapping solves this by treating your sample like a ‚Äúmini-population.‚Äù We take thousands of samples from our own data to see how much the mean varies.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 14: Bootstrapping"
    ]
  },
  {
    "objectID": "labs/lab14.html#part-1-the-infer-package",
    "href": "labs/lab14.html#part-1-the-infer-package",
    "title": "Lab 14: Bootstrapping and Resampling",
    "section": "",
    "text": "In R, the infer package makes the logic of bootstrapping very clear. We follow four steps: specify, generate, calculate, and visualize.\n\n# Install and load the infer package\nif(!require(infer)) install.packages(\"infer\")\nlibrary(tidyverse)\nlibrary(infer)\n\n# Let's bootstrap the mean height of Star Wars characters\nboot_dist &lt;- starwars |&gt;\n  drop_na(height) |&gt;\n  specify(response = height) |&gt;              # 1. What variable?\n  generate(reps = 1000, type = \"bootstrap\") |&gt; # 2. Resample 1000 times\n  calculate(stat = \"mean\")                   # 3. Find the mean each time\n\n#| label: tbl-boot-head\n#| tbl-cap: \"The first six rows of the bootstrap distribution, showing the calculated mean for each simulation replicate.\"\n\nhead(boot_dist) |&gt;\n  knitr::kable()\n\n\n\n\nreplicate\nstat\n\n\n\n\n1\n173.9012\n\n\n2\n174.7778\n\n\n3\n174.3210\n\n\n4\n177.0000\n\n\n5\n179.7778\n\n\n6\n172.1111",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 14: Bootstrapping"
    ]
  },
  {
    "objectID": "labs/lab14.html#part-2-visualizing-the-bootstrap-distribution",
    "href": "labs/lab14.html#part-2-visualizing-the-bootstrap-distribution",
    "title": "Lab 14: Bootstrapping and Resampling",
    "section": "",
    "text": "Instead of a theoretical curve, we look at the actual distribution of our 1,000 ‚Äúfake‚Äù means.\n\nvisualize(boot_dist) +\n  labs(title = \"Bootstrap Distribution of the Mean\",\n       x = \"Sample Mean Height (cm)\", \n       y = \"Count\")\n\n\n\n\n\n\n\nFigure¬†1: Bootstrap distribution of mean heights for Star Wars characters based on 1,000 resamples.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 14: Bootstrapping"
    ]
  },
  {
    "objectID": "labs/lab14.html#part-3-the-percentile-method",
    "href": "labs/lab14.html#part-3-the-percentile-method",
    "title": "Lab 14: Bootstrapping and Resampling",
    "section": "",
    "text": "To find a 95% Confidence Interval, we simply look at where the middle 95% of our 1,000 bootstrap means fall.\n\n# 1. Calculate the interval\npercentile_ci &lt;- boot_dist |&gt;\n  get_confidence_interval(level = 0.95, type = \"percentile\")\n\n# 2. Present as an accessible table\nknitr::kable(\n  percentile_ci,\n  col.names = c(\"Lower Bound (2.5%)\", \"Upper Bound (97.5%)\"),\n  digits = 2\n)\n\n\n\nTable¬†1: 95% Confidence Interval for mean height using the Percentile Method (1,000 bootstrap replicates).\n\n\n\n\n\n\nLower Bound (2.5%)\nUpper Bound (97.5%)\n\n\n\n\n166.97\n181.97",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 14: Bootstrapping"
    ]
  },
  {
    "objectID": "labs/lab14.html#part-4-why-use-bootstrapping",
    "href": "labs/lab14.html#part-4-why-use-bootstrapping",
    "title": "Lab 14: Bootstrapping and Resampling",
    "section": "",
    "text": "No ‚ÄúNormality‚Äù Required: It works even if your data is weirdly shaped.\nAny Statistic: You can bootstrap the mean, the median, the standard deviation, or even the correlation coefficient.\nVisual Logic: It helps you see the uncertainty in your estimate.\n\n\n\nLab Task 14:\n\nPick a numeric variable from your dataset.\nCreate a histogram of the original data. (Is it skewed?)\nRun the infer code above to generate 1,000 bootstrap reps for the Median instead of the mean (stat = \"median\").\nVisualize the bootstrap distribution.\nCalculate the 95% Confidence Interval.\nReflection: In your Quarto document, explain in your own words why we ‚Äúsample with replacement‚Äù during bootstrapping.\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 14: Bootstrapping"
    ]
  },
  {
    "objectID": "labs/lab15.html",
    "href": "labs/lab15.html",
    "title": "Lab 15: Non-parametric Methods for Hypothesis Testing",
    "section": "",
    "text": "Identify when to use Non-parametric tests instead of Parametric tests.\nConduct a Wilcoxon Rank-Sum Test (Mann-Whitney U).\nConduct a Wilcoxon Signed-Rank Test for paired data.\nUnderstand how ‚ÄúRanking‚Äù data removes the influence of extreme outliers.\n\n\n\n\n\n‚ÄúParametric‚Äù tests (like the t-test) assume your data follows a specific distribution (the Normal Distribution). Non-parametric tests make no such assumption. They are often called ‚ÄúDistribution-Free‚Äù tests.\n\n\n\nYour sample size is very small (n &lt; 30).\nYour data is heavily skewed and cannot be fixed.\nYou have major outliers that you cannot remove.\nYour data is Ordinal (e.g., Likert scales: ‚ÄúSatisfied‚Äù, ‚ÄúNeutral‚Äù, ‚ÄúDissatisfied‚Äù).\n\n\n\n\n\n\nThis is the non-parametric alternative to the Independent Samples t-test (Lab 12). Instead of comparing means, it compares the medians by ranking all the data points from smallest to largest.\nScenario: Are the ‚ÄúMass‚Äù values of Droids and Humans different? (Mass is often heavily skewed by outliers like Jabba the Hutt). ## Wilcoxon Rank-Sum Test: Mass by Species\nThis test compares the distribution of mass between Humans and Droids. We use this non-parametric test because mass in the Star Wars universe is often skewed by very heavy characters (like Jabba the Hutt).\n\nAccessible Logic: The Wilcoxon test doesn‚Äôt compare means; it compares the ranks of the data. If one species tends to have higher ranks than the other, the test will return a significant result.\n\n\nlibrary(tidyverse)\nlibrary(broom)\n\n# 1. Filter and clean the data\ncomparison_data &lt;- starwars |&gt; \n  filter(species %in% c(\"Human\", \"Droid\")) |&gt;\n  drop_na(mass)\n\n# 2. Run the test and save the results\nwilcox_results &lt;- wilcox.test(mass ~ species, data = comparison_data)\n\n# 3. Convert results into an accessible table\ntidy_wilcox &lt;- tidy(wilcox_results)\n\nknitr::kable(\n  tidy_wilcox[, c(\"statistic\", \"p.value\", \"method\")],\n  col.names = c(\"W Statistic\", \"p-value\", \"Test Method\"),\n  digits = 4\n)\n\n\n\nTable¬†1: Results of the Wilcoxon Rank-Sum Test comparing mass between Humans and Droids.\n\n\n\n\n\n\n\n\n\n\n\nW Statistic\np-value\nTest Method\n\n\n\n\n23\n0.1989\nWilcoxon rank sum test with continuity correction\n\n\n\n\n\n\n\n\n\n\n\n\nThis is the non-parametric alternative to the Paired t-test. Use this when you have ‚ÄúBefore‚Äù and ‚ÄúAfter‚Äù measurements on the same subjects, but the differences are not normally distributed.\n# Example syntax for paired data\n# wilcox.test(before_scores, after_scores, paired = TRUE)\n\n# Creating mock 'before' and 'after' data for the example\nbefore &lt;- c(80, 75, 90, 85)\nafter  &lt;- c(82, 78, 88, 90)\n\ntidy_paired &lt;- broom::tidy(wilcox.test(before, after, paired = TRUE))\n\nknitr::kable(\n  tidy_paired[, c(\"statistic\", \"p.value\", \"method\")],\n  col.names = c(\"V Statistic\", \"p-value\", \"Test Method\"),\n  digits = 4\n)\n\n\n\nTable¬†2: Paired Wilcoxon Signed-Rank Test results for character performance.\n\n\n\n\n\n\n\n\n\n\n\nV Statistic\np-value\nTest Method\n\n\n\n\n1.5\n0.2693\nWilcoxon signed rank test with continuity correction\n\n\n\n\n\n\n\n\n\n\n\n\nWhile non-parametric tests are safer for ‚Äúmessy‚Äù data, they are slightly less powerful than parametric tests when the data is actually normal. This means they are less likely to find a significant difference if one actually exists.\n\n\nLab Task 15:\n\nPick a numeric variable from your dataset that looks very skewed (not bell-shaped).\nCreate a Boxplot of this variable grouped by a category.\nRun a wilcox.test() to compare the two groups.\nRun a standard t.test() on the same data.\nCompare: In your Quarto document, compare the p-values. Are they similar? Which test do you trust more for this specific data, and why?\n\n\n\n\n\n\nIf you are presenting data to a stakeholder and you are worried about one or two ‚Äúcrazy‚Äù outliers ruining your average, the Wilcoxon test is your best friend. It treats the outlier as just ‚Äúthe highest rank,‚Äù preventing it from pulling the results in its direction.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 15: Non-parametric methods"
    ]
  },
  {
    "objectID": "labs/lab15.html#learning-objectives",
    "href": "labs/lab15.html#learning-objectives",
    "title": "Lab 15: Non-parametric Methods for Hypothesis Testing",
    "section": "",
    "text": "Identify when to use Non-parametric tests instead of Parametric tests.\nConduct a Wilcoxon Rank-Sum Test (Mann-Whitney U).\nConduct a Wilcoxon Signed-Rank Test for paired data.\nUnderstand how ‚ÄúRanking‚Äù data removes the influence of extreme outliers.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 15: Non-parametric methods"
    ]
  },
  {
    "objectID": "labs/lab15.html#part-1-parametric-vs.-non-parametric",
    "href": "labs/lab15.html#part-1-parametric-vs.-non-parametric",
    "title": "Lab 15: Non-parametric Methods for Hypothesis Testing",
    "section": "",
    "text": "‚ÄúParametric‚Äù tests (like the t-test) assume your data follows a specific distribution (the Normal Distribution). Non-parametric tests make no such assumption. They are often called ‚ÄúDistribution-Free‚Äù tests.\n\n\n\nYour sample size is very small (n &lt; 30).\nYour data is heavily skewed and cannot be fixed.\nYou have major outliers that you cannot remove.\nYour data is Ordinal (e.g., Likert scales: ‚ÄúSatisfied‚Äù, ‚ÄúNeutral‚Äù, ‚ÄúDissatisfied‚Äù).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 15: Non-parametric methods"
    ]
  },
  {
    "objectID": "labs/lab15.html#part-2-the-wilcoxon-rank-sum-test",
    "href": "labs/lab15.html#part-2-the-wilcoxon-rank-sum-test",
    "title": "Lab 15: Non-parametric Methods for Hypothesis Testing",
    "section": "",
    "text": "This is the non-parametric alternative to the Independent Samples t-test (Lab 12). Instead of comparing means, it compares the medians by ranking all the data points from smallest to largest.\nScenario: Are the ‚ÄúMass‚Äù values of Droids and Humans different? (Mass is often heavily skewed by outliers like Jabba the Hutt). ## Wilcoxon Rank-Sum Test: Mass by Species\nThis test compares the distribution of mass between Humans and Droids. We use this non-parametric test because mass in the Star Wars universe is often skewed by very heavy characters (like Jabba the Hutt).\n\nAccessible Logic: The Wilcoxon test doesn‚Äôt compare means; it compares the ranks of the data. If one species tends to have higher ranks than the other, the test will return a significant result.\n\n\nlibrary(tidyverse)\nlibrary(broom)\n\n# 1. Filter and clean the data\ncomparison_data &lt;- starwars |&gt; \n  filter(species %in% c(\"Human\", \"Droid\")) |&gt;\n  drop_na(mass)\n\n# 2. Run the test and save the results\nwilcox_results &lt;- wilcox.test(mass ~ species, data = comparison_data)\n\n# 3. Convert results into an accessible table\ntidy_wilcox &lt;- tidy(wilcox_results)\n\nknitr::kable(\n  tidy_wilcox[, c(\"statistic\", \"p.value\", \"method\")],\n  col.names = c(\"W Statistic\", \"p-value\", \"Test Method\"),\n  digits = 4\n)\n\n\n\nTable¬†1: Results of the Wilcoxon Rank-Sum Test comparing mass between Humans and Droids.\n\n\n\n\n\n\n\n\n\n\n\nW Statistic\np-value\nTest Method\n\n\n\n\n23\n0.1989\nWilcoxon rank sum test with continuity correction",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 15: Non-parametric methods"
    ]
  },
  {
    "objectID": "labs/lab15.html#part-3-the-wilcoxon-signed-rank-test",
    "href": "labs/lab15.html#part-3-the-wilcoxon-signed-rank-test",
    "title": "Lab 15: Non-parametric Methods for Hypothesis Testing",
    "section": "",
    "text": "This is the non-parametric alternative to the Paired t-test. Use this when you have ‚ÄúBefore‚Äù and ‚ÄúAfter‚Äù measurements on the same subjects, but the differences are not normally distributed.\n# Example syntax for paired data\n# wilcox.test(before_scores, after_scores, paired = TRUE)\n\n# Creating mock 'before' and 'after' data for the example\nbefore &lt;- c(80, 75, 90, 85)\nafter  &lt;- c(82, 78, 88, 90)\n\ntidy_paired &lt;- broom::tidy(wilcox.test(before, after, paired = TRUE))\n\nknitr::kable(\n  tidy_paired[, c(\"statistic\", \"p.value\", \"method\")],\n  col.names = c(\"V Statistic\", \"p-value\", \"Test Method\"),\n  digits = 4\n)\n\n\n\nTable¬†2: Paired Wilcoxon Signed-Rank Test results for character performance.\n\n\n\n\n\n\n\n\n\n\n\nV Statistic\np-value\nTest Method\n\n\n\n\n1.5\n0.2693\nWilcoxon signed rank test with continuity correction",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 15: Non-parametric methods"
    ]
  },
  {
    "objectID": "labs/lab15.html#part-4-the-trade-off",
    "href": "labs/lab15.html#part-4-the-trade-off",
    "title": "Lab 15: Non-parametric Methods for Hypothesis Testing",
    "section": "",
    "text": "While non-parametric tests are safer for ‚Äúmessy‚Äù data, they are slightly less powerful than parametric tests when the data is actually normal. This means they are less likely to find a significant difference if one actually exists.\n\n\nLab Task 15:\n\nPick a numeric variable from your dataset that looks very skewed (not bell-shaped).\nCreate a Boxplot of this variable grouped by a category.\nRun a wilcox.test() to compare the two groups.\nRun a standard t.test() on the same data.\nCompare: In your Quarto document, compare the p-values. Are they similar? Which test do you trust more for this specific data, and why?",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 15: Non-parametric methods"
    ]
  },
  {
    "objectID": "labs/lab15.html#pro-tip-when-in-doubt-rank-it-out",
    "href": "labs/lab15.html#pro-tip-when-in-doubt-rank-it-out",
    "title": "Lab 15: Non-parametric Methods for Hypothesis Testing",
    "section": "",
    "text": "If you are presenting data to a stakeholder and you are worried about one or two ‚Äúcrazy‚Äù outliers ruining your average, the Wilcoxon test is your best friend. It treats the outlier as just ‚Äúthe highest rank,‚Äù preventing it from pulling the results in its direction.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 15: Non-parametric methods"
    ]
  },
  {
    "objectID": "labs/lab16.html",
    "href": "labs/lab16.html",
    "title": "Lab 16: Analysis of Variance (ANOVA)",
    "section": "",
    "text": "Understand when to use ANOVA instead of multiple t-tests.\nState the Null (\\(H_0\\)) and Alternative (\\(H_a\\)) hypotheses for multiple groups.\nConduct a One-Way ANOVA in R.\nPerform Post-hoc testing (Tukey‚Äôs HSD) to find exactly where differences lie.\n\n\n\n\n\nIf you have three groups (e.g., Freshman, Sophomores, Juniors) and you want to compare their average GPA, you could run three separate t-tests. However, every time you run a test, there is a 5% chance of being wrong. By the third test, your error rate has ballooned!\nANOVA tests all groups at once, keeping our error rate at 5%.\n\nNull Hypothesis (\\(H_0\\)): All group means are equal (\\(\\mu_1 = \\mu_2 = \\mu_3\\)).\nAlternative Hypothesis (\\(H_a\\)): At least one group mean is different.\n\n\n\n\n\nWith ANOVA, side-by-side boxplots are essential. They allow us to see if the ‚Äúspread‚Äù within groups is smaller than the ‚Äúdistance‚Äù between groups.\n\nlibrary(tidyverse)\n\n# Filter for the most common eye colors to avoid a cluttered plot\neye_data &lt;- starwars |&gt; \n  filter(eye_color %in% c(\"blue\", \"brown\", \"yellow\", \"orange\")) |&gt;\n  drop_na(height)\n\nggplot(eye_data, aes(x = eye_color, y = height, fill = eye_color)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_viridis_d() + # High contrast, color-blind safe palette\n  theme_minimal() +\n  labs(title = \"Height Distribution by Eye Color\",\n       x = \"Eye Color\",\n       y = \"Height (cm)\",\n       fill = \"Eye Color\")\n\n\n\n\n\n\n\nFigure¬†1: Distribution of heights across characters with blue, brown, yellow, and orange eyes.\n\n\n\n\n\n\n\n\n\nWe use the aov() function. Like the t-test, we use the formula numeric_variable ~ categorical_variable.\n\nlibrary(broom)\n\n# 1. Fit the ANOVA model\nmodel &lt;- aov(height ~ eye_color, data = eye_data)\n\n# 2. Tidy the results into an accessible table\ntidy_anova &lt;- tidy(model)\n\n# 3. Create a clean table with descriptive headers\nknitr::kable(\n  tidy_anova,\n  col.names = c(\"Term\", \"Degrees of Freedom\", \"Sum of Squares\", \"Mean Square\", \"F-statistic\", \"p-value\"),\n  digits = 3\n)\n\n\n\nTable¬†1: One-way ANOVA results comparing mean heights across eye color groups.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nDegrees of Freedom\nSum of Squares\nMean Square\nF-statistic\np-value\n\n\n\n\neye_color\n3\n2362.679\n787.560\n0.772\n0.515\n\n\nResiduals\n53\n54068.900\n1020.168\nNA\nNA\n\n\n\n\n\n\n\n\n\n\n\nDf: Degrees of freedom.\nF value: The ratio of variance between groups to variance within groups. A large F-value usually leads to a small p-value.\nPr(&gt;F): This is your p-value. If it is &lt; 0.05, we reject the Null.\n\n\n\n\n\n\nIf your ANOVA p-value is significant, you know someone is different, but you don‚Äôt know who. We use Tukey‚Äôs Honest Significant Difference to compare every possible pair.\n\nlibrary(broom)\n\n# 1. Run Tukey's HSD\ntukey_results &lt;- TukeyHSD(model)\n\n# 2. Tidy the results into a clean table\n# TukeyHSD returns a list, so we tidy the 'eye_color' element\ntidy_tukey &lt;- tidy(tukey_results)\n\n# 3. Create the accessible table\nknitr::kable(\n  tidy_tukey[, c(\"contrast\", \"estimate\", \"conf.low\", \"conf.high\", \"adj.p.value\")],\n  col.names = c(\"Comparison\", \"Difference in Means\", \"Lower 95% CI\", \"Upper 95% CI\", \"Adjusted p-value\"),\n  digits = 3\n)\n\n\n\nTable¬†2: Tukey HSD Post-Hoc comparisons for height across eye color groups.\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison\nDifference in Means\nLower 95% CI\nUpper 95% CI\nAdjusted p-value\n\n\n\n\nbrown-blue\n-14.895\n-42.381\n12.592\n0.482\n\n\norange-blue\n-1.711\n-37.417\n33.996\n0.999\n\n\nyellow-blue\n-4.392\n-36.490\n27.705\n0.983\n\n\norange-brown\n13.184\n-22.522\n48.890\n0.762\n\n\nyellow-brown\n10.502\n-21.595\n42.600\n0.821\n\n\nyellow-orange\n-2.682\n-42.048\n36.684\n0.998\n\n\n\n\n\n\n\n\n\n\nLab Task 16:\n\nIdentify a categorical variable in your data with 3 or more groups (e.g., County, Year, or Category).\nCreate a Boxplot comparing a numeric variable across these groups.\nRun the aov() function and look at the summary().\nConclusion: * If p &gt; 0.05: State that there is no significant difference between any groups.\n\nIf p &lt; 0.05: Run TukeyHSD() and identify which specific pairs are actually different.\n\n\n\n\n\n\n\nANOVA assumes that the ‚Äúspread‚Äù (variance) is roughly the same for all groups. If one boxplot is massive and another is tiny, the math might be unreliable. In those cases, we go back to the Non-parametric methods from Lab 15!\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 16: Analysis of variance (ANOVA)"
    ]
  },
  {
    "objectID": "labs/lab16.html#learning-objectives",
    "href": "labs/lab16.html#learning-objectives",
    "title": "Lab 16: Analysis of Variance (ANOVA)",
    "section": "",
    "text": "Understand when to use ANOVA instead of multiple t-tests.\nState the Null (\\(H_0\\)) and Alternative (\\(H_a\\)) hypotheses for multiple groups.\nConduct a One-Way ANOVA in R.\nPerform Post-hoc testing (Tukey‚Äôs HSD) to find exactly where differences lie.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 16: Analysis of variance (ANOVA)"
    ]
  },
  {
    "objectID": "labs/lab16.html#part-1-why-anova",
    "href": "labs/lab16.html#part-1-why-anova",
    "title": "Lab 16: Analysis of Variance (ANOVA)",
    "section": "",
    "text": "If you have three groups (e.g., Freshman, Sophomores, Juniors) and you want to compare their average GPA, you could run three separate t-tests. However, every time you run a test, there is a 5% chance of being wrong. By the third test, your error rate has ballooned!\nANOVA tests all groups at once, keeping our error rate at 5%.\n\nNull Hypothesis (\\(H_0\\)): All group means are equal (\\(\\mu_1 = \\mu_2 = \\mu_3\\)).\nAlternative Hypothesis (\\(H_a\\)): At least one group mean is different.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 16: Analysis of variance (ANOVA)"
    ]
  },
  {
    "objectID": "labs/lab16.html#part-2-visualizing-multiple-groups",
    "href": "labs/lab16.html#part-2-visualizing-multiple-groups",
    "title": "Lab 16: Analysis of Variance (ANOVA)",
    "section": "",
    "text": "With ANOVA, side-by-side boxplots are essential. They allow us to see if the ‚Äúspread‚Äù within groups is smaller than the ‚Äúdistance‚Äù between groups.\n\nlibrary(tidyverse)\n\n# Filter for the most common eye colors to avoid a cluttered plot\neye_data &lt;- starwars |&gt; \n  filter(eye_color %in% c(\"blue\", \"brown\", \"yellow\", \"orange\")) |&gt;\n  drop_na(height)\n\nggplot(eye_data, aes(x = eye_color, y = height, fill = eye_color)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_viridis_d() + # High contrast, color-blind safe palette\n  theme_minimal() +\n  labs(title = \"Height Distribution by Eye Color\",\n       x = \"Eye Color\",\n       y = \"Height (cm)\",\n       fill = \"Eye Color\")\n\n\n\n\n\n\n\nFigure¬†1: Distribution of heights across characters with blue, brown, yellow, and orange eyes.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 16: Analysis of variance (ANOVA)"
    ]
  },
  {
    "objectID": "labs/lab16.html#part-3-running-the-anova-in-r",
    "href": "labs/lab16.html#part-3-running-the-anova-in-r",
    "title": "Lab 16: Analysis of Variance (ANOVA)",
    "section": "",
    "text": "We use the aov() function. Like the t-test, we use the formula numeric_variable ~ categorical_variable.\n\nlibrary(broom)\n\n# 1. Fit the ANOVA model\nmodel &lt;- aov(height ~ eye_color, data = eye_data)\n\n# 2. Tidy the results into an accessible table\ntidy_anova &lt;- tidy(model)\n\n# 3. Create a clean table with descriptive headers\nknitr::kable(\n  tidy_anova,\n  col.names = c(\"Term\", \"Degrees of Freedom\", \"Sum of Squares\", \"Mean Square\", \"F-statistic\", \"p-value\"),\n  digits = 3\n)\n\n\n\nTable¬†1: One-way ANOVA results comparing mean heights across eye color groups.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nDegrees of Freedom\nSum of Squares\nMean Square\nF-statistic\np-value\n\n\n\n\neye_color\n3\n2362.679\n787.560\n0.772\n0.515\n\n\nResiduals\n53\n54068.900\n1020.168\nNA\nNA\n\n\n\n\n\n\n\n\n\n\n\nDf: Degrees of freedom.\nF value: The ratio of variance between groups to variance within groups. A large F-value usually leads to a small p-value.\nPr(&gt;F): This is your p-value. If it is &lt; 0.05, we reject the Null.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 16: Analysis of variance (ANOVA)"
    ]
  },
  {
    "objectID": "labs/lab16.html#part-4-post-hoc-testing-tukeys-hsd",
    "href": "labs/lab16.html#part-4-post-hoc-testing-tukeys-hsd",
    "title": "Lab 16: Analysis of Variance (ANOVA)",
    "section": "",
    "text": "If your ANOVA p-value is significant, you know someone is different, but you don‚Äôt know who. We use Tukey‚Äôs Honest Significant Difference to compare every possible pair.\n\nlibrary(broom)\n\n# 1. Run Tukey's HSD\ntukey_results &lt;- TukeyHSD(model)\n\n# 2. Tidy the results into a clean table\n# TukeyHSD returns a list, so we tidy the 'eye_color' element\ntidy_tukey &lt;- tidy(tukey_results)\n\n# 3. Create the accessible table\nknitr::kable(\n  tidy_tukey[, c(\"contrast\", \"estimate\", \"conf.low\", \"conf.high\", \"adj.p.value\")],\n  col.names = c(\"Comparison\", \"Difference in Means\", \"Lower 95% CI\", \"Upper 95% CI\", \"Adjusted p-value\"),\n  digits = 3\n)\n\n\n\nTable¬†2: Tukey HSD Post-Hoc comparisons for height across eye color groups.\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison\nDifference in Means\nLower 95% CI\nUpper 95% CI\nAdjusted p-value\n\n\n\n\nbrown-blue\n-14.895\n-42.381\n12.592\n0.482\n\n\norange-blue\n-1.711\n-37.417\n33.996\n0.999\n\n\nyellow-blue\n-4.392\n-36.490\n27.705\n0.983\n\n\norange-brown\n13.184\n-22.522\n48.890\n0.762\n\n\nyellow-brown\n10.502\n-21.595\n42.600\n0.821\n\n\nyellow-orange\n-2.682\n-42.048\n36.684\n0.998\n\n\n\n\n\n\n\n\n\n\nLab Task 16:\n\nIdentify a categorical variable in your data with 3 or more groups (e.g., County, Year, or Category).\nCreate a Boxplot comparing a numeric variable across these groups.\nRun the aov() function and look at the summary().\nConclusion: * If p &gt; 0.05: State that there is no significant difference between any groups.\n\nIf p &lt; 0.05: Run TukeyHSD() and identify which specific pairs are actually different.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 16: Analysis of variance (ANOVA)"
    ]
  },
  {
    "objectID": "labs/lab16.html#pro-tip-the-equal-variance-assumption",
    "href": "labs/lab16.html#pro-tip-the-equal-variance-assumption",
    "title": "Lab 16: Analysis of Variance (ANOVA)",
    "section": "",
    "text": "ANOVA assumes that the ‚Äúspread‚Äù (variance) is roughly the same for all groups. If one boxplot is massive and another is tiny, the math might be unreliable. In those cases, we go back to the Non-parametric methods from Lab 15!\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 16: Analysis of variance (ANOVA)"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html",
    "href": "labs/lab17_F26.html",
    "title": "Lab 17: Linear Regression",
    "section": "",
    "text": "Understand the Linear Regression equation: \\(y = \\beta_0 + \\beta_1x + \\epsilon\\).\nCalculate and interpret the Correlation Coefficient (\\(r\\)).\nFit a Linear Model in R using the lm() function.\nEvaluate model fit using R-squared (\\(R^2\\)).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html#learning-objectives",
    "href": "labs/lab17_F26.html#learning-objectives",
    "title": "Lab 17: Linear Regression",
    "section": "",
    "text": "Understand the Linear Regression equation: \\(y = \\beta_0 + \\beta_1x + \\epsilon\\).\nCalculate and interpret the Correlation Coefficient (\\(r\\)).\nFit a Linear Model in R using the lm() function.\nEvaluate model fit using R-squared (\\(R^2\\)).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html#data-acquisition-birth-weight-dataset-lbw.csv",
    "href": "labs/lab17_F26.html#data-acquisition-birth-weight-dataset-lbw.csv",
    "title": "Lab 17: Linear Regression",
    "section": "Data Acquisition: Birth Weight Dataset (lbw.csv)",
    "text": "Data Acquisition: Birth Weight Dataset (lbw.csv)\nTo complete the regression exercises, you need the lbw.csv dataset. Choose one of the methods below to load the data into R.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html#option-1-direct-link-recommended",
    "href": "labs/lab17_F26.html#option-1-direct-link-recommended",
    "title": "Lab 17: Linear Regression",
    "section": "Option 1: Direct Link (Recommended)",
    "text": "Option 1: Direct Link (Recommended)\nThis method pulls the data directly from the lab manual website. ## Data Loading and Preview\nWe are using the lbw dataset, which contains information on low birth weight.\n\nAccessible Logic: We use the read_csv() function to pull data from a web URL. After loading, it is important to check the ‚Äúhead‚Äù (the first 6 rows) to ensure the columns and values imported correctly.\n\n\nlibrary(tidyverse)\n\n# 1. Load the data\nurl &lt;- url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/lbw.csv\"\nlbw_data &lt;- read_csv(url)\n\n# 2. Display an accessible preview\n# We use head() to get the first 6 rows and kable() to make it a table\nknitr::kable(head(lbw_data))\n\n\n\nTable¬†1: Preview of the first six rows of the low birth weight (LBW) dataset.\n\n\n\n\n\n\nrownames\nlow\nsmoke\nrace\nage\nlwt\nptl\nht\nui\nftv\nbwt\n\n\n\n\n1\n0\n0\n2\n19\n182\n0\n0\n1\n0\n2523\n\n\n2\n0\n0\n3\n33\n155\n0\n0\n0\n3\n2551\n\n\n3\n0\n1\n1\n20\n105\n0\n0\n0\n1\n2557\n\n\n4\n0\n1\n1\n21\n108\n0\n0\n1\n2\n2594\n\n\n5\n0\n1\n1\n18\n107\n0\n0\n1\n0\n2600\n\n\n6\n0\n0\n3\n21\n124\n0\n0\n0\n0\n2622",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html#option-2-local-file",
    "href": "labs/lab17_F26.html#option-2-local-file",
    "title": "Lab 17: Linear Regression",
    "section": "Option 2: Local File",
    "text": "Option 2: Local File\nUse this if the file is saved in your project folder. ## Loading Data Locally\nTo ensure this lab is reproducible, we are loading the birth weight data from our project‚Äôs data folder.\n\nAccessible Logic: The path \"data/lbw.csv\" tells R to look inside a folder named data that is located in the same place as your script. This is called a relative path.\n\n\n# 1. Load the data using a relative path\n# Ensure the 'data' folder exists in your RStudio project\nlbw_data &lt;- read.csv(\"../data/2026_Fall/lbw.csv\")\n\n# 2. Accessible Preview\nknitr::kable(head(lbw_data))\n\n\n\nTable¬†2: Preview of the locally loaded LBW dataset.\n\n\n\n\n\n\nrownames\nlow\nsmoke\nrace\nage\nlwt\nptl\nht\nui\nftv\nbwt\n\n\n\n\n1\n0\n0\n2\n19\n182\n0\n0\n1\n0\n2523\n\n\n2\n0\n0\n3\n33\n155\n0\n0\n0\n3\n2551\n\n\n3\n0\n1\n1\n20\n105\n0\n0\n0\n1\n2557\n\n\n4\n0\n1\n1\n21\n108\n0\n0\n1\n2\n2594\n\n\n5\n0\n1\n1\n18\n107\n0\n0\n1\n0\n2600\n\n\n6\n0\n0\n3\n21\n124\n0\n0\n0\n0\n2622",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html#part-1-correlation-r",
    "href": "labs/lab17_F26.html#part-1-correlation-r",
    "title": "Lab 17: Linear Regression",
    "section": "Part 1: Correlation (\\(r\\))",
    "text": "Part 1: Correlation (\\(r\\))\nBefore building a model, we need to know if a linear relationship even exists. The correlation coefficient (\\(r\\)) ranges from -1 to 1.\n\n1: Perfect positive relationship.\n0: No relationship at all.\n-1: Perfect negative relationship.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html#part-2-visualizing-the-best-fit-line",
    "href": "labs/lab17_F26.html#part-2-visualizing-the-best-fit-line",
    "title": "Lab 17: Linear Regression",
    "section": "Part 2: Visualizing the Best Fit Line",
    "text": "Part 2: Visualizing the Best Fit Line\nWe use geom_smooth(method = \"lm\") to draw the line that minimizes the distance between all data points (the ‚ÄúOrdinary Least Squares‚Äù method).\n\nggplot(lbw_data, aes(x = lwt, y = bwt)) +\n  geom_point(alpha = 0.5, color = \"#002147\") + # DCC Navy\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  theme_minimal() +\n  labs(title = \"Predicting Birth Weight based on Mother's Weight\",\n       x = \"Mother's Weight (lbs)\",\n       y = \"Birth Weight (grams)\")\n\n\n\n\n\n\n\nFigure¬†1: Regression of Birth Weight on Mother‚Äôs Weight",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html#part-3-building-the-model-in-r",
    "href": "labs/lab17_F26.html#part-3-building-the-model-in-r",
    "title": "Lab 17: Linear Regression",
    "section": "Part 3: Building the Model in R",
    "text": "Part 3: Building the Model in R\nIn R, the ‚ÄúLinear Model‚Äù function is lm(). The syntax is lm(dependent_variable ~ independent_variable).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html#part-4-making-predictions",
    "href": "labs/lab17_F26.html#part-4-making-predictions",
    "title": "Lab 17: Linear Regression",
    "section": "Part 4: Making Predictions",
    "text": "Part 4: Making Predictions\nOnce you have a model, you can plug in a value for \\(x\\) to predict \\(y\\). If our model is \\(Mass = -100 + 1.2(Height)\\), we can predict the mass of a character who is 200cm tall. ## Model Prediction: 150lb Mother\nUsing our regression model, we can predict the specific birth weight for a baby based on the mother‚Äôs weight.\n\nAccessible Logic: We are plugging 150 into our regression equation (\\(y = mx + b\\)). The predict() function calculates this value for us automatically using the model we previously fitted.\n\n\n# 1. Create a data frame for the input (required by the predict function)\nnew_mom &lt;- data.frame(lwt = 150)\n\n# 2. Run the prediction\nprediction_val &lt;- predict(lbw_model, newdata = new_mom)\n\n# 3. Present the result in a clear, single-row table\nprediction_table &lt;- data.frame(\n  input_lwt = 150,\n  predicted_bwt = prediction_val\n)\n\nknitr::kable(\n  prediction_table,\n  col.names = c(\"Mother's Weight (lbs)\", \"Predicted Birth Weight (g)\"),\n  digits = 2\n)\n\n\n\nTable¬†5: Predicted Birth Weight for a mother weighing 150 lbs.\n\n\n\n\n\n\nMother‚Äôs Weight (lbs)\nPredicted Birth Weight (g)\n\n\n\n\n150\n3033.68\n\n\n\n\n\n\n\n\n\n\nLab Task 17:\n\nPick two numeric variables from your dataset that you think are related.\nCreate a Scatter Plot and add a linear regression line.\nUse the cor() function to find the correlation coefficient.\nFit a linear model using lm() and look at the summary().\nThe Report:\n\nWhat is the slope of your model?\nWhat is the \\(R^2\\) value?\nUse your model to make one prediction for a value not in your dataset.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References & OER Credits",
    "section": "",
    "text": "This lab manual utilizes materials from the following Open Educational Resources:\n\nOpenIntro Statistics by Diez, Cetinkaya-Rundel, and Barr. Licensed under CC BY-SA 3.0.\nIntroduction to Modern Statistics by √áetinkaya-Rundel and Hardin.\nR for Data Science by Wickham, Mine √áetinkaya-Rundel, and Grolemund.\n\nAll data sets used in these labs are available via the tidyverse or openintro R packages unless otherwise noted.\n\n\n\n\nReferences\n\n√áetinkaya-Rundel, Mine, and Johanna Hardin. 2023. Introduction to Modern Statistics. 2nd ed. https://openintro-ims.netlify.app/.\n\n\nDiez, David, Mine Cetinkaya-Rundel, and Christopher Barr. 2019. OpenIntro Statistics. 4th ed. https://www.openintro.org/book/os/.\n\n\nIsmay, Chester, and Albert Y. Kim. 2020. Statistical Inference via Data Science: A ModernDive into r and the Tidyverse. CRC Press. https://moderndive.com/.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. O‚ÄôReilly Media, Inc. https://r4ds.hadley.nz/."
  },
  {
    "objectID": "labs/lab17_F26.html#correlation-analysis-mothers-weight-vs.-birth-weight",
    "href": "labs/lab17_F26.html#correlation-analysis-mothers-weight-vs.-birth-weight",
    "title": "Lab 17: Linear Regression",
    "section": "Correlation Analysis: Mother‚Äôs Weight vs.¬†Birth Weight",
    "text": "Correlation Analysis: Mother‚Äôs Weight vs.¬†Birth Weight\nWe are calculating Pearson‚Äôs correlation coefficient to see if there is a linear relationship between the mother‚Äôs weight at the last menstrual period (lwt) and the baby‚Äôs birth weight (bwt).\n\nAccessible Logic: Correlation (\\(r\\)) ranges from -1 to +1. A value of 0 means no linear relationship, while values closer to +1 or -1 indicate stronger relationships.\n\n\nlibrary(tidyverse)\n\n# 1. Calculate the correlation\ncor_result &lt;- lbw_data |&gt;\n  drop_na(lwt, bwt) |&gt;\n  summarize(correlation = cor(lwt, bwt))\n\n# 2. Display as an accessible table\nknitr::kable(\n  cor_result,\n  col.names = c(\"Correlation Coefficient (r)\"),\n  digits = 3\n)\n\n\n\nTable¬†3: Pearson Correlation Coefficient between Mother‚Äôs Weight and Birth Weight.\n\n\n\n\n\n\nCorrelation Coefficient (r)\n\n\n\n\n0.186",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17_F26.html#simple-linear-regression-predicting-birth-weight",
    "href": "labs/lab17_F26.html#simple-linear-regression-predicting-birth-weight",
    "title": "Lab 17: Linear Regression",
    "section": "Simple Linear Regression: Predicting Birth Weight",
    "text": "Simple Linear Regression: Predicting Birth Weight\nWe are fitting a linear model to see how well Mother‚Äôs Weight (lwt) predicts Birth Weight (bwt).\n\nAccessible Logic: We are looking for the equation of a line: \\[bwt = \\beta_0 + \\beta_1(lwt)\\]. * The Intercept (\\(\\beta_0\\)) is the predicted birth weight if the mother‚Äôs weight was zero. * The Slope (\\(\\beta_1\\)) tells us how many grams the birth weight increases for every 1-pound increase in mother‚Äôs weight.\n\n\nlibrary(broom)\n\n# 1. Fit the model\nlbw_model &lt;- lm(bwt ~ lwt, data = lbw_data)\n\n# 2. Tidy the coefficients into an accessible table\nmodel_stats &lt;- tidy(lbw_model)\n\nknitr::kable(\n  model_stats,\n  col.names = c(\"Term\", \"Estimate\", \"Std. Error\", \"t-statistic\", \"p-value\"),\n  digits = 3\n)\n\n\n\nTable¬†4: Regression coefficients for predicting Birth Weight from Mother‚Äôs Weight.\n\n\n\n\n\n\nTerm\nEstimate\nStd. Error\nt-statistic\np-value\n\n\n\n\n(Intercept)\n2369.184\n228.467\n10.370\n0.00\n\n\nlwt\n4.430\n1.713\n2.586\n0.01\n\n\n\n\n\n\n\n\n\n\nHow to interpret the summary:\n\nIntercept (\\(\\beta_0\\)): The predicted value of \\(y\\) when \\(x\\) is zero.\nSlope (\\(\\beta_1\\)): For every 1 unit increase in \\(x\\), how much \\(y\\) is expected to change.\nR-squared (\\(R^2\\)): The percentage of variation in \\(y\\) explained by your model. (e.g., \\(0.75\\) means your model explains 75% of the data).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab02.html",
    "href": "labs/lab02.html",
    "title": "Lab 2: RStudio Projects and Quarto Documents",
    "section": "",
    "text": "Create an RStudio Project to organize your work.\nUnderstand the structure of a Quarto (.qmd) document.\n‚ÄúRender‚Äù a document into a professional HTML report.\n\n\n\n\n\nIn Data Science, organization is everything. An RStudio Project keeps your code, data, and images in one ‚Äúfolder‚Äù so R always knows where to look.\n\n\n\nOpen RStudio.\nClick File &gt; New Project‚Ä¶\nSelect New Directory &gt; New Project.\nName your directory MAT186_Labs and save it to your Documents folder.\n\n\n\n\nNow, look at the Files pane (usually in the bottom-right of RStudio). You need to create a place for your future files:\n\nClick the New Folder button.\nType data and click OK.\nClick the New Folder button again.\nType images and click OK.\n\n\n\n\n\n\n\nNoteWhy do this?\n\n\n\nBy creating these now, you are ready for Lab 5! You will put all your datasets in /data and all your plots/diagrams in /images.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 2: RStudio Project and Quarto Documents"
    ]
  },
  {
    "objectID": "labs/lab02.html#learning-objectives",
    "href": "labs/lab02.html#learning-objectives",
    "title": "Lab 2: RStudio Projects and Quarto Documents",
    "section": "",
    "text": "Create an RStudio Project to organize your work.\nUnderstand the structure of a Quarto (.qmd) document.\n‚ÄúRender‚Äù a document into a professional HTML report.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 2: RStudio Project and Quarto Documents"
    ]
  },
  {
    "objectID": "labs/lab02.html#part-1-rstudio-projects",
    "href": "labs/lab02.html#part-1-rstudio-projects",
    "title": "Lab 2: RStudio Projects and Quarto Documents",
    "section": "",
    "text": "In Data Science, organization is everything. An RStudio Project keeps your code, data, and images in one ‚Äúfolder‚Äù so R always knows where to look.\n\n\n\nOpen RStudio.\nClick File &gt; New Project‚Ä¶\nSelect New Directory &gt; New Project.\nName your directory MAT186_Labs and save it to your Documents folder.\n\n\n\n\nNow, look at the Files pane (usually in the bottom-right of RStudio). You need to create a place for your future files:\n\nClick the New Folder button.\nType data and click OK.\nClick the New Folder button again.\nType images and click OK.\n\n\n\n\n\n\n\nNoteWhy do this?\n\n\n\nBy creating these now, you are ready for Lab 5! You will put all your datasets in /data and all your plots/diagrams in /images.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 2: RStudio Project and Quarto Documents"
    ]
  },
  {
    "objectID": "labs/lab02.html#creating-your-document",
    "href": "labs/lab02.html#creating-your-document",
    "title": "Lab 2: RStudio Projects and Quarto Documents",
    "section": "Creating your Document",
    "text": "Creating your Document\n\nIn the top menu, click File &gt; New File &gt; Quarto Document‚Ä¶\nTitle it ‚ÄúLab 2‚Äù and put your name as the Author.\nClick Create. It will open a quarto document.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 2: RStudio Project and Quarto Documents"
    ]
  },
  {
    "objectID": "labs/lab02.html#the-three-parts-of-a-quarto-document",
    "href": "labs/lab02.html#the-three-parts-of-a-quarto-document",
    "title": "Lab 2: RStudio Projects and Quarto Documents",
    "section": "The Three Parts of a Quarto Document",
    "text": "The Three Parts of a Quarto Document\nA Quarto document is made of three distinct components:\n\n1. The YAML Header\nLook at the very top of the file. You will see text between two sets of three dashes (---). This is the YAML Header; it contains the ‚Äúmetadata‚Äù or settings for your document.\n---\ntitle: \"Lab 2\"\nauthor: \"Your Name\"\nformat: html\neditor: visual\n---\n\n\n2. Markdown (Narrative)\nThe plain white areas of the document are called Markdown. This is where you write your analysis, explain your results, and answer questions. It works like a simplified word processor.\n\nYou can make text bold by using **double asterisks**.\nYou can make text italic by using *single asterisks*.\n\n\n\n3. Code Chunks\nThe gray boxes starting with ```{r} and ending with ``` are called Code Chunks. This is where you put your R code to run calculations or create graphs.\n\n# This is a code chunk. R code goes here!\n1 + 1\n\n[1] 2\n\n\n\n\n\n\n\n\nNoteTip for Students\n\n\n\nTo run the code inside a chunk, click the green Play button in the top-right corner of the gray box. The result will appear directly below the chunk!",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 2: RStudio Project and Quarto Documents"
    ]
  },
  {
    "objectID": "labs/lab02.html#part-3-rendering-the-magic-button",
    "href": "labs/lab02.html#part-3-rendering-the-magic-button",
    "title": "Lab 2: RStudio Projects and Quarto Documents",
    "section": "Part 3: Rendering (The ‚ÄúMagic‚Äù Button)",
    "text": "Part 3: Rendering (The ‚ÄúMagic‚Äù Button)\nTo turn your code into a report:\n\nClick the Render button (blue arrow icon) at the top of the editor.\nRStudio will save the file and pop up a beautiful HTML window.\n\n\n\n\n\n\n\n\nImportantüìù Lab Task 2: Your First Calculation\n\n\n\nFollow these steps to practice using Quarto:\n\nCreate a Document: In RStudio, go to File &gt; New File &gt; Quarto Document. Name it Lab2_yourname.\nClean the Workspace: Find the heading that says Quarto. Delete all the example text and code below that line so you have a blank white space.\nAdd a Title: In that new blank area, type a title for your work: # Lab 2. (Note: Using the # symbol makes the text large like a heading!)\nInsert a Chunk: Click the +C button to create a new gray R chunk. Inside the chunk, type: 2 + 2\nRender the Report: Click the Render button (blue arrow icon) at the top of your screen.\nCheck Results: Look at your final HTML report. You should see your title Lab 2, the code 2 + 2, and the result 4.\nSubmit: upload your HTML report in Brightspace and submit it.\n\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 2: RStudio Project and Quarto Documents"
    ]
  },
  {
    "objectID": "labs/lab03.html",
    "href": "labs/lab03.html",
    "title": "Lab 3: Mathematical Notation in Quarto",
    "section": "",
    "text": "Distinguish between Inline and Display math modes in Quarto.\nUse LaTeX syntax to write essential statistical symbols (\\(\\mu, \\sigma, \\bar{x}\\)).\nFormat complex equations like Linear Regression for professional lab reports.\n\n\n\n\n\nIn Data Science, we often need to document the mathematical models we use. Quarto uses a system called LaTeX (pronounced ‚ÄúLay-tek‚Äù) to render math. This ensures your formulas look professional and are accessible to screen readers.\n\n\n\n\nThere are two ways to display math in your Quarto documents depending on where you want the formula to appear.\n\n\nUse a single dollar sign $ ... $ when the math should stay inside a sentence.\n\nCode: The population mean is represented by $\\mu$.\nResult: The population mean is represented by \\(\\mu\\).\n\n\n\n\nUse double dollar signs $$...$$ to center the formula on its own line.\n\nCode: $$\\bar{x} = \\frac{\\sum x_i}{n}$$\nResult: \\[\\bar{x} = \\frac{\\sum x_i}{n}\\]\n\n\n\n\n\n\nCopy and paste these codes into your Quarto document to practice:\n\n\n\nStatistical Term\nLaTeX Code\nRendered Result\n\n\n\n\nSample Mean\n$\\bar{x}$\n\\(\\bar{x}\\)\n\n\nStandard Deviation\n$\\sigma$\n\\(\\sigma\\)\n\n\nSummation\n$\\sum$\n\\(\\sum\\)\n\n\nCorrelation Coefficient\n$r$\n\\(r\\)\n\n\nCoefficient of Determination\n$R^2$\n\\(R^2\\)\n\n\n\n\n\n\n\nFor Linear Regression, we combine several symbols. Try typing this in your Quarto file:\nCode: $$y = \\beta_0 + \\beta_1 x + \\epsilon$$\nResult: \\[y = \\beta_0 + \\beta_1 x + \\epsilon\\]\n\n\nLab Task 3:\n\nOpen your MAT186_Labs project in RStudio.\nCreate a new Quarto document (.qmd) titled ‚ÄúMath Practice.‚Äù\nWrite the formula for the Standard Deviation exactly as shown below: $$s = \\sqrt{\\frac{\\sum (x_i - \\bar{x})^2}{n - 1}}$$\nRender the document to HTML and confirm the formula appears correctly.\n\n\n\n\n\n\n\nSpaces: Do not put a space between the $ and your math code.\n\nBad: $ \\mu $\nGood: $\\mu$\n\nMissing Signs: If your formula looks like plain text, check if you forgot the closing $.\n\n\n\n\nWhen you use this LaTeX method, students using screen readers can hear the math described clearly (e.g., ‚Äúx bar equals fraction sum x sub i over n‚Äù). This is much better than using an image of an equation, which a screen reader cannot ‚Äúsee.‚Äù\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 3: Mathematical Notation in Quarto"
    ]
  },
  {
    "objectID": "labs/lab03.html#learning-objectives",
    "href": "labs/lab03.html#learning-objectives",
    "title": "Lab 3: Mathematical Notation in Quarto",
    "section": "",
    "text": "Distinguish between Inline and Display math modes in Quarto.\nUse LaTeX syntax to write essential statistical symbols (\\(\\mu, \\sigma, \\bar{x}\\)).\nFormat complex equations like Linear Regression for professional lab reports.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 3: Mathematical Notation in Quarto"
    ]
  },
  {
    "objectID": "labs/lab03.html#introduction",
    "href": "labs/lab03.html#introduction",
    "title": "Lab 3: Mathematical Notation in Quarto",
    "section": "",
    "text": "In Data Science, we often need to document the mathematical models we use. Quarto uses a system called LaTeX (pronounced ‚ÄúLay-tek‚Äù) to render math. This ensures your formulas look professional and are accessible to screen readers.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 3: Mathematical Notation in Quarto"
    ]
  },
  {
    "objectID": "labs/lab03.html#part-1-the-two-math-modes",
    "href": "labs/lab03.html#part-1-the-two-math-modes",
    "title": "Lab 3: Mathematical Notation in Quarto",
    "section": "",
    "text": "There are two ways to display math in your Quarto documents depending on where you want the formula to appear.\n\n\nUse a single dollar sign $ ... $ when the math should stay inside a sentence.\n\nCode: The population mean is represented by $\\mu$.\nResult: The population mean is represented by \\(\\mu\\).\n\n\n\n\nUse double dollar signs $$...$$ to center the formula on its own line.\n\nCode: $$\\bar{x} = \\frac{\\sum x_i}{n}$$\nResult: \\[\\bar{x} = \\frac{\\sum x_i}{n}\\]",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 3: Mathematical Notation in Quarto"
    ]
  },
  {
    "objectID": "labs/lab03.html#part-2-common-symbols-for-mat-186",
    "href": "labs/lab03.html#part-2-common-symbols-for-mat-186",
    "title": "Lab 3: Mathematical Notation in Quarto",
    "section": "",
    "text": "Copy and paste these codes into your Quarto document to practice:\n\n\n\nStatistical Term\nLaTeX Code\nRendered Result\n\n\n\n\nSample Mean\n$\\bar{x}$\n\\(\\bar{x}\\)\n\n\nStandard Deviation\n$\\sigma$\n\\(\\sigma\\)\n\n\nSummation\n$\\sum$\n\\(\\sum\\)\n\n\nCorrelation Coefficient\n$r$\n\\(r\\)\n\n\nCoefficient of Determination\n$R^2$\n\\(R^2\\)",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 3: Mathematical Notation in Quarto"
    ]
  },
  {
    "objectID": "labs/lab03.html#part-3-writing-equations",
    "href": "labs/lab03.html#part-3-writing-equations",
    "title": "Lab 3: Mathematical Notation in Quarto",
    "section": "",
    "text": "For Linear Regression, we combine several symbols. Try typing this in your Quarto file:\nCode: $$y = \\beta_0 + \\beta_1 x + \\epsilon$$\nResult: \\[y = \\beta_0 + \\beta_1 x + \\epsilon\\]\n\n\nLab Task 3:\n\nOpen your MAT186_Labs project in RStudio.\nCreate a new Quarto document (.qmd) titled ‚ÄúMath Practice.‚Äù\nWrite the formula for the Standard Deviation exactly as shown below: $$s = \\sqrt{\\frac{\\sum (x_i - \\bar{x})^2}{n - 1}}$$\nRender the document to HTML and confirm the formula appears correctly.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 3: Mathematical Notation in Quarto"
    ]
  },
  {
    "objectID": "labs/lab03.html#troubleshooting-math-errors",
    "href": "labs/lab03.html#troubleshooting-math-errors",
    "title": "Lab 3: Mathematical Notation in Quarto",
    "section": "",
    "text": "Spaces: Do not put a space between the $ and your math code.\n\nBad: $ \\mu $\nGood: $\\mu$\n\nMissing Signs: If your formula looks like plain text, check if you forgot the closing $.\n\n\n\n\nWhen you use this LaTeX method, students using screen readers can hear the math described clearly (e.g., ‚Äúx bar equals fraction sum x sub i over n‚Äù). This is much better than using an image of an equation, which a screen reader cannot ‚Äúsee.‚Äù\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 3: Mathematical Notation in Quarto"
    ]
  },
  {
    "objectID": "showcase.html",
    "href": "showcase.html",
    "title": "MAT 186: Data Science",
    "section": "",
    "text": "Every week, I pick one or two labs that did an amazing job explaining their data or organizing their code. This is a great place to see how your classmates are solving problems.\n\n\nWhy it stands out:\n\nClear Labels: They changed the x-axis from lwt to ‚ÄúMother‚Äôs Weight (lbs)‚Äù so anyone could understand it.\nGreat Detail: They explained why they chose a specific filter for their data.\nClean GitHub: Their repository is easy to navigate and looks professional.\n\n\nWant to be featured? Focus on making your graphs easy to read for someone who isn‚Äôt in our Mat186 class!",
    "crumbs": [
      "Home",
      "Getting Started",
      "Lab Showcase"
    ]
  },
  {
    "objectID": "showcase.html#lab-showcase-great-work",
    "href": "showcase.html#lab-showcase-great-work",
    "title": "MAT 186: Data Science",
    "section": "",
    "text": "Every week, I pick one or two labs that did an amazing job explaining their data or organizing their code. This is a great place to see how your classmates are solving problems.\n\n\nWhy it stands out:\n\nClear Labels: They changed the x-axis from lwt to ‚ÄúMother‚Äôs Weight (lbs)‚Äù so anyone could understand it.\nGreat Detail: They explained why they chose a specific filter for their data.\nClean GitHub: Their repository is easy to navigate and looks professional.\n\n\nWant to be featured? Focus on making your graphs easy to read for someone who isn‚Äôt in our Mat186 class!",
    "crumbs": [
      "Home",
      "Getting Started",
      "Lab Showcase"
    ]
  },
  {
    "objectID": "sharing-guide.html",
    "href": "sharing-guide.html",
    "title": "üöÄ Quick Start: Sharing Your Lab Portfolio",
    "section": "",
    "text": "Follow these steps to ensure your professor can see and grade your work.\n\n\n\nGo to GitHub.com and sign up.\nUse a professional email address (your school email is best).\n\n\n\n\n\nClick the + icon (top right) -&gt; New repository.\nName: MAT186-Labs-YourName.\nPublic/Private: Select Public.\nCheck Add a README file.\nClick Create repository.\n\n\n\n\nEvery lab requires two files to be uploaded:\n\nThe .qmd file (Your ‚Äúmath/code‚Äù file).\nThe .html file (Your ‚Äúrendered‚Äù report).\n\nSteps to Upload:\n\nClick Add file -&gt; Upload files.\nDrag both files into the box.\nIMPORTANT: Type ‚ÄúUpload Lab [X]‚Äù in the commit box and click Commit changes.\n\n\n\n\n\nCopy the URL from your browser (e.g., https://github.com/YourUser/MAT186-Labs).\nPaste this link into the Brightspace Comment Box when you submit your lab.",
    "crumbs": [
      "Home",
      "Getting Started",
      "GitHub Setup & Sharing"
    ]
  },
  {
    "objectID": "sharing-guide.html#create-your-account",
    "href": "sharing-guide.html#create-your-account",
    "title": "üöÄ Quick Start: Sharing Your Lab Portfolio",
    "section": "",
    "text": "Go to GitHub.com and sign up.\nUse a professional email address (your school email is best).",
    "crumbs": [
      "Home",
      "Getting Started",
      "GitHub Setup & Sharing"
    ]
  },
  {
    "objectID": "sharing-guide.html#create-your-repository",
    "href": "sharing-guide.html#create-your-repository",
    "title": "üöÄ Quick Start: Sharing Your Lab Portfolio",
    "section": "",
    "text": "Click the + icon (top right) -&gt; New repository.\nName: MAT186-Labs-YourName.\nPublic/Private: Select Public.\nCheck Add a README file.\nClick Create repository.",
    "crumbs": [
      "Home",
      "Getting Started",
      "GitHub Setup & Sharing"
    ]
  },
  {
    "objectID": "sharing-guide.html#uploading-your-files",
    "href": "sharing-guide.html#uploading-your-files",
    "title": "üöÄ Quick Start: Sharing Your Lab Portfolio",
    "section": "",
    "text": "Every lab requires two files to be uploaded:\n\nThe .qmd file (Your ‚Äúmath/code‚Äù file).\nThe .html file (Your ‚Äúrendered‚Äù report).\n\nSteps to Upload:\n\nClick Add file -&gt; Upload files.\nDrag both files into the box.\nIMPORTANT: Type ‚ÄúUpload Lab [X]‚Äù in the commit box and click Commit changes.",
    "crumbs": [
      "Home",
      "Getting Started",
      "GitHub Setup & Sharing"
    ]
  },
  {
    "objectID": "sharing-guide.html#how-to-share-the-link",
    "href": "sharing-guide.html#how-to-share-the-link",
    "title": "üöÄ Quick Start: Sharing Your Lab Portfolio",
    "section": "",
    "text": "Copy the URL from your browser (e.g., https://github.com/YourUser/MAT186-Labs).\nPaste this link into the Brightspace Comment Box when you submit your lab.",
    "crumbs": [
      "Home",
      "Getting Started",
      "GitHub Setup & Sharing"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MAT 186: Data Science Lab Manual",
    "section": "",
    "text": "Welcome to the official lab manual for Introduction to Data Science. This manual will guide you through 17 labs, transitioning from basic data entry to advanced predictive modeling using R and Quarto.\n\n\n\n\n\n\nImportantNew to the Course?\n\n\n\nBefore submitting your first lab, please read the GitHub Sharing Guide to ensure your work is visible for grading!\n\n\n\n\n\n\n\n\n\nA laptop or tablet is required for all lab sessions.\n\n\n\nAn account on Posit Cloud or RStudio Desktop installed.\n\n\n\nAccess our Brightspace page for dataset downloads.\n\n\n\n\n\n\n\nDutchess Community College is committed to providing equal access to education. This manual is designed with Universal Design for Learning (UDL) principles to be accessible to all students.\n\n\n\nüîç Screen Reader Friendly: All data visualizations include descriptive captions (fig-cap) acting as Alt-Text.\nüåà Colorblind Accessible: All plots utilize the Viridis color palette, ensuring data is distinguishable for everyone.\n‚å®Ô∏è Keyboard Navigation: This site is fully navigable via keyboard for students who do not use a mouse.\nüìê Accessible Math: Formulas are rendered using LaTeX, allowing screen readers to interpret mathematical logic.\n\n\n\n\nIf you encounter any barriers‚Äîsuch as difficult visualizations or navigation issues‚Äîplease contact us immediately:\n\nYour Instructor: henry.mendozarivera@sunydutchess.edu\nDCC Office of Accommodative Services: * Location: Library, Room 303\n\nPhone: 845-431-8050\n\n\n\n\n\n\n\nSolution keys are available in the sidebar menu. Please note that these are password protected and codes will be released in class following the submission deadline for each lab.\n\n\n\n\nHenry Mendoza Rivera is an Instructor in the Department of Mathematics and Computer Science at Dutchess Community College. This OER project was developed to provide high-quality, zero-cost data science education to the DCC community.\n\n\n\n\n\n\nNoteSuggested Citation\n\n\n\nMendoza Rivera, H. (2026). MAT 186: Introduction to Data Science Lab Manual. Dutchess Community College. Available at: https://hmendozardcc.github.io/mat186-lab-manual/. Licensed under CC BY-NC-SA 4.0."
  },
  {
    "objectID": "index.html#accessibility-statement",
    "href": "index.html#accessibility-statement",
    "title": "MAT 186: Data Science Lab Manual",
    "section": "",
    "text": "Dutchess Community College is committed to providing equal access to education. This lab manual is designed with Universal Design for Learning (UDL) principles to be accessible to all students, including those using assistive technologies.\n\n\n\nScreen Reader Friendly: All data visualizations include descriptive captions (fig-cap) that act as Alt-Text.\nColorblind Accessibility: All plots utilize the Viridis color palette, ensuring data is distinguishable regardless of color vision deficiency.\nKeyboard Navigation: This site is fully navigable via keyboard for students who do not use a mouse.\nAccessible Math: Mathematical formulas are rendered using LaTeX, allowing screen readers to interpret mathematical logic accurately.\n\n\n\n\nIf you encounter any barriers while using this manual‚Äîsuch as a visualization that is difficult to interpret or code that is hard to navigate‚Äîplease do not hesitate to contact:\n\nYour Instructor: henry.mendozarivera@sunydutchess.edu\nDCC Office of Accommodative Services: * Location: Library, Room 303\n\nPhone: 845-431-8050"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "MAT 186: Data Science Lab Manual",
    "section": "",
    "text": "A laptop or tablet is required for all lab sessions.\n\n\n\nAn account on Posit Cloud or RStudio Desktop installed.\n\n\n\nAccess our Brightspace page for dataset downloads."
  },
  {
    "objectID": "solutions/lab01-sol.html",
    "href": "solutions/lab01-sol.html",
    "title": "Lab 01: Solutions",
    "section": "",
    "text": "üîí This content is password protected\n\n\nPlease enter the code provided in class to view the solutions.\n\n Unlock\n\n\n\nLab01-solution\n\nknitr::include_graphics(\"../images/lab01-sol.png\")\n\n\n\n\n\n\n\nFigure¬†1: The code: print(‚ÄòHello, MAT 186!‚Äô)",
    "crumbs": [
      "Home",
      "Course Labs",
      "üîë Lab 1 Solution"
    ]
  },
  {
    "objectID": "solutions/lab01-ans-k8p2.html",
    "href": "solutions/lab01-ans-k8p2.html",
    "title": "Lab 01: Solutions",
    "section": "",
    "text": "üîí Solutions Protected\n\n\nPlease enter the classroom code to unlock Lab 1 results.\n\n Unlock\n\n\n\nLab01-solution\n\nknitr::include_graphics(\"../images/res_01_99x.png\")\n\n\n\n\n\n\n\nFigure¬†1: The code: print(‚ÄòHello, MAT 186!‚Äô)\n\n\n\n\n\n\n\n\n\n\n\nüè† Back to Solutions Hub",
    "crumbs": [
      "Home",
      "Course Labs",
      "üîë Lab 1 Solution"
    ]
  },
  {
    "objectID": "index.html#accessibility-universal-design",
    "href": "index.html#accessibility-universal-design",
    "title": "MAT 186: Data Science Lab Manual",
    "section": "",
    "text": "Dutchess Community College is committed to providing equal access to education. This manual is designed with Universal Design for Learning (UDL) principles to be accessible to all students.\n\n\n\nüîç Screen Reader Friendly: All data visualizations include descriptive captions (fig-cap) acting as Alt-Text.\nüåà Colorblind Accessible: All plots utilize the Viridis color palette, ensuring data is distinguishable for everyone.\n‚å®Ô∏è Keyboard Navigation: This site is fully navigable via keyboard for students who do not use a mouse.\nüìê Accessible Math: Formulas are rendered using LaTeX, allowing screen readers to interpret mathematical logic.\n\n\n\n\nIf you encounter any barriers‚Äîsuch as difficult visualizations or navigation issues‚Äîplease contact us immediately:\n\nYour Instructor: henry.mendozarivera@sunydutchess.edu\nDCC Office of Accommodative Services: * Location: Library, Room 303\n\nPhone: 845-431-8050"
  },
  {
    "objectID": "index.html#accessing-solutions",
    "href": "index.html#accessing-solutions",
    "title": "MAT 186: Data Science Lab Manual",
    "section": "",
    "text": "Solution keys are available in the sidebar menu. Please note that these are password protected and codes will be released in class following the submission deadline for each lab."
  },
  {
    "objectID": "solutions/lab02-ans-v4n9.html",
    "href": "solutions/lab02-ans-v4n9.html",
    "title": "Solution - Lab 02: RStudio & Quarto",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box."
  },
  {
    "objectID": "solutions/lab02-ans-v4n9.html#lab-2-official-solutions",
    "href": "solutions/lab02-ans-v4n9.html#lab-2-official-solutions",
    "title": "Solution - Lab 02: RStudio & Quarto",
    "section": "Lab 2 Official Solutions",
    "text": "Lab 2 Official Solutions\n\nTask 1: Basic Arithmetic\nThe student was asked to create a code chunk that calculates \\(2 + 2\\).\n\n2 + 2\n\n[1] 4\n\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "accessibility.html",
    "href": "accessibility.html",
    "title": "Accessibility Statement",
    "section": "",
    "text": "This course site is designed to be accessible to all students, including those with disabilities. We aim to meet or exceed WCAG 2.1 Level AA standards, ensuring that every student at Dutchess Community College has equal access to our Data Science materials.\n\n\nTo achieve our 100% Accessibility rating (as verified by Lighthouse audits), we have implemented the following features:\n\nAlt-Text for Data Visualizations: Every chart, graph, and plot in our labs includes descriptive alternative text. This allows screen reader users to understand the trends and conclusions of the data without seeing the image.\nSemantic Navigation: We use a clear heading hierarchy (# H1, ## H2, ### H3) to allow for easy keyboard navigation and screen reader ‚Äúheading jumps.‚Äù\nMathematical Accessibility: All mathematical notation is rendered using MathJax, which transforms LaTeX equations into readable text for assistive technologies.\nColor Contrast: Text and background colors have been selected to meet high contrast requirements for improved readability.\nAccessible Code: Code chunks are formatted to be legible and distinguishable from standard prose.\n\n\n\n\nAccessibility relies on the following technologies to work with the particular combination of web browser and any assistive technologies or plugins installed on your computer: * HTML * WAI-ARIA * CSS * JavaScript\n\n\n\nIf you encounter any accessibility barriers while using this site, please contact me directly. I am committed to making adjustments to ensure you have the materials you need to succeed.\nYou may also reach out to the DCC Office of Accommodative Services for further support and official accommodations.\n\nThis site was last audited on r format(Sys.Date(), \"%B %Y\") and received a 100% Accessibility score using Google Lighthouse."
  },
  {
    "objectID": "accessibility.html#our-commitment",
    "href": "accessibility.html#our-commitment",
    "title": "Accessibility Statement",
    "section": "",
    "text": "Dutchess Community College is committed to ensuring that our lab manuals are accessible to all students, including those with disabilities. This site is built with Quarto and complies with WCAG 2.1 Level AA standards."
  },
  {
    "objectID": "accessibility.html#accessibility-features",
    "href": "accessibility.html#accessibility-features",
    "title": "Accessibility Statement",
    "section": "Accessibility Features",
    "text": "Accessibility Features\n\nMathematical Formulas: We use MathJax to render equations. This allows formulas to be read by screen readers and zoomed without loss of resolution.\nKeyboard Navigation: All parts of this site are navigable using the Tab key.\nHigh Contrast: Colors have been selected to meet contrast requirements for readability.\nAlternative Text: All structural images include descriptive alt-text."
  },
  {
    "objectID": "accessibility.html#support",
    "href": "accessibility.html#support",
    "title": "Accessibility Statement",
    "section": "Support",
    "text": "Support\nIf you encounter any accessibility barriers or have difficulty accessing the content in these labs, please contact your instructor or the DCC Office of Accommodative Services."
  },
  {
    "objectID": "solutions/lab03-ans-x7m1.html",
    "href": "solutions/lab03-ans-x7m1.html",
    "title": "Solution - Lab 03: Mathematical Notation",
    "section": "",
    "text": "The student was asked to render the sample standard deviation formula using LaTeX.\nThe expected output:\n\\[s = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n - 1}}\\]\n\n\n\n\nInline Math: We use single dollar signs, like \\(E = mc^2\\), to put math inside a sentence.\nDisplay Math: We use double dollar signs to center the math on its own line.\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab03-ans-x7m1.html#mathematical-notation-in-quarto---official-solutions",
    "href": "solutions/lab03-ans-x7m1.html#mathematical-notation-in-quarto---official-solutions",
    "title": "Solution - Lab 3: Mathematical Notation in Quarto",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab04-ans-b2r6.html",
    "href": "solutions/lab04-ans-b2r6.html",
    "title": "Solution - Lab 4: GitHub Repository",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nThe student should have successfully initialized a Git repository.\nVerification Checklist:\n\nThe repository is named MAT186-Work.\nThe visibility is set to Public (or Private if specified by the instructor).\nA .gitignore file is present to exclude the .Rproj.user folder.\n\n\n\n\nThe ‚ÄúSolution‚Äù to this task is the successful appearance of the Quarto files on the student‚Äôs GitHub URL.\nThe command line sequence they should have used is:\ngit add .\ngit commit -m \"Finished Lab 4 tasks\"\ngit push origin main\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab04-ans-b2r6.html#github-repository---official-solutions",
    "href": "solutions/lab04-ans-b2r6.html#github-repository---official-solutions",
    "title": "Solution - Lab 4: GitHub Repository",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nThe student should have successfully initialized a Git repository.\nVerification Checklist:\n\nThe repository is named MAT186-Work.\nThe visibility is set to Public (or Private if specified by the instructor).\nA .gitignore file is present to exclude the .Rproj.user folder.\n\n\n\n\nThe ‚ÄúSolution‚Äù to this task is the successful appearance of the Quarto files on the student‚Äôs GitHub URL.\nThe command line sequence they should have used is:\ngit add .\ngit commit -m \"Finished Lab 4 tasks\"\ngit push origin main\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab07-ans-h9y4.html",
    "href": "solutions/lab07-ans-h9y4.html",
    "title": "Solution - Lab 7: Cleaning Data",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nIn this lab, we move from simply looking at data to transforming it. Raw data from portals like NY Open Data often contains too many variables or messy formatting. We use the dplyr library to keep only what is relevant to our research question.\n\n\n\n\nWe continue using the tidyverse package. We must be careful with our file paths; since this solution is in the solutions/ folder, we use ../ to find our data.\n\nlibrary(tidyverse)\n\n# Load the SUNY Enrollment data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n\n\n\nThe goal of this task was to create a ‚ÄúClean‚Äù version of our table by selecting 4 key columns, filtering for a specific sector, and renaming columns for better readability.\n\n\n\nSelect: We kept Term , Institution Sector, Total Enrollment, and Hispanic/Latino.\nRename: We shortened the names to semester, sector, total, and hispanic_latino.\nFilter: We narrowed the results to only show ‚ÄúCommunity Colleges‚Äù.\n\n\n# Create the cleaned object\ncleaned_suny &lt;- ny_data |&gt; \n  # Task 2: Select the 4 most important columns by their position\n  # This avoids \"Column not found\" errors caused by hidden spaces!\n  select(1, 2, 3, 6) |&gt; \n  \n  # Task 4: Rename the columns for clarity\n  # rename(new_name = old_position_or_name)\n  rename(semester = 1,\n         sector = 2,\n         total_enrollment = 3,\n         hispanic_latino = 4) |&gt; \n  \n  # Task 3: Filter for a specific category\n  filter(sector == \"Community Colleges\")\n\n# Task 5: Show the first 10 rows\nhead(cleaned_suny, n = 10)\n\n# A tibble: 10 √ó 4\n   semester  sector             total_enrollment hispanic_latino\n   &lt;chr&gt;     &lt;chr&gt;                         &lt;dbl&gt;           &lt;dbl&gt;\n 1 Fall 2019 Community Colleges           192959           31531\n 2 Fall 2018 Community Colleges           199873           31057\n 3 Fall 2017 Community Colleges           209418           30861\n 4 Fall 2016 Community Colleges           216277           30097\n 5 Fall 2015 Community Colleges           222998           29222\n 6 Fall 2014 Community Colleges           233812           28584\n 7 Fall 2013 Community Colleges           239791           27436\n 8 Fall 2012 Community Colleges           243007           25968\n 9 Fall 2011 Community Colleges           247667           24101\n10 Fall 2010 Community Colleges           249343           21809\n\n\n\n\n\nBy applying these transformations, we have turned a large dataset into a focused report.\n\nThe Observation: Each row now represents a specific semester‚Äôs enrollment data for the Community College sector.\nThe Benefit: Instead of 12 columns, we now have the 4 most important variables for analyzing Hispanic/Latino enrollment trends in community colleges.\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab07-ans-h9y4.html#cleaning-data---official-solutions",
    "href": "solutions/lab07-ans-h9y4.html#cleaning-data---official-solutions",
    "title": "Solution - Lab 7: Cleaning Data",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nIn this lab, we move from simply looking at data to transforming it. Raw data from portals like NY Open Data often contains too many variables or messy formatting. We use the dplyr library to keep only what is relevant to our research question.\n\n\n\n\nWe continue using the tidyverse package. We must be careful with our file paths; since this solution is in the solutions/ folder, we use ../ to find our data.\n\nlibrary(tidyverse)\n\n# Load the SUNY Enrollment data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n\n\n\nThe goal of this task was to create a ‚ÄúClean‚Äù version of our table by selecting 4 key columns, filtering for a specific sector, and renaming columns for better readability.\n\n\n\nSelect: We kept Term , Institution Sector, Total Enrollment, and Hispanic/Latino.\nRename: We shortened the names to semester, sector, total, and hispanic_latino.\nFilter: We narrowed the results to only show ‚ÄúCommunity Colleges‚Äù.\n\n\n# Create the cleaned object\ncleaned_suny &lt;- ny_data |&gt; \n  # Task 2: Select the 4 most important columns by their position\n  # This avoids \"Column not found\" errors caused by hidden spaces!\n  select(1, 2, 3, 6) |&gt; \n  \n  # Task 4: Rename the columns for clarity\n  # rename(new_name = old_position_or_name)\n  rename(semester = 1,\n         sector = 2,\n         total_enrollment = 3,\n         hispanic_latino = 4) |&gt; \n  \n  # Task 3: Filter for a specific category\n  filter(sector == \"Community Colleges\")\n\n# Task 5: Show the first 10 rows\nhead(cleaned_suny, n = 10)\n\n# A tibble: 10 √ó 4\n   semester  sector             total_enrollment hispanic_latino\n   &lt;chr&gt;     &lt;chr&gt;                         &lt;dbl&gt;           &lt;dbl&gt;\n 1 Fall 2019 Community Colleges           192959           31531\n 2 Fall 2018 Community Colleges           199873           31057\n 3 Fall 2017 Community Colleges           209418           30861\n 4 Fall 2016 Community Colleges           216277           30097\n 5 Fall 2015 Community Colleges           222998           29222\n 6 Fall 2014 Community Colleges           233812           28584\n 7 Fall 2013 Community Colleges           239791           27436\n 8 Fall 2012 Community Colleges           243007           25968\n 9 Fall 2011 Community Colleges           247667           24101\n10 Fall 2010 Community Colleges           249343           21809\n\n\n\n\n\nBy applying these transformations, we have turned a large dataset into a focused report.\n\nThe Observation: Each row now represents a specific semester‚Äôs enrollment data for the Community College sector.\nThe Benefit: Instead of 12 columns, we now have the 4 most important variables for analyzing Hispanic/Latino enrollment trends in community colleges.\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab12-ans-p9v2.html",
    "href": "solutions/lab12-ans-p9v2.html",
    "title": "Solution - Lab 12: Statistical inference for two means",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\nTo solve Lab 12, we perform a Two-Sample T-Test. This test is used to compare the means of a numeric variable across two distinct groups. Using your SUNY dataset, we will compare the average enrollment of Community Colleges versus Doctoral Degree Granting Institutions.\nHere is the complete solution for solutions/lab12-ans-q8w1.qmd, including all accessibility requirements."
  },
  {
    "objectID": "solutions/lab12-ans-p9v2.html#statistical-inference-for-two-means---official-solutions",
    "href": "solutions/lab12-ans-p9v2.html#statistical-inference-for-two-means---official-solutions",
    "title": "Solution - Lab 12: Statistical inference for two means",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\nTo solve Lab 12, we perform a Two-Sample T-Test. This test is used to compare the means of a numeric variable across two distinct groups. Using your SUNY dataset, we will compare the average enrollment of Community Colleges versus Doctoral Degree Granting Institutions.\nHere is the complete solution for solutions/lab12-ans-q8w1.qmd, including all accessibility requirements."
  },
  {
    "objectID": "solutions/lab14-ans-x2n8.html",
    "href": "solutions/lab14-ans-x2n8.html",
    "title": "Solution - Lab 14: Bootstrapping",
    "section": "",
    "text": "To solve Lab 14, we focus on Bootstrapping, a powerful non-parametric method for estimating the uncertainty of a statistic (like the Median) without assuming the data is normally distributed. ::: {.callout-note} ### Instructor Note Add your specific DCC lab answers below this box. ::: ## Lab 14 Official Solutions: Resampling Methods\nIn this lab, we use the infer package to estimate the 95% confidence interval for the median enrollment in the SUNY system using bootstrapping.\n\n\nWe load the necessary libraries and clean our numeric variable by removing commas from the ‚ÄúTotal Enrollment‚Äù column.\n\nlibrary(tidyverse)\nlibrary(infer) # Used for bootstrapping\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Clean numeric variable\nclean_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  filter(!is.na(total_enroll))\n\n\n\n\nBefore bootstrapping, we examine the original distribution of the data.\n\nggplot(clean_data, aes(x = total_enroll)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 15) +\n  labs(title = \"Original Enrollment Distribution\",\n       x = \"Total Students\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure¬†1: Histogram of the original SUNY enrollment data.\n\n\n\n\n\nObservation: The original data is strongly right-skewed. Because the distribution is not symmetrical, the Median is a better measure of the ‚Äútypical‚Äù enrollment than the Mean.\n\n\n\nWe use the infer pipeline to generate 1,000 bootstrap replicates of the median.\n\n# 1. Specify the variable\n# 2. Generate 1,000 resamples with replacement\n# 3. Calculate the median for each resample\nset.seed(123)\nboot_dist &lt;- clean_data |&gt;\n  specify(response = total_enroll) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  calculate(stat = \"median\")\n\n# Visualize the bootstrap distribution\n#| label: fig-boot-dist\n#| fig-cap: \"Distribution of 1,000 bootstrap medians.\"\n#| fig-alt: \"A histogram showing the distribution of the calculated medians from 1,000 bootstrap samples. The distribution is much more symmetrical and bell-shaped than the original data.\"\nvisualize(boot_dist) +\n  labs(title = \"Bootstrap Distribution of the Median\",\n       x = \"Bootstrap Median Enrollment\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nWe calculate the lower and upper bounds of our estimate using the percentile method.\n\n# Calculate the 95% Confidence Interval\npercentile_ci &lt;- boot_dist |&gt;\n  get_confidence_interval(level = 0.95, type = \"percentile\")\n\npercentile_ci\n\n# A tibble: 1 √ó 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1   88892.  101060.\n\n\n\n\n\nWhy do we ‚Äúsample with replacement‚Äù during bootstrapping?\nWe sample with replacement because we are treating our original sample as a ‚Äúpseudo-population.‚Äù By allowing the same observation to be picked more than once (or not at all) in a single bootstrap resample, we simulate the natural variation that would occur if we were able to take many new independent samples from the actual entire population. Without replacement, every resample would simply be identical to the original dataset, and we would have no way to measure the uncertainty of our statistic.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab14-ans-x2n8.html#bootstrapping---official-solutions",
    "href": "solutions/lab14-ans-x2n8.html#bootstrapping---official-solutions",
    "title": "Solution - Lab 14: Bootstrapping",
    "section": "",
    "text": "To solve Lab 14, we focus on Bootstrapping, a powerful non-parametric method for estimating the uncertainty of a statistic (like the Median) without assuming the data is normally distributed. ::: {.callout-note} ### Instructor Note Add your specific DCC lab answers below this box. ::: ## Lab 14 Official Solutions: Resampling Methods\nIn this lab, we use the infer package to estimate the 95% confidence interval for the median enrollment in the SUNY system using bootstrapping.\n\n\nWe load the necessary libraries and clean our numeric variable by removing commas from the ‚ÄúTotal Enrollment‚Äù column.\n\nlibrary(tidyverse)\nlibrary(infer) # Used for bootstrapping\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Clean numeric variable\nclean_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  filter(!is.na(total_enroll))\n\n\n\n\nBefore bootstrapping, we examine the original distribution of the data.\n\nggplot(clean_data, aes(x = total_enroll)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 15) +\n  labs(title = \"Original Enrollment Distribution\",\n       x = \"Total Students\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure¬†1: Histogram of the original SUNY enrollment data.\n\n\n\n\n\nObservation: The original data is strongly right-skewed. Because the distribution is not symmetrical, the Median is a better measure of the ‚Äútypical‚Äù enrollment than the Mean.\n\n\n\nWe use the infer pipeline to generate 1,000 bootstrap replicates of the median.\n\n# 1. Specify the variable\n# 2. Generate 1,000 resamples with replacement\n# 3. Calculate the median for each resample\nset.seed(123)\nboot_dist &lt;- clean_data |&gt;\n  specify(response = total_enroll) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  calculate(stat = \"median\")\n\n# Visualize the bootstrap distribution\n#| label: fig-boot-dist\n#| fig-cap: \"Distribution of 1,000 bootstrap medians.\"\n#| fig-alt: \"A histogram showing the distribution of the calculated medians from 1,000 bootstrap samples. The distribution is much more symmetrical and bell-shaped than the original data.\"\nvisualize(boot_dist) +\n  labs(title = \"Bootstrap Distribution of the Median\",\n       x = \"Bootstrap Median Enrollment\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nWe calculate the lower and upper bounds of our estimate using the percentile method.\n\n# Calculate the 95% Confidence Interval\npercentile_ci &lt;- boot_dist |&gt;\n  get_confidence_interval(level = 0.95, type = \"percentile\")\n\npercentile_ci\n\n# A tibble: 1 √ó 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1   88892.  101060.\n\n\n\n\n\nWhy do we ‚Äúsample with replacement‚Äù during bootstrapping?\nWe sample with replacement because we are treating our original sample as a ‚Äúpseudo-population.‚Äù By allowing the same observation to be picked more than once (or not at all) in a single bootstrap resample, we simulate the natural variation that would occur if we were able to take many new independent samples from the actual entire population. Without replacement, every resample would simply be identical to the original dataset, and we would have no way to measure the uncertainty of our statistic.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab11-ans-m1k5.html",
    "href": "solutions/lab11-ans-m1k5.html",
    "title": "Solution - Lab 11: Statistical inference for one proportion",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nWe load our dataset and count how many times ‚ÄúCommunity Colleges‚Äù appears compared to the total number of observations.\n\nlibrary(tidyverse)\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# 1. Count successes (Community Colleges)\nsuccesses &lt;- ny_data |&gt; \n  filter(`Institution Sector` == \"Community Colleges\") |&gt; \n  nrow()\n\n# 2. Count total observations\ntotal_n &lt;- nrow(ny_data)\n\n# Display counts\ntibble(Category = \"Community Colleges\", Successes = successes, Total = total_n)\n\n# A tibble: 1 √ó 3\n  Category           Successes Total\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Community Colleges        23    92\n\n\n\n\n\nWe are testing the claim that exactly one-quarter of our data entries come from the Community College sector.Null Hypothesis (\\(H_0\\)): The proportion of Community Colleges is 0.25 (\\(p = 0.25\\)).Alternative Hypothesis (\\(H_a\\)): The proportion of Community Colleges is not 0.25 (\\(p \\neq 0.25\\)).\n\n\n\nWe use prop.test() to determine if our sample proportion is significantly different from our hypothesized value of 0.25.\n\n# Run the proportion test\n# x = number of successes, n = total sample size, p = hypothesized proportion\nprop_results &lt;- prop.test(x = successes, n = total_n, p = 0.25)\n\n# Display results\nprop_results\n\n\n    1-sample proportions test without continuity correction\n\ndata:  successes out of total_n, null probability 0.25\nX-squared = 0, df = 1, p-value = 1\nalternative hypothesis: true p is not equal to 0.25\n95 percent confidence interval:\n 0.1727526 0.3472881\nsample estimates:\n   p \n0.25 \n\n\n\n\n\nWe visualize the frequency of each sector to show how the ‚ÄúSuccess‚Äù category compares to the others.\n\nggplot(ny_data, aes(x = `Institution Sector`)) +\n  geom_bar(fill = \"darkred\", color = \"black\") +\n  labs(title = \"Frequency of Institution Sectors\",\n       x = \"Sector\",\n       y = \"Number of Observations\") +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\n\n\n\nFigure¬†1: Bar chart showing the frequency of different SUNY Institution Sectors in the dataset.\n\n\n\n\n\n\n\n\nBased on the statistical output above, here is our formal summary:\n\nSample Proportion (\\(\\hat{p}\\)): The calculated sample proportion is r round(prop_results$estimate, 2).\nSignificance: The p-value is r round(prop_results$p.value, 4). Since this is greater than 0.05, our result is not significant.\nConfidence Interval: We are 95% confident that the true proportion of Community Colleges in this dataset lies between r round(prop_results\\(conf.int[1], 3) and r round(prop_results\\)conf.int[2], 3).\nConclusion: Since the p-value is 1 (or very high), we fail to reject the null hypothesis. There is no evidence to suggest the proportion is different from 0.25; in fact, it matches our hypothesis exactly.\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab11-ans-m1k5.html#statistical-inference-for-one-proportion---official-solutions",
    "href": "solutions/lab11-ans-m1k5.html#statistical-inference-for-one-proportion---official-solutions",
    "title": "Solution - Lab 11: Statistical inference for one proportion",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nWe load our dataset and count how many times ‚ÄúCommunity Colleges‚Äù appears compared to the total number of observations.\n\nlibrary(tidyverse)\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# 1. Count successes (Community Colleges)\nsuccesses &lt;- ny_data |&gt; \n  filter(`Institution Sector` == \"Community Colleges\") |&gt; \n  nrow()\n\n# 2. Count total observations\ntotal_n &lt;- nrow(ny_data)\n\n# Display counts\ntibble(Category = \"Community Colleges\", Successes = successes, Total = total_n)\n\n# A tibble: 1 √ó 3\n  Category           Successes Total\n  &lt;chr&gt;                  &lt;int&gt; &lt;int&gt;\n1 Community Colleges        23    92\n\n\n\n\n\nWe are testing the claim that exactly one-quarter of our data entries come from the Community College sector.Null Hypothesis (\\(H_0\\)): The proportion of Community Colleges is 0.25 (\\(p = 0.25\\)).Alternative Hypothesis (\\(H_a\\)): The proportion of Community Colleges is not 0.25 (\\(p \\neq 0.25\\)).\n\n\n\nWe use prop.test() to determine if our sample proportion is significantly different from our hypothesized value of 0.25.\n\n# Run the proportion test\n# x = number of successes, n = total sample size, p = hypothesized proportion\nprop_results &lt;- prop.test(x = successes, n = total_n, p = 0.25)\n\n# Display results\nprop_results\n\n\n    1-sample proportions test without continuity correction\n\ndata:  successes out of total_n, null probability 0.25\nX-squared = 0, df = 1, p-value = 1\nalternative hypothesis: true p is not equal to 0.25\n95 percent confidence interval:\n 0.1727526 0.3472881\nsample estimates:\n   p \n0.25 \n\n\n\n\n\nWe visualize the frequency of each sector to show how the ‚ÄúSuccess‚Äù category compares to the others.\n\nggplot(ny_data, aes(x = `Institution Sector`)) +\n  geom_bar(fill = \"darkred\", color = \"black\") +\n  labs(title = \"Frequency of Institution Sectors\",\n       x = \"Sector\",\n       y = \"Number of Observations\") +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\n\n\n\nFigure¬†1: Bar chart showing the frequency of different SUNY Institution Sectors in the dataset.\n\n\n\n\n\n\n\n\nBased on the statistical output above, here is our formal summary:\n\nSample Proportion (\\(\\hat{p}\\)): The calculated sample proportion is r round(prop_results$estimate, 2).\nSignificance: The p-value is r round(prop_results$p.value, 4). Since this is greater than 0.05, our result is not significant.\nConfidence Interval: We are 95% confident that the true proportion of Community Colleges in this dataset lies between r round(prop_results\\(conf.int[1], 3) and r round(prop_results\\)conf.int[2], 3).\nConclusion: Since the p-value is 1 (or very high), we fail to reject the null hypothesis. There is no evidence to suggest the proportion is different from 0.25; in fact, it matches our hypothesis exactly.\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab06-ans-w5q1.html",
    "href": "solutions/lab06-ans-w5q1.html",
    "title": "Solution - Lab 6: Data collection",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nThe student‚Äôs project folder must be organized correctly for the code to run.\nRequirements: 1. Source: NY State Open Data Portal. 2. File Format: CSV. 3. Location: The file race_ny.csv must be moved from ‚ÄúDownloads‚Äù into the data/ folder inside the RStudio Project.\n\n\n\n\nThis is an example of what the student should have written in their Quarto document:\n\n‚ÄúThis dataset, race_ny.csv, was obtained from the NY State Open Data Portal. The data was collected by New York State government agencies to track demographic participation. One row in this dataset represents a single recorded observation of an individual or event entry categorized by race and ethnicity for a specific year and location.‚Äù\n\n\n\n\n\nThe student must use read_csv() (from the tidyverse package) and head(..., n = 10).\n\n\n\n\n\n\nImportantPath Reminder\n\n\n\nSince this solution is inside the solutions/ folder, we use ../data/ to access the data folder. In the student‚Äôs main lab file, they would likely just use data/race_ny.csv.\n\n\n\n# 1. Load the necessary library\nlibrary(tidyverse)\n\n# 2. Load the data using the professional folder path\n# Replace 'race_ny.csv' with the actual name of your downloaded file\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# 3. Show the first 10 rows\nhead(ny_data, n = 10)\n\n# A tibble: 10 √ó 12\n   Term    `Institution Sector` `Total Enrollment`  White Black or African Ame‚Ä¶¬π\n   &lt;chr&gt;   &lt;chr&gt;                             &lt;dbl&gt;  &lt;dbl&gt;                  &lt;dbl&gt;\n 1 Fall 2‚Ä¶ Community Colleges               192959 109000                  22626\n 2 Fall 2‚Ä¶ Comprehensive Colle‚Ä¶              83674  51819                  10215\n 3 Fall 2‚Ä¶ Doctoral Degree Gra‚Ä¶             112265  51837                   9048\n 4 Fall 2‚Ä¶ Technology Colleges               26674  16050                   3336\n 5 Fall 2‚Ä¶ Community Colleges               199873 115352                  24025\n 6 Fall 2‚Ä¶ Comprehensive Colle‚Ä¶              85613  53566                  10527\n 7 Fall 2‚Ä¶ Doctoral Degree Gra‚Ä¶             111299  51711                   8952\n 8 Fall 2‚Ä¶ Technology Colleges               27266  16700                   3381\n 9 Fall 2‚Ä¶ Community Colleges               209418 120742                  25454\n10 Fall 2‚Ä¶ Comprehensive Colle‚Ä¶              86301  54882                  10417\n# ‚Ñπ abbreviated name: ¬π‚Äã`Black or African American`\n# ‚Ñπ 7 more variables: `Hispanic/Latino` &lt;dbl&gt;,\n#   `American Indian or Alaska Native` &lt;dbl&gt;,\n#   `Native Hawaiian or Other Pacific Islander` &lt;dbl&gt;,\n#   `Two or More Races` &lt;dbl&gt;, Asian &lt;dbl&gt;, `Non-resident Alien` &lt;dbl&gt;,\n#   Unknown &lt;dbl&gt;\n\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab06-ans-w5q1.html#data-collection---official-solutions",
    "href": "solutions/lab06-ans-w5q1.html#data-collection---official-solutions",
    "title": "Solution - Lab 6: Data collection",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nThe student‚Äôs project folder must be organized correctly for the code to run.\nRequirements: 1. Source: NY State Open Data Portal. 2. File Format: CSV. 3. Location: The file race_ny.csv must be moved from ‚ÄúDownloads‚Äù into the data/ folder inside the RStudio Project.\n\n\n\n\nThis is an example of what the student should have written in their Quarto document:\n\n‚ÄúThis dataset, race_ny.csv, was obtained from the NY State Open Data Portal. The data was collected by New York State government agencies to track demographic participation. One row in this dataset represents a single recorded observation of an individual or event entry categorized by race and ethnicity for a specific year and location.‚Äù\n\n\n\n\n\nThe student must use read_csv() (from the tidyverse package) and head(..., n = 10).\n\n\n\n\n\n\nImportantPath Reminder\n\n\n\nSince this solution is inside the solutions/ folder, we use ../data/ to access the data folder. In the student‚Äôs main lab file, they would likely just use data/race_ny.csv.\n\n\n\n# 1. Load the necessary library\nlibrary(tidyverse)\n\n# 2. Load the data using the professional folder path\n# Replace 'race_ny.csv' with the actual name of your downloaded file\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# 3. Show the first 10 rows\nhead(ny_data, n = 10)\n\n# A tibble: 10 √ó 12\n   Term    `Institution Sector` `Total Enrollment`  White Black or African Ame‚Ä¶¬π\n   &lt;chr&gt;   &lt;chr&gt;                             &lt;dbl&gt;  &lt;dbl&gt;                  &lt;dbl&gt;\n 1 Fall 2‚Ä¶ Community Colleges               192959 109000                  22626\n 2 Fall 2‚Ä¶ Comprehensive Colle‚Ä¶              83674  51819                  10215\n 3 Fall 2‚Ä¶ Doctoral Degree Gra‚Ä¶             112265  51837                   9048\n 4 Fall 2‚Ä¶ Technology Colleges               26674  16050                   3336\n 5 Fall 2‚Ä¶ Community Colleges               199873 115352                  24025\n 6 Fall 2‚Ä¶ Comprehensive Colle‚Ä¶              85613  53566                  10527\n 7 Fall 2‚Ä¶ Doctoral Degree Gra‚Ä¶             111299  51711                   8952\n 8 Fall 2‚Ä¶ Technology Colleges               27266  16700                   3381\n 9 Fall 2‚Ä¶ Community Colleges               209418 120742                  25454\n10 Fall 2‚Ä¶ Comprehensive Colle‚Ä¶              86301  54882                  10417\n# ‚Ñπ abbreviated name: ¬π‚Äã`Black or African American`\n# ‚Ñπ 7 more variables: `Hispanic/Latino` &lt;dbl&gt;,\n#   `American Indian or Alaska Native` &lt;dbl&gt;,\n#   `Native Hawaiian or Other Pacific Islander` &lt;dbl&gt;,\n#   `Two or More Races` &lt;dbl&gt;, Asian &lt;dbl&gt;, `Non-resident Alien` &lt;dbl&gt;,\n#   Unknown &lt;dbl&gt;\n\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab09-ans-f6p2.html",
    "href": "solutions/lab09-ans-f6p2.html",
    "title": "Solution - Lab 9: Probability distribution",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nWe load the tidyverse and import our dataset. Because our CSV uses commas inside numbers (e.g., ‚Äú192,959‚Äù), we must clean the data so R can perform calculations.\n\nlibrary(tidyverse)\n\n# Import the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Data Cleaning for Accessibility:\n# 1. Select 'Total Enrollment' (Column 3)\n# 2. Remove commas so R sees it as a number\nclean_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  filter(!is.na(total_enroll))\n\n\n\n\nWe create a histogram of total_enrollment to check for normality.\n\nggplot(clean_data, aes(x = total_enroll)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 20) +\n  labs(title = \"Distribution of SUNY Enrollment\",\n       x = \"Total Students\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure¬†1: Histogram showing the frequency distribution of total student enrollment across SUNY sectors.\n\n\n\n\n\nObservation: The data is not Normal. It is heavily skewed to the right. A ‚ÄúNormal‚Äù distribution would be symmetrical like a bell, but here most data is clustered on the left with a long tail on the right.\n\n\n\nWe find the mean (the center) and the standard deviation (the spread) for our variable.\n\ne_mean &lt;- mean(clean_data$total_enroll)\ne_sd &lt;- sd(clean_data$total_enroll)\n\n# Display results in an accessible table\ntibble(Metric = c(\"Mean (Center)\", \"Standard Deviation (Spread)\"), \n       Value = c(round(e_mean, 2), round(e_sd, 2)))\n\n# A tibble: 2 √ó 2\n  Metric                        Value\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 Mean (Center)               105701.\n2 Standard Deviation (Spread)  67729.\n\n\n\n\n\nThe Central Limit Theorem (CLT) tells us that if we take the average of many samples, that average will look normal, even if the original data does not.\nSmall Sample Size (n = 5)\n\nset.seed(123)\nsim_5 &lt;- replicate(1000, mean(sample(clean_data$total_enroll, 5, replace = TRUE)))\nhist(sim_5, col = \"skyblue\", border = \"white\", \n     main = \"Sample Size n = 5\", xlab = \"Sample Means\")\n\n\n\n\n\n\n\nFigure¬†2: CLT Simulation with a small sample size (n = 5).\n\n\n\n\n\nLarge Sample Size (n = 100)\n\nset.seed(123)\nsim_100 &lt;- replicate(1000, mean(sample(clean_data$total_enroll, 100, replace = TRUE)))\nhist(sim_100, col = \"darkblue\", border = \"white\", \n     main = \"Sample Size n = 100\", xlab = \"Sample Means\")\n\n\n\n\n\n\n\nFigure¬†3: CLT Simulation with a large sample size (n = 100).\n\n\n\n\n\n\n\n\nWhen the sample size increased from 5 to 100, the spread of the histogram became significantly narrower. The sample means became more concentrated around the true population mean, and the shape transformed into a clear, symmetrical bell curve. This demonstrates that larger samples provide more consistent and predictable estimates.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab09-ans-f6p2.html#probability-distribution---official-solutions",
    "href": "solutions/lab09-ans-f6p2.html#probability-distribution---official-solutions",
    "title": "Solution - Lab 9: Probability distribution",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nWe load the tidyverse and import our dataset. Because our CSV uses commas inside numbers (e.g., ‚Äú192,959‚Äù), we must clean the data so R can perform calculations.\n\nlibrary(tidyverse)\n\n# Import the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Data Cleaning for Accessibility:\n# 1. Select 'Total Enrollment' (Column 3)\n# 2. Remove commas so R sees it as a number\nclean_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  filter(!is.na(total_enroll))\n\n\n\n\nWe create a histogram of total_enrollment to check for normality.\n\nggplot(clean_data, aes(x = total_enroll)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 20) +\n  labs(title = \"Distribution of SUNY Enrollment\",\n       x = \"Total Students\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure¬†1: Histogram showing the frequency distribution of total student enrollment across SUNY sectors.\n\n\n\n\n\nObservation: The data is not Normal. It is heavily skewed to the right. A ‚ÄúNormal‚Äù distribution would be symmetrical like a bell, but here most data is clustered on the left with a long tail on the right.\n\n\n\nWe find the mean (the center) and the standard deviation (the spread) for our variable.\n\ne_mean &lt;- mean(clean_data$total_enroll)\ne_sd &lt;- sd(clean_data$total_enroll)\n\n# Display results in an accessible table\ntibble(Metric = c(\"Mean (Center)\", \"Standard Deviation (Spread)\"), \n       Value = c(round(e_mean, 2), round(e_sd, 2)))\n\n# A tibble: 2 √ó 2\n  Metric                        Value\n  &lt;chr&gt;                         &lt;dbl&gt;\n1 Mean (Center)               105701.\n2 Standard Deviation (Spread)  67729.\n\n\n\n\n\nThe Central Limit Theorem (CLT) tells us that if we take the average of many samples, that average will look normal, even if the original data does not.\nSmall Sample Size (n = 5)\n\nset.seed(123)\nsim_5 &lt;- replicate(1000, mean(sample(clean_data$total_enroll, 5, replace = TRUE)))\nhist(sim_5, col = \"skyblue\", border = \"white\", \n     main = \"Sample Size n = 5\", xlab = \"Sample Means\")\n\n\n\n\n\n\n\nFigure¬†2: CLT Simulation with a small sample size (n = 5).\n\n\n\n\n\nLarge Sample Size (n = 100)\n\nset.seed(123)\nsim_100 &lt;- replicate(1000, mean(sample(clean_data$total_enroll, 100, replace = TRUE)))\nhist(sim_100, col = \"darkblue\", border = \"white\", \n     main = \"Sample Size n = 100\", xlab = \"Sample Means\")\n\n\n\n\n\n\n\nFigure¬†3: CLT Simulation with a large sample size (n = 100).\n\n\n\n\n\n\n\n\nWhen the sample size increased from 5 to 100, the spread of the histogram became significantly narrower. The sample means became more concentrated around the true population mean, and the shape transformed into a clear, symmetrical bell curve. This demonstrates that larger samples provide more consistent and predictable estimates.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "labs/glossary.html",
    "href": "labs/glossary.html",
    "title": "Glossary of Data Science Terms",
    "section": "",
    "text": "Glossary of Data Science Terms\nThis glossary provides definitions for key terms used throughout MAT 186. If you encounter a term you don‚Äôt understand in the labs, check here first.\n\n\nC\nCRAN (Comprehensive R Archive Network): The global network of servers that stores and distributes R and its packages. Think of it as the ‚ÄúApp Store‚Äù for R.\n\n\nD\nData Frame: A table-like structure in R where each column represents a variable and each row represents an observation.\n\n\nI\nIDE (Integrated Development Environment): A software application (like RStudio) that provides comprehensive facilities to computer programmers for software development.\n\n\nM\nMarkdown: A lightweight markup language with plain-text-formatting syntax. It allows you to write formatted text that can be easily converted to HTML.\n\n\nQ\nQuarto: The next-generation version of RMarkdown. It is an open-source scientific and technical publishing system used to create documents, books, and websites.\n\n\nY\nYAML: Stands for ‚ÄúYet Another Markup Language.‚Äù In Quarto, the YAML header (at the top of the file) is where you define settings like the title, author, and output format.\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions"
  },
  {
    "objectID": "labs/lab17.html",
    "href": "labs/lab17.html",
    "title": "Lab 17: Linear Regression",
    "section": "",
    "text": "Understand the Linear Regression equation: \\(y = \\beta_0 + \\beta_1x + \\epsilon\\).\nCalculate and interpret the Correlation Coefficient (\\(r\\)).\nFit a Linear Model in R using the lm() function.\nEvaluate model fit using R-squared (\\(R^2\\)).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#learning-objectives",
    "href": "labs/lab17.html#learning-objectives",
    "title": "Lab 17: Linear Regression",
    "section": "",
    "text": "Understand the Linear Regression equation: \\(y = \\beta_0 + \\beta_1x + \\epsilon\\).\nCalculate and interpret the Correlation Coefficient (\\(r\\)).\nFit a Linear Model in R using the lm() function.\nEvaluate model fit using R-squared (\\(R^2\\)).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#data-acquisition-birth-weight-dataset-lbw.csv",
    "href": "labs/lab17.html#data-acquisition-birth-weight-dataset-lbw.csv",
    "title": "Lab 17: Linear Regression",
    "section": "Data Acquisition: Birth Weight Dataset (lbw.csv)",
    "text": "Data Acquisition: Birth Weight Dataset (lbw.csv)\nTo complete the regression exercises, you need the lbw.csv dataset. Choose one of the methods below to load the data into R.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#option-1-direct-link-recommended",
    "href": "labs/lab17.html#option-1-direct-link-recommended",
    "title": "Lab 17: Linear Regression",
    "section": "Option 1: Direct Link (Recommended)",
    "text": "Option 1: Direct Link (Recommended)\nThis method pulls the data directly from the lab manual website. ## Data Loading and Preview\nWe are using the lbw dataset, which contains information on low birth weight.\n\nAccessible Logic: We use the read_csv() function to pull data from a web URL. After loading, it is important to check the ‚Äúhead‚Äù (the first 6 rows) to ensure the columns and values imported correctly.\n\n\nlibrary(tidyverse)\n\n# 1. Load the data\nurl &lt;- url &lt;- \"https://vincentarelbundock.github.io/Rdatasets/csv/COUNT/lbw.csv\"\nlbw_data &lt;- read_csv(url)\n\n# 2. Display an accessible preview\n# We use head() to get the first 6 rows and kable() to make it a table\nknitr::kable(head(lbw_data))\n\n\n\nTable¬†1: Preview of the first six rows of the low birth weight (LBW) dataset.\n\n\n\n\n\n\nrownames\nlow\nsmoke\nrace\nage\nlwt\nptl\nht\nui\nftv\nbwt\n\n\n\n\n1\n0\n0\n2\n19\n182\n0\n0\n1\n0\n2523\n\n\n2\n0\n0\n3\n33\n155\n0\n0\n0\n3\n2551\n\n\n3\n0\n1\n1\n20\n105\n0\n0\n0\n1\n2557\n\n\n4\n0\n1\n1\n21\n108\n0\n0\n1\n2\n2594\n\n\n5\n0\n1\n1\n18\n107\n0\n0\n1\n0\n2600\n\n\n6\n0\n0\n3\n21\n124\n0\n0\n0\n0\n2622",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#option-2-local-file",
    "href": "labs/lab17.html#option-2-local-file",
    "title": "Lab 17: Linear Regression",
    "section": "Option 2: Local File",
    "text": "Option 2: Local File\nUse this if the file is saved in your project folder. ## Loading Data Locally\nTo ensure this lab is reproducible, we are loading the birth weight data from our project‚Äôs data folder.\n\nAccessible Logic: The path \"data/lbw.csv\" tells R to look inside a folder named data that is located in the same place as your script. This is called a relative path.\n\n\n# 1. Load the data using a relative path\n# Ensure the 'data' folder exists in your RStudio project\nlbw_data &lt;- read.csv(\"../data/2026_Fall/lbw.csv\")\n\n# 2. Accessible Preview\nknitr::kable(head(lbw_data))\n\n\n\nTable¬†2: Preview of the locally loaded LBW dataset.\n\n\n\n\n\n\nrownames\nlow\nsmoke\nrace\nage\nlwt\nptl\nht\nui\nftv\nbwt\n\n\n\n\n1\n0\n0\n2\n19\n182\n0\n0\n1\n0\n2523\n\n\n2\n0\n0\n3\n33\n155\n0\n0\n0\n3\n2551\n\n\n3\n0\n1\n1\n20\n105\n0\n0\n0\n1\n2557\n\n\n4\n0\n1\n1\n21\n108\n0\n0\n1\n2\n2594\n\n\n5\n0\n1\n1\n18\n107\n0\n0\n1\n0\n2600\n\n\n6\n0\n0\n3\n21\n124\n0\n0\n0\n0\n2622",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#part-1-correlation-r",
    "href": "labs/lab17.html#part-1-correlation-r",
    "title": "Lab 17: Linear Regression",
    "section": "Part 1: Correlation (\\(r\\))",
    "text": "Part 1: Correlation (\\(r\\))\nBefore building a model, we need to know if a linear relationship even exists. The correlation coefficient (\\(r\\)) ranges from -1 to 1.\n\n1: Perfect positive relationship.\n0: No relationship at all.\n-1: Perfect negative relationship.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#correlation-analysis-mothers-weight-vs.-birth-weight",
    "href": "labs/lab17.html#correlation-analysis-mothers-weight-vs.-birth-weight",
    "title": "Lab 17: Linear Regression",
    "section": "Correlation Analysis: Mother‚Äôs Weight vs.¬†Birth Weight",
    "text": "Correlation Analysis: Mother‚Äôs Weight vs.¬†Birth Weight\nWe are calculating Pearson‚Äôs correlation coefficient to see if there is a linear relationship between the mother‚Äôs weight at the last menstrual period (lwt) and the baby‚Äôs birth weight (bwt).\n\nAccessible Logic: Correlation (\\(r\\)) ranges from -1 to +1. A value of 0 means no linear relationship, while values closer to +1 or -1 indicate stronger relationships.\n\n\nlibrary(tidyverse)\n\n# 1. Calculate the correlation\ncor_result &lt;- lbw_data |&gt;\n  drop_na(lwt, bwt) |&gt;\n  summarize(correlation = cor(lwt, bwt))\n\n# 2. Display as an accessible table\nknitr::kable(\n  cor_result,\n  col.names = c(\"Correlation Coefficient (r)\"),\n  digits = 3\n)\n\n\n\nTable¬†3: Pearson Correlation Coefficient between Mother‚Äôs Weight and Birth Weight.\n\n\n\n\n\n\nCorrelation Coefficient (r)\n\n\n\n\n0.186",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#part-2-visualizing-the-best-fit-line",
    "href": "labs/lab17.html#part-2-visualizing-the-best-fit-line",
    "title": "Lab 17: Linear Regression",
    "section": "Part 2: Visualizing the Best Fit Line",
    "text": "Part 2: Visualizing the Best Fit Line\nWe use geom_smooth(method = \"lm\") to draw the line that minimizes the distance between all data points (the ‚ÄúOrdinary Least Squares‚Äù method).\n\nggplot(lbw_data, aes(x = lwt, y = bwt)) +\n  geom_point(alpha = 0.5, color = \"#002147\") + # DCC Navy\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  theme_minimal() +\n  labs(title = \"Predicting Birth Weight based on Mother's Weight\",\n       x = \"Mother's Weight (lbs)\",\n       y = \"Birth Weight (grams)\")\n\n\n\n\n\n\n\nFigure¬†1: Regression of Birth Weight on Mother‚Äôs Weight",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#part-3-building-the-model-in-r",
    "href": "labs/lab17.html#part-3-building-the-model-in-r",
    "title": "Lab 17: Linear Regression",
    "section": "Part 3: Building the Model in R",
    "text": "Part 3: Building the Model in R\nIn R, the ‚ÄúLinear Model‚Äù function is lm(). The syntax is lm(dependent_variable ~ independent_variable).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#simple-linear-regression-predicting-birth-weight",
    "href": "labs/lab17.html#simple-linear-regression-predicting-birth-weight",
    "title": "Lab 17: Linear Regression",
    "section": "Simple Linear Regression: Predicting Birth Weight",
    "text": "Simple Linear Regression: Predicting Birth Weight\nWe are fitting a linear model to see how well Mother‚Äôs Weight (lwt) predicts Birth Weight (bwt).\n\nAccessible Logic: We are looking for the equation of a line: \\[bwt = \\beta_0 + \\beta_1(lwt)\\]. * The Intercept (\\(\\beta_0\\)) is the predicted birth weight if the mother‚Äôs weight was zero. * The Slope (\\(\\beta_1\\)) tells us how many grams the birth weight increases for every 1-pound increase in mother‚Äôs weight.\n\n\nlibrary(broom)\n\n# 1. Fit the model\nlbw_model &lt;- lm(bwt ~ lwt, data = lbw_data)\n\n# 2. Tidy the coefficients into an accessible table\nmodel_stats &lt;- tidy(lbw_model)\n\nknitr::kable(\n  model_stats,\n  col.names = c(\"Term\", \"Estimate\", \"Std. Error\", \"t-statistic\", \"p-value\"),\n  digits = 3\n)\n\n\n\nTable¬†4: Regression coefficients for predicting Birth Weight from Mother‚Äôs Weight.\n\n\n\n\n\n\nTerm\nEstimate\nStd. Error\nt-statistic\np-value\n\n\n\n\n(Intercept)\n2369.184\n228.467\n10.370\n0.00\n\n\nlwt\n4.430\n1.713\n2.586\n0.01\n\n\n\n\n\n\n\n\n\n\nHow to interpret the summary:\n\nIntercept (\\(\\beta_0\\)): The predicted value of \\(y\\) when \\(x\\) is zero.\nSlope (\\(\\beta_1\\)): For every 1 unit increase in \\(x\\), how much \\(y\\) is expected to change.\nR-squared (\\(R^2\\)): The percentage of variation in \\(y\\) explained by your model. (e.g., \\(0.75\\) means your model explains 75% of the data).",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab17.html#part-4-making-predictions",
    "href": "labs/lab17.html#part-4-making-predictions",
    "title": "Lab 17: Linear Regression",
    "section": "Part 4: Making Predictions",
    "text": "Part 4: Making Predictions\nOnce you have a model, you can plug in a value for \\(x\\) to predict \\(y\\). If our model is \\(Mass = -100 + 1.2(Height)\\), we can predict the mass of a character who is 200cm tall. ## Model Prediction: 150lb Mother\nUsing our regression model, we can predict the specific birth weight for a baby based on the mother‚Äôs weight.\n\nAccessible Logic: We are plugging 150 into our regression equation (\\(y = mx + b\\)). The predict() function calculates this value for us automatically using the model we previously fitted.\n\n\n# 1. Create a data frame for the input (required by the predict function)\nnew_mom &lt;- data.frame(lwt = 150)\n\n# 2. Run the prediction\nprediction_val &lt;- predict(lbw_model, newdata = new_mom)\n\n# 3. Present the result in a clear, single-row table\nprediction_table &lt;- data.frame(\n  input_lwt = 150,\n  predicted_bwt = prediction_val\n)\n\nknitr::kable(\n  prediction_table,\n  col.names = c(\"Mother's Weight (lbs)\", \"Predicted Birth Weight (g)\"),\n  digits = 2\n)\n\n\n\nTable¬†5: Predicted Birth Weight for a mother weighing 150 lbs.\n\n\n\n\n\n\nMother‚Äôs Weight (lbs)\nPredicted Birth Weight (g)\n\n\n\n\n150\n3033.68\n\n\n\n\n\n\n\n\n\n\nLab Task 17:\n\nPick two numeric variables from your dataset that you think are related.\nCreate a Scatter Plot and add a linear regression line.\nUse the cor() function to find the correlation coefficient.\nFit a linear model using lm() and look at the summary().\nThe Report:\n\nWhat is the slope of your model?\nWhat is the \\(R^2\\) value?\nUse your model to make one prediction for a value not in your dataset.\n\n\n\n\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 17: Regression models"
    ]
  },
  {
    "objectID": "labs/lab04.html",
    "href": "labs/lab04.html",
    "title": "Lab 4: Creating Your Data Science Portfolio on GitHub",
    "section": "",
    "text": "Create a personal GitHub account.\nInitialize a new repository for MAT 186 work.\nUnderstand the ‚ÄúCommit‚Äù and ‚ÄúPush‚Äù workflow.\nHost a live version of a lab report using GitHub Pages.\n\n\n\n\n\nData Science is a collaborative field. GitHub is the industry standard for version control and sharing code. In this lab, you will set up your own ‚Äúportfolio‚Äù‚Äîa place where you can showcase the work you do in this class to future employers or transfer institutions.\n\n\n\n\n\nGo to GitHub.com.\nSign up for a free account.\n\nTip: Choose a professional username (e.g., jsmith-dcc), as you may show this to employers later!\n\nVerify your email address.\n\n\n\n\n\nA Repository (or ‚ÄúRepo‚Äù) is like a project folder that lives in the cloud.\n\nClick the + icon in the top right and select New repository.\nRepository name: mat186-work\nDescription: ‚ÄúLabs and projects for Introduction to Data Science at DCC.‚Äù\nPublic/Private: Select Public.\nCheck the box that says Add a README file.\nClick Create repository.\n\n\n\n\n\nNow, let‚Äôs add the work you‚Äôve done in previous labs.\n\nIn your new mat186-work repository, click Add file &gt; Upload files.\nDrag and drop your HTML files from Lab 2 and Lab 3 into the browser.\nAt the bottom, type a ‚ÄúCommit message‚Äù like: Initial upload of Lab 2 and 3.\nClick Commit changes.\n\n\n\n\n\nLet‚Äôs make your lab reports viewable as actual websites.\n\nGo to your repository Settings tab.\nOn the left menu, click Pages.\nUnder Build and deployment, set the Branch to main and click Save.\nAfter a minute, GitHub will give you a URL (e.g., https://username.github.io/mat186-work/).\n\n\n\nLab Task 4:\n\nCreate your mat186-work repository.\nUpload the HTML version of your Lab 3 (Math Formulas).\nEnable GitHub Pages.\nPaste the link to your live GitHub Page into the Brightspace assignment.\n\n\n\n\n\nBy putting your work on GitHub, you are participating in Open Science. This allows others to learn from your code and allows you to track your own progress throughout the semester!\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 4: GitHub Repository"
    ]
  },
  {
    "objectID": "labs/lab04.html#learning-objectives",
    "href": "labs/lab04.html#learning-objectives",
    "title": "Lab 4: Creating Your Data Science Portfolio on GitHub",
    "section": "",
    "text": "Create a personal GitHub account.\nInitialize a new repository for MAT 186 work.\nUnderstand the ‚ÄúCommit‚Äù and ‚ÄúPush‚Äù workflow.\nHost a live version of a lab report using GitHub Pages.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 4: GitHub Repository"
    ]
  },
  {
    "objectID": "labs/lab04.html#introduction",
    "href": "labs/lab04.html#introduction",
    "title": "Lab 4: Creating Your Data Science Portfolio on GitHub",
    "section": "",
    "text": "Data Science is a collaborative field. GitHub is the industry standard for version control and sharing code. In this lab, you will set up your own ‚Äúportfolio‚Äù‚Äîa place where you can showcase the work you do in this class to future employers or transfer institutions.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 4: GitHub Repository"
    ]
  },
  {
    "objectID": "labs/lab04.html#part-1-setting-up-your-account",
    "href": "labs/lab04.html#part-1-setting-up-your-account",
    "title": "Lab 4: Creating Your Data Science Portfolio on GitHub",
    "section": "",
    "text": "Go to GitHub.com.\nSign up for a free account.\n\nTip: Choose a professional username (e.g., jsmith-dcc), as you may show this to employers later!\n\nVerify your email address.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 4: GitHub Repository"
    ]
  },
  {
    "objectID": "labs/lab04.html#part-2-creating-your-first-repository",
    "href": "labs/lab04.html#part-2-creating-your-first-repository",
    "title": "Lab 4: Creating Your Data Science Portfolio on GitHub",
    "section": "",
    "text": "A Repository (or ‚ÄúRepo‚Äù) is like a project folder that lives in the cloud.\n\nClick the + icon in the top right and select New repository.\nRepository name: mat186-work\nDescription: ‚ÄúLabs and projects for Introduction to Data Science at DCC.‚Äù\nPublic/Private: Select Public.\nCheck the box that says Add a README file.\nClick Create repository.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 4: GitHub Repository"
    ]
  },
  {
    "objectID": "labs/lab04.html#part-3-uploading-your-lab-reports",
    "href": "labs/lab04.html#part-3-uploading-your-lab-reports",
    "title": "Lab 4: Creating Your Data Science Portfolio on GitHub",
    "section": "",
    "text": "Now, let‚Äôs add the work you‚Äôve done in previous labs.\n\nIn your new mat186-work repository, click Add file &gt; Upload files.\nDrag and drop your HTML files from Lab 2 and Lab 3 into the browser.\nAt the bottom, type a ‚ÄúCommit message‚Äù like: Initial upload of Lab 2 and 3.\nClick Commit changes.",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 4: GitHub Repository"
    ]
  },
  {
    "objectID": "labs/lab04.html#part-4-publishing-with-github-pages",
    "href": "labs/lab04.html#part-4-publishing-with-github-pages",
    "title": "Lab 4: Creating Your Data Science Portfolio on GitHub",
    "section": "",
    "text": "Let‚Äôs make your lab reports viewable as actual websites.\n\nGo to your repository Settings tab.\nOn the left menu, click Pages.\nUnder Build and deployment, set the Branch to main and click Save.\nAfter a minute, GitHub will give you a URL (e.g., https://username.github.io/mat186-work/).\n\n\n\nLab Task 4:\n\nCreate your mat186-work repository.\nUpload the HTML version of your Lab 3 (Math Formulas).\nEnable GitHub Pages.\nPaste the link to your live GitHub Page into the Brightspace assignment.\n\n\n\n\n\nBy putting your work on GitHub, you are participating in Open Science. This allows others to learn from your code and allows you to track your own progress throughout the semester!\n\n\n\n\n\n\n\nTipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions",
    "crumbs": [
      "Home",
      "Course Labs",
      "Lab 4: GitHub Repository"
    ]
  },
  {
    "objectID": "solutions/lab05-ans-t8j3.html",
    "href": "solutions/lab05-ans-t8j3.html",
    "title": "Solution - Lab 5: Getting data into R",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nStudents were required to download the lbw.csv dataset. Success in this task is confirmed by the file appearing in the project directory.\n\n\n\nTo import the data correctly using the Tidyverse, the library(tidyverse) must be called first. We use read_csv() to create a tibble.\n\nlibrary(tidyverse)\n\n# Task 2: Import the data\n# Assumes 'lbw.csv' is in the same folder as this .qmd file\nlbw_data &lt;- read_csv(\"../data/lbw.csv\")"
  },
  {
    "objectID": "solutions/lab05-ans-t8j3.html#getting-data-into-r---official-solutions",
    "href": "solutions/lab05-ans-t8j3.html#getting-data-into-r---official-solutions",
    "title": "Solution - Lab 5: Getting data into R",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nStudents were required to download the lbw.csv dataset. Success in this task is confirmed by the file appearing in the project directory.\n\n\n\nTo import the data correctly using the Tidyverse, the library(tidyverse) must be called first. We use read_csv() to create a tibble.\n\nlibrary(tidyverse)\n\n# Task 2: Import the data\n# Assumes 'lbw.csv' is in the same folder as this .qmd file\nlbw_data &lt;- read_csv(\"../data/lbw.csv\")"
  },
  {
    "objectID": "solutions/lab17-ans-a6t2.html",
    "href": "solutions/lab17-ans-a6t2.html",
    "title": "Solution - Lab 17: Regression models",
    "section": "",
    "text": "To solve Lab 17, we focus on Correlation and Simple Linear Regression. This lab allows us to model the relationship between two numeric variables. In your SUNY dataset, we will investigate how Total Enrollment (the independent variable) predicts the number of Hispanic/Latino students (the dependent variable). ::: {.callout-note} ### Instructor Note Add your specific DCC lab answers below this box. :::"
  },
  {
    "objectID": "solutions/lab17-ans-a6t2.html#regression-models---official-solutions",
    "href": "solutions/lab17-ans-a6t2.html#regression-models---official-solutions",
    "title": "Solution - Lab 17: Regression models",
    "section": "",
    "text": "To solve Lab 17, we focus on Correlation and Simple Linear Regression. This lab allows us to model the relationship between two numeric variables. In your SUNY dataset, we will investigate how Total Enrollment (the independent variable) predicts the number of Hispanic/Latino students (the dependent variable). ::: {.callout-note} ### Instructor Note Add your specific DCC lab answers below this box. :::"
  },
  {
    "objectID": "solutions/lab10-ans-g4d8.html",
    "href": "solutions/lab10-ans-g4d8.html",
    "title": "Solution - Lab 10: Statistical inference for one mean",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nAs in previous labs, we must clean the Total Enrollment column by removing commas and converting it to a numeric format to ensure the t.test() function can process the data correctly.\n\nlibrary(tidyverse)\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Clean numeric variable for accessibility and analysis\nclean_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  filter(!is.na(total_enroll))\n\n\n\n\nWe want to test if the true mean enrollment across all SUNY sectors is significantly different from 100,000 students.\n\nNull Hypothesis (\\(H_0\\)): The mean enrollment is equal to 100,000 (\\(\\mu = 100,000\\)).\nAlternative Hypothesis (\\(H_a\\)): The mean enrollment is not equal to 100,000 (\\(\\mu \\neq 100,000\\)).\n\n\n\n\nWe use the t.test() function in R. We set mu = 100000 to test our hypothesis.\n\n# Perform the t-test\ntest_results &lt;- t.test(clean_data$total_enroll, mu = 100000)\n\n# Display the results\ntest_results\n\n\n    One Sample t-test\n\ndata:  clean_data$total_enroll\nt = 0.80733, df = 91, p-value = 0.4216\nalternative hypothesis: true mean is not equal to 1e+05\n95 percent confidence interval:\n  91674.45 119726.98\nsample estimates:\nmean of x \n 105700.7 \n\n\n\n\n\nTo provide context for our test, we visualize the data distribution relative to our test value (\\(\\mu\\)).\n\nggplot(clean_data, aes(x = total_enroll)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 15) +\n  geom_vline(xintercept = 100000, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Enrollment Distribution vs. Null Hypothesis\",\n       x = \"Total Enrollment\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure¬†1: Histogram of enrollment with the null hypothesis mean (100,000) marked as a dashed red line.\n\n\n\n\n\n\n\n\nBased on the results of our t-test:\nFormal Conclusion: Since the p-value was r round(test_results$p.value, 4), which is greater than the standard alpha level of 0.05, we fail to reject the null hypothesis. There is not sufficient evidence to suggest that the mean enrollment is significantly different from 100,000.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab10-ans-g4d8.html#statistical-inference-for-one-mean---official-solutions",
    "href": "solutions/lab10-ans-g4d8.html#statistical-inference-for-one-mean---official-solutions",
    "title": "Solution - Lab 10: Statistical inference for one mean",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nAs in previous labs, we must clean the Total Enrollment column by removing commas and converting it to a numeric format to ensure the t.test() function can process the data correctly.\n\nlibrary(tidyverse)\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Clean numeric variable for accessibility and analysis\nclean_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  filter(!is.na(total_enroll))\n\n\n\n\nWe want to test if the true mean enrollment across all SUNY sectors is significantly different from 100,000 students.\n\nNull Hypothesis (\\(H_0\\)): The mean enrollment is equal to 100,000 (\\(\\mu = 100,000\\)).\nAlternative Hypothesis (\\(H_a\\)): The mean enrollment is not equal to 100,000 (\\(\\mu \\neq 100,000\\)).\n\n\n\n\nWe use the t.test() function in R. We set mu = 100000 to test our hypothesis.\n\n# Perform the t-test\ntest_results &lt;- t.test(clean_data$total_enroll, mu = 100000)\n\n# Display the results\ntest_results\n\n\n    One Sample t-test\n\ndata:  clean_data$total_enroll\nt = 0.80733, df = 91, p-value = 0.4216\nalternative hypothesis: true mean is not equal to 1e+05\n95 percent confidence interval:\n  91674.45 119726.98\nsample estimates:\nmean of x \n 105700.7 \n\n\n\n\n\nTo provide context for our test, we visualize the data distribution relative to our test value (\\(\\mu\\)).\n\nggplot(clean_data, aes(x = total_enroll)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 15) +\n  geom_vline(xintercept = 100000, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Enrollment Distribution vs. Null Hypothesis\",\n       x = \"Total Enrollment\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure¬†1: Histogram of enrollment with the null hypothesis mean (100,000) marked as a dashed red line.\n\n\n\n\n\n\n\n\nBased on the results of our t-test:\nFormal Conclusion: Since the p-value was r round(test_results$p.value, 4), which is greater than the standard alpha level of 0.05, we fail to reject the null hypothesis. There is not sufficient evidence to suggest that the mean enrollment is significantly different from 100,000.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab13-ans-c7w4.html",
    "href": "solutions/lab13-ans-c7w4.html",
    "title": "Solution - Lab 13: Statistical inference for two proportions",
    "section": "",
    "text": "In this lab, we compare the proportion of ‚ÄúSuccesses‚Äù (which we will define as Hispanic/Latino student enrollment) between two distinct groups (Community Colleges and Doctoral Institutions). ::: {.callout-note} ### Instructor Note Add your specific DCC lab answers below this box. ::: ## Lab 13 Official Solutions: Two-Sample Proportion Inference\nIn this lab, we test whether the proportion of Hispanic/Latino students differs significantly between Community Colleges and Doctoral Institutions.\n\n\nOur dataset provides counts. To create a ‚ÄúSuccess/Failure‚Äù comparison, we define ‚ÄúSuccess‚Äù as being a Hispanic/Latino student and ‚ÄúFailure‚Äù as being any other student within that sector.\n\nlibrary(tidyverse)\n\n# Load and clean the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# 1. Clean numeric columns and filter for two groups\ncomparison_data &lt;- ny_data |&gt;\n  mutate(\n    total = as.numeric(gsub(\",\", \"\", `Total Enrollment`)),\n    hispanic = as.numeric(gsub(\",\", \"\", `Hispanic/Latino`)),\n    other = total - hispanic\n  ) |&gt;\n  filter(`Institution Sector` %in% c(\"Community Colleges\", \"Doctoral Degree Granting Institutions\")) |&gt;\n  group_by(`Institution Sector`) |&gt;\n  summarise(\n    total_hispanic = sum(hispanic, na.rm = TRUE),\n    total_other = sum(other, na.rm = TRUE),\n    total_n = sum(total, na.rm = TRUE)\n  )\n\n\n\n\nWe use position = ‚Äúfill‚Äù to create a chart that compares the relative proportions (the percentage) rather than the raw counts.\n\n# Reshape data for plotting\nplot_data &lt;- comparison_data |&gt;\n  pivot_longer(cols = c(total_hispanic, total_other), \n               names_to = \"Outcome\", \n               values_to = \"Count\")\n\nggplot(plot_data, aes(x = `Institution Sector`, y = Count, fill = Outcome)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  scale_y_continuous(labels = scales::percent) +\n  scale_fill_manual(values = c(\"darkorange\", \"grey80\"), \n                    labels = c(\"Hispanic/Latino\", \"Other\")) +\n  labs(title = \"Proportion of Hispanic/Latino Enrollment\",\n       x = \"Institution Sector\",\n       y = \"Percentage of Total Enrollment\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure¬†1: Stacked bar chart showing the proportion of Hispanic/Latino students versus other students by sector.\n\n\n\n\n\n\n\n\nWe are testing if the proportion of Hispanic/Latino students is the same in both sectors.\n\nNull Hypothesis (\\(H_0\\)): The proportion of Hispanic students is the same in both sectors (\\(p_1 = p_2\\)).\nAlternative Hypothesis (\\(H_a\\)): The proportion of Hispanic students is different between the two sectors (\\(p_1 \\neq p_2\\)).\n\n\n\n\nWe use prop.test() by providing the vector of successes and the vector of total sample sizes.\n\n# Run the test\n# successes = c(Group1_Success, Group2_Success)\n# totals = c(Group1_Total, Group2_Total)\np_test &lt;- prop.test(x = comparison_data$total_hispanic, \n                    n = comparison_data$total_n)\n\n# Display results\np_test\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  comparison_data$total_hispanic out of comparison_data$total_n\nX-squared = 20695, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n95 percent confidence interval:\n 0.03416619 0.03505954\nsample estimates:\n    prop 1     prop 2 \n0.11420780 0.07959493 \n\n\n\n\n\nBased on the statistical analysis:\nFormal Conclusion: Since the p-value was r format.pval(p_test$p.value, digits = 4), which is less than the alpha level of 0.05, we reject the null hypothesis and conclude there is a significant difference in the proportions of Hispanic/Latino students between Community Colleges and Doctoral Institutions.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab13-ans-c7w4.html#statistical-inference-for-two-proportions---official-solutions",
    "href": "solutions/lab13-ans-c7w4.html#statistical-inference-for-two-proportions---official-solutions",
    "title": "Solution - Lab 13: Statistical inference for two proportions",
    "section": "",
    "text": "In this lab, we compare the proportion of ‚ÄúSuccesses‚Äù (which we will define as Hispanic/Latino student enrollment) between two distinct groups (Community Colleges and Doctoral Institutions). ::: {.callout-note} ### Instructor Note Add your specific DCC lab answers below this box. ::: ## Lab 13 Official Solutions: Two-Sample Proportion Inference\nIn this lab, we test whether the proportion of Hispanic/Latino students differs significantly between Community Colleges and Doctoral Institutions.\n\n\nOur dataset provides counts. To create a ‚ÄúSuccess/Failure‚Äù comparison, we define ‚ÄúSuccess‚Äù as being a Hispanic/Latino student and ‚ÄúFailure‚Äù as being any other student within that sector.\n\nlibrary(tidyverse)\n\n# Load and clean the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# 1. Clean numeric columns and filter for two groups\ncomparison_data &lt;- ny_data |&gt;\n  mutate(\n    total = as.numeric(gsub(\",\", \"\", `Total Enrollment`)),\n    hispanic = as.numeric(gsub(\",\", \"\", `Hispanic/Latino`)),\n    other = total - hispanic\n  ) |&gt;\n  filter(`Institution Sector` %in% c(\"Community Colleges\", \"Doctoral Degree Granting Institutions\")) |&gt;\n  group_by(`Institution Sector`) |&gt;\n  summarise(\n    total_hispanic = sum(hispanic, na.rm = TRUE),\n    total_other = sum(other, na.rm = TRUE),\n    total_n = sum(total, na.rm = TRUE)\n  )\n\n\n\n\nWe use position = ‚Äúfill‚Äù to create a chart that compares the relative proportions (the percentage) rather than the raw counts.\n\n# Reshape data for plotting\nplot_data &lt;- comparison_data |&gt;\n  pivot_longer(cols = c(total_hispanic, total_other), \n               names_to = \"Outcome\", \n               values_to = \"Count\")\n\nggplot(plot_data, aes(x = `Institution Sector`, y = Count, fill = Outcome)) +\n  geom_bar(stat = \"identity\", position = \"fill\") +\n  scale_y_continuous(labels = scales::percent) +\n  scale_fill_manual(values = c(\"darkorange\", \"grey80\"), \n                    labels = c(\"Hispanic/Latino\", \"Other\")) +\n  labs(title = \"Proportion of Hispanic/Latino Enrollment\",\n       x = \"Institution Sector\",\n       y = \"Percentage of Total Enrollment\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure¬†1: Stacked bar chart showing the proportion of Hispanic/Latino students versus other students by sector.\n\n\n\n\n\n\n\n\nWe are testing if the proportion of Hispanic/Latino students is the same in both sectors.\n\nNull Hypothesis (\\(H_0\\)): The proportion of Hispanic students is the same in both sectors (\\(p_1 = p_2\\)).\nAlternative Hypothesis (\\(H_a\\)): The proportion of Hispanic students is different between the two sectors (\\(p_1 \\neq p_2\\)).\n\n\n\n\nWe use prop.test() by providing the vector of successes and the vector of total sample sizes.\n\n# Run the test\n# successes = c(Group1_Success, Group2_Success)\n# totals = c(Group1_Total, Group2_Total)\np_test &lt;- prop.test(x = comparison_data$total_hispanic, \n                    n = comparison_data$total_n)\n\n# Display results\np_test\n\n\n    2-sample test for equality of proportions with continuity correction\n\ndata:  comparison_data$total_hispanic out of comparison_data$total_n\nX-squared = 20695, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n95 percent confidence interval:\n 0.03416619 0.03505954\nsample estimates:\n    prop 1     prop 2 \n0.11420780 0.07959493 \n\n\n\n\n\nBased on the statistical analysis:\nFormal Conclusion: Since the p-value was r format.pval(p_test$p.value, digits = 4), which is less than the alpha level of 0.05, we reject the null hypothesis and conclude there is a significant difference in the proportions of Hispanic/Latino students between Community Colleges and Doctoral Institutions.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab16-ans-y3l9.html",
    "href": "solutions/lab16-ans-y3l9.html",
    "title": "Solution - Lab 16: Analysis of variance (ANOVA)",
    "section": "",
    "text": "To solve Lab 16, we focus on ANOVA (Analysis of Variance). This statistical method is used to compare the means of three or more groups to see if at least one is significantly different from the others. In your SUNY dataset, the ‚ÄúInstitution Sector‚Äù has 4 distinct categories, making it perfect for this test.\n\n\n\n\n\n\nNoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box."
  },
  {
    "objectID": "solutions/lab16-ans-y3l9.html#analysis-of-variance-anova---official-solutions",
    "href": "solutions/lab16-ans-y3l9.html#analysis-of-variance-anova---official-solutions",
    "title": "Solution - Lab 16: Analysis of variance (ANOVA)",
    "section": "",
    "text": "To solve Lab 16, we focus on ANOVA (Analysis of Variance). This statistical method is used to compare the means of three or more groups to see if at least one is significantly different from the others. In your SUNY dataset, the ‚ÄúInstitution Sector‚Äù has 4 distinct categories, making it perfect for this test.\n\n\n\n\n\n\nNoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box."
  },
  {
    "objectID": "solutions/lab08-ans-s3z7.html",
    "href": "solutions/lab08-ans-s3z7.html",
    "title": "Solution - Lab 8: Exploratory Data Analysis",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nWe load our library and re-apply the cleaning steps from Lab 7 to ensure we are working with the correct variables.\n\nlibrary(tidyverse)\n\n# 1. Load data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# 2. Re-apply Lab 7 Cleaning (using indices for accessibility)\ncleaned_suny &lt;- ny_data |&gt; \n  select(1, 2, 3, 6) |&gt; \n  rename(semester = 1,\n         sector = 2,\n         total_enrollment = 3,\n         hispanic_latino = 4) |&gt; \n  filter(sector == \"Community Colleges\")\n\n\n\n\nWe calculate the summary statistics for our main numeric variable: total_enrollment.\n\nstats &lt;- cleaned_suny |&gt; \n  summarise(\n    mean_enrollment = mean(total_enrollment, na.rm = TRUE),\n    sd_enrollment = sd(total_enrollment, na.rm = TRUE)\n  )\n\nstats\n\n# A tibble: 1 √ó 2\n  mean_enrollment sd_enrollment\n            &lt;dbl&gt;         &lt;dbl&gt;\n1         207879.        28395.\n\n\n\n\n\nA histogram helps us see the distribution of enrollment across different community college campuses and semesters.\n\nggplot(cleaned_suny, aes(x = total_enrollment)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 15) +\n  labs(title = \"Distribution of Total Enrollment\",\n       subtitle = \"SUNY Community Colleges\",\n       x = \"Total Students\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nObservation: The data appears to be right-skewed. Most community colleges have a smaller enrollment (under 10,000), while a few very large institutions pull the tail to the right.\n\n\n\nWe compare total_enrollment to hispanic_latino enrollment to see if they grow together.\n\nggplot(cleaned_suny, aes(x = total_enrollment, y = hispanic_latino)) +\n  geom_point(alpha = 0.6, color = \"darkgreen\") +\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n  labs(title = \"Total Enrollment vs. Hispanic/Latino Enrollment\",\n       x = \"Total Students\",\n       y = \"Hispanic/Latino Students\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nWe compare the distribution of total enrollment across different semesters.\n\nggplot(cleaned_suny, aes(x = semester, y = total_enrollment)) +\n  geom_boxplot(fill = \"orange\", alpha = 0.7) +\n  labs(title = \"Enrollment Distribution by Semester\",\n       x = \"Semester\",\n       y = \"Total Students\") +\n  theme_minimal() +\n  coord_flip() # Flipping for easier reading of labels\n\n\n\n\n\n\n\n\nFinal Observation (3 Sentences) In these plots, there is a very strong positive correlation between the size of a college and its Hispanic/Latino student population, as shown by the linear trend in the scatter plot. Interestingly, the boxplot reveals that total enrollment has been gradually declining across the semesters, evidenced by the median line shifting downward. A major outlier exists in the community college sector, representing a massive campus that significantly exceeds the average enrollment of all other schools.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab08-ans-s3z7.html#exploratory-data-analysis---official-solutions",
    "href": "solutions/lab08-ans-s3z7.html#exploratory-data-analysis---official-solutions",
    "title": "Solution - Lab 8: Exploratory Data Analysis",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box.\n\n\n\n\nWe load our library and re-apply the cleaning steps from Lab 7 to ensure we are working with the correct variables.\n\nlibrary(tidyverse)\n\n# 1. Load data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# 2. Re-apply Lab 7 Cleaning (using indices for accessibility)\ncleaned_suny &lt;- ny_data |&gt; \n  select(1, 2, 3, 6) |&gt; \n  rename(semester = 1,\n         sector = 2,\n         total_enrollment = 3,\n         hispanic_latino = 4) |&gt; \n  filter(sector == \"Community Colleges\")\n\n\n\n\nWe calculate the summary statistics for our main numeric variable: total_enrollment.\n\nstats &lt;- cleaned_suny |&gt; \n  summarise(\n    mean_enrollment = mean(total_enrollment, na.rm = TRUE),\n    sd_enrollment = sd(total_enrollment, na.rm = TRUE)\n  )\n\nstats\n\n# A tibble: 1 √ó 2\n  mean_enrollment sd_enrollment\n            &lt;dbl&gt;         &lt;dbl&gt;\n1         207879.        28395.\n\n\n\n\n\nA histogram helps us see the distribution of enrollment across different community college campuses and semesters.\n\nggplot(cleaned_suny, aes(x = total_enrollment)) +\n  geom_histogram(fill = \"steelblue\", color = \"white\", bins = 15) +\n  labs(title = \"Distribution of Total Enrollment\",\n       subtitle = \"SUNY Community Colleges\",\n       x = \"Total Students\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nObservation: The data appears to be right-skewed. Most community colleges have a smaller enrollment (under 10,000), while a few very large institutions pull the tail to the right.\n\n\n\nWe compare total_enrollment to hispanic_latino enrollment to see if they grow together.\n\nggplot(cleaned_suny, aes(x = total_enrollment, y = hispanic_latino)) +\n  geom_point(alpha = 0.6, color = \"darkgreen\") +\n  geom_smooth(method = \"lm\", color = \"red\", se = FALSE) +\n  labs(title = \"Total Enrollment vs. Hispanic/Latino Enrollment\",\n       x = \"Total Students\",\n       y = \"Hispanic/Latino Students\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nWe compare the distribution of total enrollment across different semesters.\n\nggplot(cleaned_suny, aes(x = semester, y = total_enrollment)) +\n  geom_boxplot(fill = \"orange\", alpha = 0.7) +\n  labs(title = \"Enrollment Distribution by Semester\",\n       x = \"Semester\",\n       y = \"Total Students\") +\n  theme_minimal() +\n  coord_flip() # Flipping for easier reading of labels\n\n\n\n\n\n\n\n\nFinal Observation (3 Sentences) In these plots, there is a very strong positive correlation between the size of a college and its Hispanic/Latino student population, as shown by the linear trend in the scatter plot. Interestingly, the boxplot reveals that total enrollment has been gradually declining across the semesters, evidenced by the median line shifting downward. A major outlier exists in the community college sector, representing a massive campus that significantly exceeds the average enrollment of all other schools.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab15-ans-r5h1.html",
    "href": "solutions/lab15-ans-r5h1.html",
    "title": "Solution - Lab 15: Non-parametric methods",
    "section": "",
    "text": "To solve Lab 15, we focus on Non-parametric Testing. This lab is crucial for real-world data science because many datasets (like your SUNY enrollment data) are skewed and do not follow a ‚ÄúNormal‚Äù distribution. We will compare the standard T-test with the Wilcoxon Rank-Sum test to see how they handle skewed data differently. ::: {.callout-note} ### Instructor Note Add your specific DCC lab answers below this box. ::: ## Lab 15 Official Solutions: Wilcoxon vs.¬†T-Test\nIn this final lab, we investigate how to handle highly skewed data by comparing parametric and non-parametric tests.\n\n\nWe prepare our data by cleaning the enrollment numbers and filtering for two distinct sectors: Community Colleges and Doctoral Degree Granting Institutions.\n\nlibrary(tidyverse)\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Clean data: \n# Remove commas and filter for two groups\ncomparison_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  filter(`Institution Sector` %in% c(\"Community Colleges\", \"Doctoral Degree Granting Institutions\")) |&gt;\n  rename(sector = `Institution Sector`)\n\n\n\n\nWe use a boxplot to visualize the distribution of enrollment.\n\nggplot(comparison_data, aes(x = sector, y = total_enroll, fill = sector)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = c(\"darkgreen\", \"purple\")) +\n  labs(title = \"Enrollment Distribution by Sector\",\n       x = \"Sector\",\n       y = \"Total Students\") +\n  theme_minimal() +\n  guides(fill = \"none\")\n\n\n\n\n\n\n\nFigure¬†1: Boxplot comparing Total Enrollment across two SUNY sectors.\n\n\n\n\n\n\n\n\nWe run both a Wilcoxon Rank-Sum Test (which compares medians/ranks) and a T-Test (which compares means).\nThe Wilcoxon Test (Non-parametric)\n\nwilcox_results &lt;- wilcox.test(total_enroll ~ sector, data = comparison_data)\nwilcox_results\n\n\n    Wilcoxon rank sum exact test\n\ndata:  total_enroll by sector\nW = 529, p-value = 2.429e-13\nalternative hypothesis: true location shift is not equal to 0\n\n\nThe T-Test (Parametric)\n\nt_results &lt;- t.test(total_enroll ~ sector, data = comparison_data)\nt_results\n\n\n    Welch Two Sample t-test\n\ndata:  total_enroll by sector\nt = 17.047, df = 24.837, p-value = 3.228e-15\nalternative hypothesis: true difference in means between group Community Colleges and group Doctoral Degree Granting Institutions is not equal to 0\n95 percent confidence interval:\n  91558.41 116731.86\nsample estimates:\n                   mean in group Community Colleges \n                                           207878.5 \nmean in group Doctoral Degree Granting Institutions \n                                           103733.4 \n\n\n\n\n\nP-Value Comparison:\n\n**Wilcoxon P-value: r format.pval(wilcox_results$p.value, digits = 4)\n**T-Test P-value: r format.pval(t_results$p.value, digits = 4)\n\nReflection: In this specific dataset, both p-values are extremely small (well below 0.05), so both tests lead us to reject the null hypothesis. However, I trust the Wilcoxon test more for this specific data.\nWhy? The enrollment data is highly skewed and contains outliers (massive differences between campus sizes). The T-test assumes the data follows a normal distribution and is sensitive to outliers because it relies on the mean. The Wilcoxon test is more robust because it uses the ranks of the data rather than the raw values, making it the more appropriate ‚Äúaccessible‚Äù choice for messy, real-world data that isn‚Äôt bell-shaped. \n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab15-ans-r5h1.html#non-parametric-methods---official-solutions",
    "href": "solutions/lab15-ans-r5h1.html#non-parametric-methods---official-solutions",
    "title": "Solution - Lab 15: Non-parametric methods",
    "section": "",
    "text": "To solve Lab 15, we focus on Non-parametric Testing. This lab is crucial for real-world data science because many datasets (like your SUNY enrollment data) are skewed and do not follow a ‚ÄúNormal‚Äù distribution. We will compare the standard T-test with the Wilcoxon Rank-Sum test to see how they handle skewed data differently. ::: {.callout-note} ### Instructor Note Add your specific DCC lab answers below this box. ::: ## Lab 15 Official Solutions: Wilcoxon vs.¬†T-Test\nIn this final lab, we investigate how to handle highly skewed data by comparing parametric and non-parametric tests.\n\n\nWe prepare our data by cleaning the enrollment numbers and filtering for two distinct sectors: Community Colleges and Doctoral Degree Granting Institutions.\n\nlibrary(tidyverse)\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Clean data: \n# Remove commas and filter for two groups\ncomparison_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  filter(`Institution Sector` %in% c(\"Community Colleges\", \"Doctoral Degree Granting Institutions\")) |&gt;\n  rename(sector = `Institution Sector`)\n\n\n\n\nWe use a boxplot to visualize the distribution of enrollment.\n\nggplot(comparison_data, aes(x = sector, y = total_enroll, fill = sector)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = c(\"darkgreen\", \"purple\")) +\n  labs(title = \"Enrollment Distribution by Sector\",\n       x = \"Sector\",\n       y = \"Total Students\") +\n  theme_minimal() +\n  guides(fill = \"none\")\n\n\n\n\n\n\n\nFigure¬†1: Boxplot comparing Total Enrollment across two SUNY sectors.\n\n\n\n\n\n\n\n\nWe run both a Wilcoxon Rank-Sum Test (which compares medians/ranks) and a T-Test (which compares means).\nThe Wilcoxon Test (Non-parametric)\n\nwilcox_results &lt;- wilcox.test(total_enroll ~ sector, data = comparison_data)\nwilcox_results\n\n\n    Wilcoxon rank sum exact test\n\ndata:  total_enroll by sector\nW = 529, p-value = 2.429e-13\nalternative hypothesis: true location shift is not equal to 0\n\n\nThe T-Test (Parametric)\n\nt_results &lt;- t.test(total_enroll ~ sector, data = comparison_data)\nt_results\n\n\n    Welch Two Sample t-test\n\ndata:  total_enroll by sector\nt = 17.047, df = 24.837, p-value = 3.228e-15\nalternative hypothesis: true difference in means between group Community Colleges and group Doctoral Degree Granting Institutions is not equal to 0\n95 percent confidence interval:\n  91558.41 116731.86\nsample estimates:\n                   mean in group Community Colleges \n                                           207878.5 \nmean in group Doctoral Degree Granting Institutions \n                                           103733.4 \n\n\n\n\n\nP-Value Comparison:\n\n**Wilcoxon P-value: r format.pval(wilcox_results$p.value, digits = 4)\n**T-Test P-value: r format.pval(t_results$p.value, digits = 4)\n\nReflection: In this specific dataset, both p-values are extremely small (well below 0.05), so both tests lead us to reject the null hypothesis. However, I trust the Wilcoxon test more for this specific data.\nWhy? The enrollment data is highly skewed and contains outliers (massive differences between campus sizes). The T-test assumes the data follows a normal distribution and is sensitive to outliers because it relies on the mean. The Wilcoxon test is more robust because it uses the ranks of the data rather than the raw values, making it the more appropriate ‚Äúaccessible‚Äù choice for messy, real-world data that isn‚Äôt bell-shaped. \n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "submission-criteria.html",
    "href": "submission-criteria.html",
    "title": "üìã Lab Submission Guide",
    "section": "",
    "text": "To earn full credit, your lab must be submitted correctly to both GitHub and Brightspace. Use this page as your final checklist!\n\n\n\n\n\n\n\n\n\n\n\nSection\nThe Goal\nPoints\n\n\n\n\nDoes it Run?\nYour Render button works. There are no red error messages in your final HTML.\n5 pts\n\n\nThe Story\nYou wrote 1-2 sentences under each graph/table explaining what the data shows.\n3 pts\n\n\nThe Details\nYour name is in the YAML, files are named correctly, and graphs have titles.\n2 pts\n\n\n\n\n\n\n\nProfessional data scientists make sure their work is readable by everyone!\n\nHuman Labels: Rename axis labels (like lwt) to real words (like ‚ÄúMother‚Äôs Weight‚Äù).\nGraph Titles: Every visualization needs a clear, descriptive title.\nCaptions: Use #| fig-cap: \"Description\" inside your R code chunks.\nClean Tables: Use knitr::kable() to format your data nicely.\n\n\n\n\n\n\n\nBefore uploading, ensure your files follow this format:\nLab#_FirstName_LastName\nExample: Lab2_Jane_Doe.qmd and Lab2_Jane_Doe.html\n\n\n\n\nGo to your GitHub repository.\nClick Add file &gt; Upload files.\nDrag BOTH the .qmd and the .html files into the box.\nImportant: Scroll down and click the green Commit changes button.\n\n\n\n\n\nGo to the Lab folder in Brightspace.\nUpload ONLY the .html file. (This is the file I will grade).\n\n\n\n\n\n\n\nImportantüõë If your code won‚Äôt ‚ÄúRender‚Äù\n\n\n\nIf you have a code error you can‚Äôt fix: 1. Put a # at the start of the broken line (e.g., # ggplot(...)). 2. This ‚Äúcomments out‚Äù the code so the rest of the document can finish. 3. You might lose a technical point, but you can still earn points for the rest of your work!",
    "crumbs": [
      "Home",
      "Getting Started",
      "How to Submit (Read First!)"
    ]
  },
  {
    "objectID": "submission-criteria.html#how-you-are-graded-10-points",
    "href": "submission-criteria.html#how-you-are-graded-10-points",
    "title": "üìã Lab Submission Guide",
    "section": "",
    "text": "Section\nThe Goal\nPoints\n\n\n\n\nDoes it Run?\nYour Render button works. There are no red error messages in your final HTML.\n5 pts\n\n\nThe Story\nYou wrote 1-2 sentences under each graph/table explaining what the data shows.\n3 pts\n\n\nThe Details\nYour name is in the YAML, files are named correctly, and graphs have titles.\n2 pts",
    "crumbs": [
      "Home",
      "Getting Started",
      "How to Submit (Read First!)"
    ]
  },
  {
    "objectID": "submission-criteria.html#accessibility-checklist",
    "href": "submission-criteria.html#accessibility-checklist",
    "title": "üìã Lab Submission Guide",
    "section": "",
    "text": "Professional data scientists make sure their work is readable by everyone!\n\nHuman Labels: Rename axis labels (like lwt) to real words (like ‚ÄúMother‚Äôs Weight‚Äù).\nGraph Titles: Every visualization needs a clear, descriptive title.\nCaptions: Use #| fig-cap: \"Description\" inside your R code chunks.\nClean Tables: Use knitr::kable() to format your data nicely.",
    "crumbs": [
      "Home",
      "Getting Started",
      "How to Submit (Read First!)"
    ]
  },
  {
    "objectID": "submission-criteria.html#step-by-step-submission",
    "href": "submission-criteria.html#step-by-step-submission",
    "title": "üìã Lab Submission Guide",
    "section": "",
    "text": "Before uploading, ensure your files follow this format:\nLab#_FirstName_LastName\nExample: Lab2_Jane_Doe.qmd and Lab2_Jane_Doe.html\n\n\n\n\nGo to your GitHub repository.\nClick Add file &gt; Upload files.\nDrag BOTH the .qmd and the .html files into the box.\nImportant: Scroll down and click the green Commit changes button.\n\n\n\n\n\nGo to the Lab folder in Brightspace.\nUpload ONLY the .html file. (This is the file I will grade).\n\n\n\n\n\n\n\nImportantüõë If your code won‚Äôt ‚ÄúRender‚Äù\n\n\n\nIf you have a code error you can‚Äôt fix: 1. Put a # at the start of the broken line (e.g., # ggplot(...)). 2. This ‚Äúcomments out‚Äù the code so the rest of the document can finish. 3. You might lose a technical point, but you can still earn points for the rest of your work!",
    "crumbs": [
      "Home",
      "Getting Started",
      "How to Submit (Read First!)"
    ]
  },
  {
    "objectID": "solutions/lab03-ans-x7m1.html#lab-3-official-solutions",
    "href": "solutions/lab03-ans-x7m1.html#lab-3-official-solutions",
    "title": "Solution - Lab 03: Mathematical Notation",
    "section": "",
    "text": "The student was asked to render the sample standard deviation formula using LaTeX.\nThe expected output:\n\\[s = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}{n - 1}}\\]\n\n\n\n\nInline Math: We use single dollar signs, like \\(E = mc^2\\), to put math inside a sentence.\nDisplay Math: We use double dollar signs to center the math on its own line.\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions.html",
    "href": "solutions.html",
    "title": "MAT 186: Data Science",
    "section": "",
    "text": "Lab\nTopic\nSolution Link\n\n\n\n\n01\nR and RStudio Installation\nView Solution\n\n\n02\nRStudio Project and Quarto Documents\nView Solution\n\n\n03\nMathematical Notation in Quarto\nView Solution\n\n\n04\nGitHub Repository\nView Solution\n\n\n05\nGetting data into R\nView Solution\n\n\n06\nData collection\nView Solution\n\n\n07\nCleaning Data\nView Solution\n\n\n08\nExploratory Data Analysis\nView Solution\n\n\n09\nProbability distribution\nView Solution\n\n\n10\nInference for one mean\nView Solution\n\n\n11\nInference for one proportion\nView Solution\n\n\n12\nInference for two means\nView Solution\n\n\n13\nInference for two proportions\nView Solution\n\n\n14\nBootstrapping\nView Solution\n\n\n15\nNon-parametric methods\nView Solution\n\n\n16\nAnalysis of variance (ANOVA)\nView Solution\n\n\n17\nRegression models\nView Solution"
  },
  {
    "objectID": "solutions/lab02-ans-v4n9.html#rstudio-project-and-quarto-documents---official-solutions",
    "href": "solutions/lab02-ans-v4n9.html#rstudio-project-and-quarto-documents---official-solutions",
    "title": "Solution - Lab 02: RStudio & Quarto",
    "section": "",
    "text": "NoteInstructor Note\n\n\n\nAdd your specific DCC lab answers below this box."
  },
  {
    "objectID": "instructor-dashboard.html",
    "href": "instructor-dashboard.html",
    "title": "Instructor Dashboard",
    "section": "",
    "text": "WarningConfidential\n\n\n\nThis page is for instructor use only. Do not link this page in the main website navigation."
  },
  {
    "objectID": "instructor-dashboard.html#master-password-key",
    "href": "instructor-dashboard.html#master-password-key",
    "title": "Instructor Dashboard",
    "section": "üîë Master Password Key",
    "text": "üîë Master Password Key\n\n\n\nLab #\nTopic\nOriginal Password\nFilename\n\n\n\n\n02\nRStudio & Quarto\nv4n9\nlab02-ans-v4n9.qmd\n\n\n03\nMath Notation\nx7m1\nlab03-ans-x7m1.qmd\n\n\n04\nGitHub Repo\nb2r6\nlab04-ans-b2r6.qmd\n\n\n05\nData Input\nt8j3\nlab05-ans-t8j3.qmd\n\n\n06\nData Collection\nw5q1\nlab06-ans-w5q1.qmd\n\n\n07\nCleaning Data\nh9y4\nlab07-ans-h9y4.qmd\n\n\n08\nEDA\ns3z7\nlab08-ans-s3z7.qmd\n\n\n09\nProbability\nf6p2\nlab09-ans-f6p2.qmd\n\n\n10\nOne Mean\ng4d8\nlab10-ans-g4d8.qmd\n\n\n11\nOne Proportion\nm1k5\nlab11-ans-m1k5.qmd\n\n\n12\nTwo Means\np9v2\nlab12-ans-p9v2.qmd\n\n\n13\nTwo Proportions\nc7w4\nlab13-ans-c7w4.qmd\n\n\n14\nBootstrapping\nx2n8\nlab14-ans-x2n8.qmd\n\n\n15\nNon-parametric\nr5h1\nlab15-ans-r5h1.qmd\n\n\n16\nANOVA\ny3l9\nlab16-ans-y3l9.qmd\n\n\n17\nRegression\na6t2\nlab17-ans-a6t2.qmd\n\n\n\n\n\nüöÄ Quick Admin Tasks\n\nCurrent Temp Password: MAT186LABSOER\nTo Restore: Run the ‚ÄúRestore Original Passwords‚Äù R script.\nTo Update Solutions: Go to the solutions/ folder directly."
  },
  {
    "objectID": "labs/lab17_S27.html",
    "href": "labs/lab17_S27.html",
    "title": "Lab 17: Linear Regression",
    "section": "",
    "text": "TipDone with the Lab?\n\n\n\nIf you have finished all the tasks above, you can verify your work against the official solutions.\n\nüîì Access Lab Solutions"
  },
  {
    "objectID": "solutions/lab12-ans-p9v2.html#markdown",
    "href": "solutions/lab12-ans-p9v2.html#markdown",
    "title": "Solution - Lab 12: Statistical inference for two means",
    "section": "Markdown",
    "text": "Markdown\ntitle: ‚ÄúSolution - Lab 12: Comparing Two Means‚Äù subtitle: ‚ÄúMAT 186: Introduction to Data Science‚Äù format: html: toc: true toc-location: right ‚Äî"
  },
  {
    "objectID": "solutions/lab12-ans-p9v2.html#lab-12-official-solutions-two-sample-inference",
    "href": "solutions/lab12-ans-p9v2.html#lab-12-official-solutions-two-sample-inference",
    "title": "Solution - Lab 12: Statistical inference for two means",
    "section": "Lab 12 Official Solutions: Two-Sample Inference",
    "text": "Lab 12 Official Solutions: Two-Sample Inference\nIn this lab, we test whether there is a statistically significant difference between the enrollment means of two different SUNY sectors.\n\nTask 1: Loading and Filtering Data\nWe prepare our data by cleaning the numeric enrollment column and filtering our categorical variable to include only two specific groups: Community Colleges and Doctoral Degree Granting Institutions.\n\nlibrary(tidyverse)\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Clean data: \n# 1. Remove commas from enrollment numbers\n# 2. Filter for only TWO groups in the 'Institution Sector'\ncomparison_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  filter(`Institution Sector` %in% c(\"Community Colleges\", \"Doctoral Degree Granting Institutions\")) |&gt;\n  rename(sector = `Institution Sector`)\n\n\n\nTask 2: Visualizing the Comparison\nA boxplot allows us to see the center and spread of enrollment for both groups side-by-side.\n\nggplot(comparison_data, aes(x = sector, y = total_enroll, fill = sector)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = c(\"steelblue\", \"darkorange\")) +\n  labs(title = \"Enrollment Comparison: Community vs. Doctoral\",\n       x = \"Institution Sector\",\n       y = \"Total Students\") +\n  theme_minimal() +\n  guides(fill = \"none\") # Hide legend as X-axis labels are sufficient\n\n\n\n\n\n\n\nFigure¬†1: Boxplot comparing Total Enrollment between Community Colleges and Doctoral Institutions.\n\n\n\n\n\n\n\nTask 3: State Your Hypotheses\nWe are testing if there is a real difference in the average size of these two types of institutions.\n\nNull Hypothesis (\\(H_0\\)): There is no difference in mean enrollment between the two sectors (\\(\\mu_1 = \\mu_2\\)).\nAlternative Hypothesis (\\(H_a\\)): There is a significant difference in mean enrollment between the two sectors (\\(\\mu_1 \\neq \\mu_2\\)).\n\n\n\nTask 4: Running the Two-Sample T-Test\nWe use the formula syntax numeric_variable ~ categorical_variable to run the test.\n\n# Run the two-sample t-test\nt_results &lt;- t.test(total_enroll ~ sector, data = comparison_data)\n\n# Display results\nt_results\n\n\n    Welch Two Sample t-test\n\ndata:  total_enroll by sector\nt = 17.047, df = 24.837, p-value = 3.228e-15\nalternative hypothesis: true difference in means between group Community Colleges and group Doctoral Degree Granting Institutions is not equal to 0\n95 percent confidence interval:\n  91558.41 116731.86\nsample estimates:\n                   mean in group Community Colleges \n                                           207878.5 \nmean in group Doctoral Degree Granting Institutions \n                                           103733.4 \n\n\n\n\nTask 5: The Conclusion\nBased on the statistical analysis:\nFormal Conclusion: Since the p-value was r format.pval(t_results$p.value, digits = 4), which is much smaller than the alpha level of 0.05, we reject the null hypothesis. The data provides strong evidence that the average enrollment at Community Colleges is significantly different (higher) than the average enrollment at Doctoral Degree Granting Institutions.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab16-ans-y3l9.html#lab-16-official-solutions-anova",
    "href": "solutions/lab16-ans-y3l9.html#lab-16-official-solutions-anova",
    "title": "Solution - Lab 16: Analysis of variance (ANOVA)",
    "section": "Lab 16 Official Solutions: ANOVA",
    "text": "Lab 16 Official Solutions: ANOVA\nIn this lab, we determine if there are significant differences in average enrollment across the four different SUNY institution sectors.\n\nTask 1: Data Preparation\nWe clean the Total Enrollment column by removing commas and ensuring the Institution Sector variable is treated as a factor for our analysis.\n\nlibrary(tidyverse)\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Clean data: \n# Remove commas from enrollment and ensure Sector has at least 3 groups\nclean_data &lt;- ny_data |&gt;\n  mutate(total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`))) |&gt;\n  rename(sector = `Institution Sector`) |&gt;\n  filter(!is.na(total_enroll))\n\n###Task 2: Visual Comparison (Boxplot) We visualize the distribution of enrollment across all four sectors.\n\nggplot(clean_data, aes(x = sector, y = total_enroll, fill = sector)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(title = \"Enrollment Variance Across SUNY Sectors\",\n       x = \"Institution Sector\",\n       y = \"Total Students\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  guides(fill = \"none\")\n\n\n\n\n\n\n\nFigure¬†1: Boxplot comparing Total Enrollment across four SUNY sectors.\n\n\n\n\n\n\n\nTask 3: Running the ANOVA\nWe use the aov() function to test our null hypothesis that all sector means are equal (\\(H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4\\)).\n\n# Run the ANOVA model\nanova_model &lt;- aov(total_enroll ~ sector, data = clean_data)\n\n# Display the summary table\nsummary(anova_model)\n\n            Df    Sum Sq   Mean Sq F value Pr(&gt;F)    \nsector       3 3.974e+11 1.325e+11   580.5 &lt;2e-16 ***\nResiduals   88 2.008e+10 2.282e+08                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nTask 4: Post-Hoc Testing (Tukey HSD)\nSince our ANOVA returned a p-value much smaller than 0.05, we must run a Tukey HSD test to see which specific pairs of sectors are different.\n\n# Run Tukey Honestly Significant Difference test\ntukey_results &lt;- TukeyHSD(anova_model)\ntukey_results\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = total_enroll ~ sector, data = clean_data)\n\n$sector\n                                                                   diff\nComprehensive Colleges-Community Colleges                    -122190.70\nDoctoral Degree Granting Institutions-Community Colleges     -104145.13\nTechnology Colleges-Community Colleges                       -182375.39\nDoctoral Degree Granting Institutions-Comprehensive Colleges   18045.57\nTechnology Colleges-Comprehensive Colleges                    -60184.70\nTechnology Colleges-Doctoral Degree Granting Institutions     -78230.26\n                                                                     lwr\nComprehensive Colleges-Community Colleges                    -133856.013\nDoctoral Degree Granting Institutions-Community Colleges     -115810.448\nTechnology Colleges-Community Colleges                       -194040.709\nDoctoral Degree Granting Institutions-Comprehensive Colleges    6380.247\nTechnology Colleges-Comprehensive Colleges                    -71850.013\nTechnology Colleges-Doctoral Degree Granting Institutions     -89895.579\n                                                                    upr\nComprehensive Colleges-Community Colleges                    -110525.38\nDoctoral Degree Granting Institutions-Community Colleges      -92479.81\nTechnology Colleges-Community Colleges                       -170710.07\nDoctoral Degree Granting Institutions-Comprehensive Colleges   29710.88\nTechnology Colleges-Comprehensive Colleges                    -48519.38\nTechnology Colleges-Doctoral Degree Granting Institutions     -66564.94\n                                                                 p adj\nComprehensive Colleges-Community Colleges                    0.0000000\nDoctoral Degree Granting Institutions-Community Colleges     0.0000000\nTechnology Colleges-Community Colleges                       0.0000000\nDoctoral Degree Granting Institutions-Comprehensive Colleges 0.0006246\nTechnology Colleges-Comprehensive Colleges                   0.0000000\nTechnology Colleges-Doctoral Degree Granting Institutions    0.0000000\n\n\n\n\nTask 5: Conclusion\nBased on the statistical analysis:\nFormal Conclusion: The ANOVA results yielded a p-value of &lt; 2e-16, which is significantly less than 0.05. Therefore, we reject the null hypothesis and conclude that there is a significant difference in mean enrollment between at least two of the SUNY sectors.\nFollow-up Analysis: According to the Tukey HSD test, almost all pairs show significant differences (p-adj &lt; 0.05). Specifically, the difference between Community Colleges and Technology Colleges is among the most extreme, while some other pairs might show overlapping intervals. This confirms that the size of an institution is heavily dependent on its specific sector classification.\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "solutions/lab17-ans-a6t2.html#lab-17-official-solutions-linear-modeling",
    "href": "solutions/lab17-ans-a6t2.html#lab-17-official-solutions-linear-modeling",
    "title": "Solution - Lab 17: Regression models",
    "section": "Lab 17 Official Solutions: Linear Modeling",
    "text": "Lab 17 Official Solutions: Linear Modeling\nIn this lab, we use simple linear regression to quantify the relationship between total campus enrollment and Hispanic/Latino student populations.\n\nTask 1: Data Preparation\nWe clean our numeric variables by removing commas and ensuring there are no missing values in our target columns.\n\nlibrary(tidyverse)\n\n# Load the data\nny_data &lt;- read_csv(\"../data/race_ny.csv\")\n\n# Clean numeric variables\nclean_data &lt;- ny_data |&gt;\n  mutate(\n    total_enroll = as.numeric(gsub(\",\", \"\", `Total Enrollment`)),\n    hispanic_enroll = as.numeric(gsub(\",\", \"\", `Hispanic/Latino`))\n  ) |&gt;\n  filter(!is.na(total_enroll), !is.na(hispanic_enroll))\n\n\n\nTask 2: Correlation Coefficient\nWe calculate the Pearson correlation coefficient (\\(r\\)) to measure the strength and direction of the linear relationship.\n\nr_value &lt;- cor(clean_data$total_enroll, clean_data$hispanic_enroll)\ncat(\"The correlation coefficient (r) is:\", round(r_value, 4))\n\nThe correlation coefficient (r) is: 0.8294\n\n\n\n\nTask 3: Scatter Plot with Regression Line\nWe visualize the relationship with a scatter plot and add a linear trend line.\n\nggplot(clean_data, aes(x = total_enroll, y = hispanic_enroll)) +\n  geom_point(alpha = 0.5, color = \"darkblue\") +\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  labs(title = \"Predicting Hispanic Enrollment from Total Enrollment\",\n       x = \"Total Enrollment (Independent Variable)\",\n       y = \"Hispanic/Latino Enrollment (Dependent Variable)\") +\n  theme_minimal()\n\n\n\n\n\n\n\nFigure¬†1: Scatter plot of Total Enrollment vs.¬†Hispanic/Latino Enrollment with a linear regression line.\n\n\n\n\n\n\n\nTask 4: Running the Linear Regression Model\nWe use the lm() function to create our mathematical model: \\(Y = \\beta_0 + \\beta_1X\\).\n\n# Formula: Y ~ X\nmodel &lt;- lm(hispanic_enroll ~ total_enroll, data = clean_data)\n\n# Display the regression summary\nsummary(model)\n\n\nCall:\nlm(formula = hispanic_enroll ~ total_enroll, data = clean_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8839.9 -4143.0  -378.9  2436.0 15662.3 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -9.117e+02  9.735e+02  -0.936    0.352    \ntotal_enroll  1.094e-01  7.767e-03  14.087   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5018 on 90 degrees of freedom\nMultiple R-squared:  0.688, Adjusted R-squared:  0.6845 \nF-statistic: 198.4 on 1 and 90 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nTask 5: Conclusion\nBased on our linear regression analysis, we can draw the following conclusions:\n\nStrength of Relationship: There is a very strong positive correlation (\\(r \\approx 0.83\\)) between total enrollment and Hispanic/Latino enrollment.\nThe Slope: The slope coefficient is approximately r round(coef(model)[2], 4). This means that for every 1 additional student enrolled at a SUNY institution, we expect the Hispanic/Latino student population to increase by about r round(coef(model)[2], 2) students on average.\nPredictive Power (\\(R^2\\)): The R-squared value of r round(summary(model)\\(r.squared, 4) suggests that roughly r round(summary(model)\\)r.squared * 100, 1)% of the variation in Hispanic student enrollment can be explained by the total size of the institution.\n\n\n\n\n\nüè† Back to Solutions Hub"
  },
  {
    "objectID": "accessibility.html#commitment-to-accessibility",
    "href": "accessibility.html#commitment-to-accessibility",
    "title": "Accessibility Statement",
    "section": "",
    "text": "This course site is designed to be accessible to all students, including those with disabilities. We aim to meet or exceed WCAG 2.1 Level AA standards, ensuring that every student at Dutchess Community College has equal access to our Data Science materials.\n\n\nTo achieve our 100% Accessibility rating (as verified by Lighthouse audits), we have implemented the following features:\n\nAlt-Text for Data Visualizations: Every chart, graph, and plot in our labs includes descriptive alternative text. This allows screen reader users to understand the trends and conclusions of the data without seeing the image.\nSemantic Navigation: We use a clear heading hierarchy (# H1, ## H2, ### H3) to allow for easy keyboard navigation and screen reader ‚Äúheading jumps.‚Äù\nMathematical Accessibility: All mathematical notation is rendered using MathJax, which transforms LaTeX equations into readable text for assistive technologies.\nColor Contrast: Text and background colors have been selected to meet high contrast requirements for improved readability.\nAccessible Code: Code chunks are formatted to be legible and distinguishable from standard prose.\n\n\n\n\nAccessibility relies on the following technologies to work with the particular combination of web browser and any assistive technologies or plugins installed on your computer: * HTML * WAI-ARIA * CSS * JavaScript\n\n\n\nIf you encounter any accessibility barriers while using this site, please contact me directly. I am committed to making adjustments to ensure you have the materials you need to succeed.\nYou may also reach out to the DCC Office of Accommodative Services for further support and official accommodations.\n\nThis site was last audited on r format(Sys.Date(), \"%B %Y\") and received a 100% Accessibility score using Google Lighthouse."
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Student Resources",
    "section": "",
    "text": "Welcome to the MAT 186 Resource Hub. Use these tools to support your learning throughout the semester."
  },
  {
    "objectID": "resources.html#essential-r-data-science-tools",
    "href": "resources.html#essential-r-data-science-tools",
    "title": "Student Resources",
    "section": "üõ†Ô∏è Essential R & Data Science Tools",
    "text": "üõ†Ô∏è Essential R & Data Science Tools\n\nRStudio Cheat Sheets\nR can be challenging to memorize. These official ‚ÄúCheat Sheets‚Äù are the industry standard for quick reference. These links lead to the official Posit documentation:\n\nData Visualization (ggplot2)\nData Transformation (dplyr)\nQuarto Markdown Reference\nBrowse All Posit Cheat Sheets\n\n\n\nAI for Learning (Generative AI Policy)\nIn this course, we use AI as a tutor, not a replacement.\n\nGood use: ‚ÄúExplain why this t-test code is giving me an error.‚Äù\nBad use: ‚ÄúWrite the entire conclusion for Lab 12 for me.‚Äù\nTip: Always double-check AI-generated code; it can sometimes suggest outdated packages!"
  },
  {
    "objectID": "resources.html#dutchess-community-college-support",
    "href": "resources.html#dutchess-community-college-support",
    "title": "Student Resources",
    "section": "üéì Dutchess Community College Support",
    "text": "üéì Dutchess Community College Support\n\nAcademic Support & Tutoring\nIf you are struggling with the math or coding concepts, help is available:\n\nThe Math Center: Located in Washington Center (Room 224). They offer walk-in tutoring for statistics.\nWriting Center: Excellent for help with your final project reports.\nDCC Help Desk: For issues with your DCC login or Microsoft 365. Submit a Ticket\n\n\n\nAccommodative Services\nIf you have a documented disability and require specific accommodations for this course, please visit the Office of Accommodative Services in the Orcutt Student Center."
  },
  {
    "objectID": "resources.html#practice-data-sources",
    "href": "resources.html#practice-data-sources",
    "title": "Student Resources",
    "section": "üìä Practice Data Sources",
    "text": "üìä Practice Data Sources\nWant to explore data outside of our labs? These sites offer free, clean datasets:\n\nNY.gov Open Data: Real data about New York State (similar to our enrollment data).\nKaggle: A massive community for data science competitions and datasets.\nTidyTuesday: A weekly social data project in R."
  },
  {
    "objectID": "resources.html#recommended-tutorials",
    "href": "resources.html#recommended-tutorials",
    "title": "Student Resources",
    "section": "üì∫ Recommended Tutorials",
    "text": "üì∫ Recommended Tutorials\nIf you prefer watching to reading:\n\nR Programming for Beginners (YouTube)\nStatQuest with Josh Starmer: The best channel for understanding the ‚Äúlogic‚Äù behind p-values and regression."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This course, MAT 186: Introduction to Data Science, is an Open Educational Resource. All materials created for this course are shared openly to reduce the cost of education for students and to encourage collaboration among educators."
  },
  {
    "objectID": "license.html#open-educational-resource-oer",
    "href": "license.html#open-educational-resource-oer",
    "title": "License",
    "section": "",
    "text": "This course, MAT 186: Introduction to Data Science, is an Open Educational Resource. All materials created for this course are shared openly to reduce the cost of education for students and to encourage collaboration among educators."
  },
  {
    "objectID": "license.html#creative-commons-license",
    "href": "license.html#creative-commons-license",
    "title": "License",
    "section": "Creative Commons License",
    "text": "Creative Commons License\nExcept where otherwise noted, the content on this site is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) License.\n\nWhat this means for you:\n\nAttribution: You must give appropriate credit, provide a link to the license, and indicate if changes were made.\nNonCommercial: You may not use the material for commercial purposes.\nShareAlike: If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.\n\nFor more information, visit the Creative Commons website."
  },
  {
    "objectID": "index.html#about-the-author",
    "href": "index.html#about-the-author",
    "title": "MAT 186: Data Science Lab Manual",
    "section": "",
    "text": "Henry Mendoza Rivera is an Instructor in the Department of Mathematics and Computer Science at Dutchess Community College. This OER project was developed to provide high-quality, zero-cost data science education to the DCC community.\n\n\n\n\n\n\nNoteSuggested Citation\n\n\n\nMendoza Rivera, H. (2026). MAT 186: Introduction to Data Science Lab Manual. Dutchess Community College. Available at: https://hmendozardcc.github.io/mat186-lab-manual/. Licensed under CC BY-NC-SA 4.0."
  },
  {
    "objectID": "resources.html#video-tutorials-creative-commons",
    "href": "resources.html#video-tutorials-creative-commons",
    "title": "Student Resources",
    "section": "üì∫ Video Tutorials (Creative Commons)",
    "text": "üì∫ Video Tutorials (Creative Commons)\nIf you prefer visual learning, these tutorials cover the core concepts of our course.\n\n1. Introduction to the Data Science Workflow\nUnderstand how ‚ÄúTidy‚Äù data moves from import to communication. \n\n\n2. Getting Started with R & RStudio\nA great refresher on the environment we use in the labs. \n\n\n3. Understanding Statistical Logic (StatQuest)\nJosh Starmer breaks down complex concepts like P-values and Regression into simple terms. * StatQuest with Josh Starmer Channel"
  }
]